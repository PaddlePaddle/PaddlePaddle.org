<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="design-doc-variable">
<span id="design-doc-variable"></span><h1>Design Doc: Variable<a class="headerlink" href="#design-doc-variable" title="永久链接至标题">¶</a></h1>
<p>Variable is also known as <em>blob</em> in MxNet and Caffe2.  It is the input and output type of operators, where a neural network is a graph of operators.</p>
<div class="section" id="requirements-lazy-memory-allocation">
<span id="requirements-lazy-memory-allocation"></span><h2>Requirements: Lazy Memory Allocation<a class="headerlink" href="#requirements-lazy-memory-allocation" title="永久链接至标题">¶</a></h2>
<p>For the flexibility of a DL system, a variable should be able to contain any typed value – a tensor in most cases, but could also be some integer IDs or a scope of other variables in the case of RNN.</p>
<p>To use the minimum amount of memory, we would like that a variable allocates memory only when it has to, or, lazy memory allocation.  Let’s take the following example:</p>
<div class="highlight-cpp"><div class="highlight"><pre><span></span><span class="n">Variable</span> <span class="n">vr</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">;</span>

<span class="n">Tensor</span><span class="o">*</span> <span class="n">t1</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">();</span>
<span class="n">Tensor</span><span class="o">*</span> <span class="n">t2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">();</span>

<span class="n">Randomize</span><span class="p">(</span>
  <span class="cm">/* malloc */</span> <span class="n">v1</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">float16</span><span class="o">&gt;</span><span class="p">(</span><span class="n">DDim</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">)),</span>
  <span class="cm">/* size */</span> <span class="n">t1</span><span class="p">.</span><span class="n">Size</span><span class="p">());</span>
  
<span class="n">Randomize</span><span class="p">(</span>
  <span class="cm">/* malloc */</span> <span class="n">v2</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">float16</span><span class="o">&gt;</span><span class="p">(</span><span class="n">DDim</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">300</span><span class="p">)),</span>
  <span class="cm">/* size */</span> <span class="n">t2</span><span class="p">.</span><span class="n">Size</span><span class="p">());</span>
  
<span class="n">Mult</span><span class="p">(</span>
  <span class="cm">/*result*/</span> <span class="n">vr</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">v1</span><span class="p">.</span><span class="n">Type</span><span class="p">()</span><span class="o">&gt;</span><span class="p">(</span><span class="n">SizeOfMult</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)),</span>
  <span class="cm">/*input1*/</span> <span class="n">v1</span><span class="p">.</span><span class="n">Get</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">data</span><span class="p">(),</span>
  <span class="cm">/*input2*/</span> <span class="n">v2</span><span class="p">.</span><span class="n">Get</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">data</span><span class="p">());</span>
</pre></div>
</div>
<p>We see that a variable holds nothing until <code class="docutils literal"><span class="pre">Variable::GetMutable&lt;Tensor&gt;()</span></code> allocates a tensor and puts it in the variable.  Similarly, a tensor gets its memory until <code class="docutils literal"><span class="pre">Tensor::mutable_data()</span></code>.</p>
<p>This syntax for lazy memory allocation when we call <code class="docutils literal"><span class="pre">Randomize</span></code> and <code class="docutils literal"><span class="pre">Mult</span></code>, those functions that mutate the variable, so it saves us some line of C++ code.</p>
</div>
<div class="section" id="implementation-type-hiding">
<span id="implementation-type-hiding"></span><h2>Implementation: Type Hiding<a class="headerlink" href="#implementation-type-hiding" title="永久链接至标题">¶</a></h2>
<p>To make memory allocation lazy, we cannot assume that we know the type held by a variable at definition time.  In other words, <code class="docutils literal"><span class="pre">class</span> <span class="pre">Variable</span></code> cannot be a template <code class="docutils literal"><span class="pre">template</span> <span class="pre">&lt;T&gt;</span> <span class="pre">class</span> <span class="pre">Variable</span></code>.</p>
<p>Because we don’t know the type <code class="docutils literal"><span class="pre">T</span></code>, we cannot save a <code class="docutils literal"><span class="pre">T*</span></code> as <code class="docutils literal"><span class="pre">Variable's</span></code> data member.  Instead, we save an interface object <code class="docutils literal"><span class="pre">Placeholder</span></code>, which can return the pointer to the saved object via <code class="docutils literal"><span class="pre">Placeholder::Ptr()</span></code> as <code class="docutils literal"><span class="pre">void*</span></code>.</p>
<p>But anyway, Variable needs to know <code class="docutils literal"><span class="pre">T</span></code> so could it <code class="docutils literal"><span class="pre">delete&lt;T&gt;(ptr)</span></code> and so could <code class="docutils literal"><span class="pre">Variable::Get</span></code> checks the expected type and the saved object’s type.</p>
<p>We save <code class="docutils literal"><span class="pre">T</span></code> in <code class="docutils literal"><span class="pre">PlaceholderImpl</span></code>, the implementation of <code class="docutils literal"><span class="pre">Placeholder</span></code>.  Please be aware that <code class="docutils literal"><span class="pre">PlaceholderImpl</span></code> is a class template and <code class="docutils literal"><span class="pre">T</span></code> is passed in as a template parameter.</p>
<p>Because <code class="docutils literal"><span class="pre">PlaceholderImpl</span></code> knows <code class="docutils literal"><span class="pre">T</span></code>, it can save and return <code class="docutils literal"><span class="pre">typeid(T)</span></code> for the type comparison in <code class="docutils literal"><span class="pre">Variable::Get</span></code> and <code class="docutils literal"><span class="pre">Variable::GetMutable</span></code>.</p>
</div>
<div class="section" id="conclusion">
<span id="conclusion"></span><h2>Conclusion<a class="headerlink" href="#conclusion" title="永久链接至标题">¶</a></h2>
<p>The technique type hiding utilizes C++ class templates, interface and derivation, and C++ RTTI (typeid).  This combination saves us from defining something like <code class="docutils literal"><span class="pre">caffe2::TypeMeta</span></code>, which takes hundreds of lines of C++ code.</p>
</div>
</div>
</div>
<div class="articleComments">
</div>
</div>
<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="run-in-docker-containers">
<h1>Run in Docker Containers<a class="headerlink" href="#run-in-docker-containers" title="Permalink to this headline">¶</a></h1>
<p>Run PaddlePaddle in Docker container so that you don’t need to care about
runtime dependencies, also you can run under Windows system. You can get
tutorials at <a class="reference external" href="https://docs.docker.com/get-started/">here</a> .</p>
<p>If you are using Windows, please refer to
<a class="reference external" href="https://docs.docker.com/toolbox/toolbox_install_windows/">this</a>
tutorial to start running docker under windows.</p>
<p>After you’ve read above tutorials you may proceed the following steps.</p>
<div class="section" id="pull-paddlepaddle-docker-image">
<span id="docker-pull"></span><h2>Pull PaddlePaddle Docker Image<a class="headerlink" href="#pull-paddlepaddle-docker-image" title="Permalink to this headline">¶</a></h2>
<p>Run the following command to download the latest Docker images, the version is cpu_avx_mkl:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>docker pull paddlepaddle/paddle
</pre></div>
</div>
</div></blockquote>
<p>For users in China, we provide a faster mirror:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>docker pull docker.paddlepaddlehub.com/paddle
</pre></div>
</div>
</div></blockquote>
<p>Download GPU version (cuda8.0_cudnn5_avx_mkl) images:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>docker pull paddlepaddle/paddle:latest-gpu
docker pull docker.paddlepaddlehub.com/paddle:latest-gpu
</pre></div>
</div>
</div></blockquote>
<p>Choose between different BLAS version:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span><span class="c1"># image using MKL by default</span>
docker pull paddlepaddle/paddle
<span class="c1"># image using OpenBLAS</span>
docker pull paddlepaddle/paddle:latest-openblas
</pre></div>
</div>
</div></blockquote>
<p>If you want to use legacy versions, choose a tag from
<a class="reference external" href="https://hub.docker.com/r/paddlepaddle/paddle/tags/">DockerHub</a>
and run:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>docker pull paddlepaddle/paddle:<span class="o">[</span>tag<span class="o">]</span>
<span class="c1"># i.e.</span>
docker pull docker.paddlepaddlehub.com/paddle:0.11.0-gpu
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="launch-your-training-program-in-docker">
<span id="docker-run"></span><h2>Launch your training program in Docker<a class="headerlink" href="#launch-your-training-program-in-docker" title="Permalink to this headline">¶</a></h2>
<p>Assume that you have already written a PaddlePaddle program
named <code class="code docutils literal"><span class="pre">train.py</span></code> under directory <code class="code docutils literal"><span class="pre">/home/work</span></code> (refer to
<a class="reference external" href="http://www.paddlepaddle.org/docs/develop/book/01.fit_a_line/index.cn.html">PaddlePaddleBook</a>
for more samples), then run the following command:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nb">cd</span> /home/work
docker run -it -v <span class="nv">$PWD</span>:/work paddlepaddle/paddle /work/train.py
</pre></div>
</div>
</div></blockquote>
<p>In the above command, <code class="code docutils literal"><span class="pre">-it</span></code> means run the container interactively;
<code class="code docutils literal"><span class="pre">-v</span> <span class="pre">$PWD:/work</span></code> means mount the current directory ($PWD will expand
to current absolute path in Linux) under <code class="code docutils literal"><span class="pre">/work</span></code> in the container.
<code class="code docutils literal"><span class="pre">paddlepaddle/paddle</span></code> to specify image to use; finnally
<code class="code docutils literal"><span class="pre">/work/train.py</span></code> is the command to run inside docker.</p>
<p>Also, you can go into the container shell, run or debug your code
interactively:</p>
<blockquote>
<div></div></blockquote>
<p><strong>NOTE: We did not install vim in the default docker image to reduce the image size, you can run</strong> <code class="code docutils literal"><span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">-y</span> <span class="pre">vim</span></code> <strong>to install it if you need to edit python files.</strong></p>
</div>
<div class="section" id="paddlepaddle-book">
<span id="docker-run-book"></span><h2>PaddlePaddle Book<a class="headerlink" href="#paddlepaddle-book" title="Permalink to this headline">¶</a></h2>
<p>You can create a container serving PaddlePaddle Book using Jupyter Notebook in
one minute using Docker. PaddlePaddle Book is an interactive Jupyter Notebook
for users and developers.If you want to
dig deeper into deep learning, PaddlePaddle Book definitely is your best choice.</p>
<p>We provide a packaged book image, simply issue the command:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>docker run -p <span class="m">8888</span>:8888 paddlepaddle/book
</pre></div>
</div>
</div></blockquote>
<p>For users in China, we provide a faster mirror:</p>
<blockquote>
<div></div></blockquote>
<p>Then, you would back and paste the address into the local browser:</p>
<blockquote>
<div><div class="highlight-text"><div class="highlight"><pre><span></span>http://localhost:8888/
</pre></div>
</div>
</div></blockquote>
<p>That’s all. Enjoy your journey!</p>
</div>
<div class="section" id="train-with-docker-with-gpu">
<span id="docker-run-gpu"></span><h2>Train with Docker with GPU<a class="headerlink" href="#train-with-docker-with-gpu" title="Permalink to this headline">¶</a></h2>
<p>We recommend using
<a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>
to run GPU training jobs. Please ensure you have latest
GPU driver installed before move on.</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>nvidia-docker run -it -v <span class="nv">$PWD</span>:/work paddlepaddle/paddle:latest-gpu /bin/bash
</pre></div>
</div>
</div></blockquote>
<p><strong>NOTE: If you don’t have nvidia-docker installed, try the following method to mount CUDA libs and devices into the container.</strong></p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">CUDA_SO</span><span class="o">=</span><span class="s2">"</span><span class="k">$(</span><span class="se">\l</span>s /usr/lib64/libcuda* <span class="p">|</span> xargs -I<span class="o">{}</span> <span class="nb">echo</span> <span class="s1">'-v {}:{}'</span><span class="k">)</span><span class="s2"> </span><span class="k">$(</span><span class="se">\l</span>s /usr/lib64/libnvidia* <span class="p">|</span> xargs -I<span class="o">{}</span> <span class="nb">echo</span> <span class="s1">'-v {}:{}'</span><span class="k">)</span><span class="s2">"</span>
<span class="nb">export</span> <span class="nv">DEVICES</span><span class="o">=</span><span class="k">$(</span><span class="se">\l</span>s /dev/nvidia* <span class="p">|</span> xargs -I<span class="o">{}</span> <span class="nb">echo</span> <span class="s1">'--device {}:{}'</span><span class="k">)</span>
docker run <span class="si">${</span><span class="nv">CUDA_SO</span><span class="si">}</span> <span class="si">${</span><span class="nv">DEVICES</span><span class="si">}</span> -it paddlepaddle/paddle:latest-gpu
</pre></div>
</div>
</div></blockquote>
<p><strong>About AVX:</strong></p>
<p>AVX is a kind of CPU instruction can accelerate PaddlePaddle’s calculations.
The latest PaddlePaddle Docker image turns AVX on by default, so, if your
computer doesn’t support AVX, you’ll probably need to
<a class="reference external" href="./build_from_source_en.html">build</a> with <code class="code docutils literal"><span class="pre">WITH_AVX=OFF</span></code>.</p>
<p>The following command will tell you whether your computer supports AVX.</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span><span class="k">if</span> cat /proc/cpuinfo <span class="p">|</span> grep -i avx<span class="p">;</span> <span class="k">then</span> <span class="nb">echo</span> Yes<span class="p">;</span> <span class="k">else</span> <span class="nb">echo</span> No<span class="p">;</span> <span class="k">fi</span>
</pre></div>
</div>
</div></blockquote>
</div>
</div>
</div>
<div class="articleComments">
</div>
</div>
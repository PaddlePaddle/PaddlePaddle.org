<div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<div itemprop="articleBody">
<div class="section" id="rnn">
<span id="rnn"></span><h1>RNN 变长输入设计<a class="headerlink" href="#rnn" title="永久链接至标题">¶</a></h1>
<p>对变长序列的学习，现有主流框架比如 tensorflow, pytorch, caffe2, mxnet 等均使用了padding的方式，
即将一个mini-batch内不同长度的序列补0到固定长度参与计算。</p>
<p>现有Paddle包括 <code class="docutils literal"><span class="pre">RecurrentLayerGroup</span></code> 在内的RNN均实现了无padding的变长序列支持，本文也将基于该模块的思路，设计重构后的变长序列支持。</p>
<div class="section" id="">
<span id="id1"></span><h2>背景介绍<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>由于tensor必须有明确的shape，因此基于tensor 的主流框架在存储变长序列时，
必须用zero-padding的方式将变长序列补全为固定shape的tensor。</p>
<p>由于padding是一种框架实现变长序列的妥协， 从用户角度，在使用RNN类模型时自然会比较介意padding的存在，
因此会有pytorch中对非padding方式变长序列支持长篇的讨论[3]。</p>
<p>由于padding对内存和计算会有额外的消耗，tensorflow和mxnet均使用了bucketing来进行优化[1][2]，
但不管是padding还是bucket，对于用户都是额外的使用负担。</p>
<p>因此，<strong>paddle原生支持变长序列的方式，能直接满足用户对变长序列的最直接的需求，在当前主流平台中可以算是一大优势</strong>。</p>
<p>但对变长序列的支持，需要对目前框架做一些修改，下面讨论如何在最小修改下支持变长序列。</p>
</div>
<div class="section" id="lodtensor">
<span id="lodtensor"></span><h2>多层序列数据格式 <code class="docutils literal"><span class="pre">LODTensor</span></code><a class="headerlink" href="#lodtensor" title="永久链接至标题">¶</a></h2>
<p>目前 Paddle 会将一个mini-batch内的数据存储在一维的内存上，
额外使用 <code class="docutils literal"><span class="pre">Argument.sequenceStartPositions</span></code> 来存储每个句子的信息。</p>
<p>Paddle里使用 <code class="docutils literal"><span class="pre">Argument.subSequenceStartPositions</span></code> 来存储2层的序列信息，更高维度的序列则无法直接支持；</p>
<p>为了支持 <code class="docutils literal"><span class="pre">N-level</span></code> 序列的存储，本文将序列信息定义成如下数据结构:</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lod_start_pos_</span><span class="p">;</span>
</pre></div>
</div>
<p>或者更明确的定义</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="k">typedef</span> <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">level_t</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">level_t</span><span class="o">&gt;</span> <span class="n">lod_start_pos</span><span class="p">;</span>
</pre></div>
</div>
<p>这里的每一个 <code class="docutils literal"><span class="pre">level_t</span></code> 存储一个粒度(level)的偏移信息，和paddle目前做法一致。</p>
<p>为了更透明地传递序列信息，我们引入了一种新的tensor 称为 <code class="docutils literal"><span class="pre">LODTensor</span></code>[4]，
其关于tensor相关的接口都直接继承自 <code class="docutils literal"><span class="pre">Tensor</span></code>，但另外添加了序列相关接口。
如此，在操作一个 <code class="docutils literal"><span class="pre">LODTensor</span></code> 时，普通 <code class="docutils literal"><span class="pre">Op</span></code> 直接当成 <code class="docutils literal"><span class="pre">Tensor</span></code> 使用，
而操作序列的 <code class="docutils literal"><span class="pre">Op</span></code> 会额外操作 <code class="docutils literal"><span class="pre">LODTensor</span></code> 的变长序列操作的相关接口。</p>
<p><code class="docutils literal"><span class="pre">LODTensor</span></code> 具体定义如下：</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LODTensor</span> <span class="o">:</span> <span class="k">public</span> <span class="n">Tensor</span> <span class="p">{</span>
<span class="k">public</span><span class="o">:</span>
  <span class="kt">size_t</span> <span class="n">Levels</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">seq_start_positions_</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="p">}</span>
  <span class="kt">size_t</span> <span class="n">Elements</span><span class="p">(</span><span class="kt">int</span> <span class="n">level</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="k">const</span> <span class="p">{</span>
    <span class="k">return</span> <span class="n">seq_start_positions_</span><span class="p">[</span><span class="n">level</span><span class="p">].</span><span class="n">size</span><span class="p">();</span>
  <span class="p">}</span>
  <span class="c1">// slice of level[elem_begin: elem_end]</span>
  <span class="c1">// NOTE low performance in slice seq_start_positions_.</span>
  <span class="c1">// TODO should call Tensor's Slice.</span>
  <span class="n">LODTensor</span> <span class="n">LODSlice</span><span class="p">(</span><span class="kt">int</span> <span class="n">level</span><span class="p">,</span> <span class="kt">int</span> <span class="n">elem_begin</span><span class="p">,</span> <span class="kt">int</span> <span class="n">elem_end</span><span class="p">)</span> <span class="k">const</span><span class="p">;</span>

  <span class="c1">// slice with tensor's data shared with this.</span>
  <span class="n">LODTensor</span> <span class="nf">LODSliceShared</span><span class="p">(</span><span class="kt">int</span> <span class="n">level</span><span class="p">,</span> <span class="kt">int</span> <span class="n">elem_begin</span><span class="p">,</span> <span class="kt">int</span> <span class="n">elem_end</span><span class="p">)</span> <span class="k">const</span><span class="p">;</span>

  <span class="c1">// copy other's lod_start_pos_, to share LOD info.</span>
  <span class="c1">// NOTE the LOD info sould not be changed.</span>
  <span class="kt">void</span> <span class="nf">ShareConstLODFrom</span><span class="p">(</span><span class="k">const</span> <span class="n">LODTensor</span> <span class="o">&amp;</span><span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">lod_start_pos_</span> <span class="o">=</span> <span class="n">other</span><span class="p">.</span><span class="n">lod_start_pos_</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="c1">// copy other's lod_start_pos_'s content, free to mutate.</span>
  <span class="kt">void</span> <span class="nf">ShareMutableLODFrom</span><span class="p">(</span><span class="k">const</span> <span class="n">LODTensor</span> <span class="o">&amp;</span><span class="n">other</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">lod_start_pos_</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span> <span class="o">&lt;</span>
                     <span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">other</span><span class="p">.</span><span class="n">lod_start_pos_</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span>
                                                   <span class="n">other</span><span class="p">.</span><span class="n">lod_start_pos_</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
  <span class="p">}</span>

<span class="k">private</span><span class="o">:</span>
  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lod_start_pos_</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
</div>
<p>其中， <code class="docutils literal"><span class="pre">lod_start_pos_</span></code> 使用了 <code class="docutils literal"><span class="pre">shared_ptr</span></code> 来减少存储和复制的代价，
可以认为 <code class="docutils literal"><span class="pre">LODTensor</span></code> 是 <code class="docutils literal"><span class="pre">Tensor</span></code> 的扩展，几乎完全兼容原始 <code class="docutils literal"><span class="pre">Tensor</span></code> 的使用。</p>
</div>
<div class="section" id="">
<span id="id2"></span><h2>框架支持<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<div class="section" id="tensor-lodtensor">
<span id="tensor-lodtensor"></span><h3>框架现有的 <code class="docutils literal"><span class="pre">Tensor</span></code> 调用替换为 <code class="docutils literal"><span class="pre">LODTensor</span></code><a class="headerlink" href="#tensor-lodtensor" title="永久链接至标题">¶</a></h3>
<p>为了实现 <code class="docutils literal"><span class="pre">LODTensor</span></code> 的传递，框架里很多 <code class="docutils literal"><span class="pre">Tensor</span></code> 都需要变成 <code class="docutils literal"><span class="pre">LODTensor</span></code>，
简单实现，直接 <strong>把之前所有的<code class="docutils literal"><span class="pre">Tensor</span></code> 全部替换成 <code class="docutils literal"><span class="pre">LODTensor</span></code>，这里可以直接修改 <code class="docutils literal"><span class="pre">pybind.cc</span></code> 里面创建<code class="docutils literal"><span class="pre">Tensor</span></code>的接口</strong>。</p>
<p>此外，用户有可能需要感知序列的存在（比如序列的可视化需要解析模型中输出的序列），因此一些序列操作的API也需要暴露到 python 层。</p>
</div>
<div class="section" id="lod-start-pos-op">
<span id="lod-start-pos-op"></span><h3><code class="docutils literal"><span class="pre">lod_start_pos</span></code> 随着Op调用链传递<a class="headerlink" href="#lod-start-pos-op" title="永久链接至标题">¶</a></h3>
<p>框架需要支持下列特性，以实现<code class="docutils literal"><span class="pre">lod_start_pos</span></code>的传递：</p>
<ol class="simple">
<li>以 <code class="docutils literal"><span class="pre">shared_ptr</span></code> 的方式实现传递<ul>
<li>不修改 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 内容的作为 consumer</li>
<li>修改 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的作为 producer</li>
<li>约定 consumer 只需要复制传递过来的 <code class="docutils literal"><span class="pre">shared_ptr</span></code><ul>
<li>producer 需要创建自己的独立的内存，以存储自己独立的修改，并暴露 <code class="docutils literal"><span class="pre">shared_ptr</span></code> 给后续 consumer</li>
</ul>
</li>
<li>由于传递过程是以复制<code class="docutils literal"><span class="pre">shared_ptr</span></code>的方式实现，因此框架只需要传递一次 <code class="docutils literal"><span class="pre">lod_start_pos</span></code></li>
</ul>
</li>
<li>对于不感知 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的Op足够透明</li>
<li>需要修改 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的producer Op可以在 <code class="docutils literal"><span class="pre">Run</span></code> 时更新自己的 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 数据</li>
</ol>
<p>具体的设计分为以下3小节</p>
<div class="section" id="load-start-pos">
<span id="load-start-pos"></span><h4><code class="docutils literal"><span class="pre">load_start_pos</span></code> 的传递<a class="headerlink" href="#load-start-pos" title="永久链接至标题">¶</a></h4>
<ul class="simple">
<li>对于不需要修改 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的情况，调用 LODTensor的 <code class="docutils literal"><span class="pre">ShareConstLODFrom</span></code> 接口实现复制</li>
<li>需要修改的，调用<code class="docutils literal"><span class="pre">ShareMutableLODFrom</span></code> 接口自己分配内存以存储修改</li>
</ul>
</div>
<div class="section" id="">
<span id="id3"></span><h4>框架透明<a class="headerlink" href="#" title="永久链接至标题">¶</a></h4>
<p>传递这一步需要加入到网络跑之前的初始化操作中，并且只需要初始化一次，基于当前框架设计的初步方案如下</p>
<ul class="simple">
<li>在 Op 的 <code class="docutils literal"><span class="pre">attrs</span></code> 中添加一项 <code class="docutils literal"><span class="pre">do_mutate_lod_info</span></code> 的属性，默认为 <code class="docutils literal"><span class="pre">false</span></code><ul>
<li>有需要修改 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的Op需要在定义 <code class="docutils literal"><span class="pre">OpProto</span></code> 时设置为 <code class="docutils literal"><span class="pre">true</span></code></li>
</ul>
</li>
<li><code class="docutils literal"><span class="pre">OperatorBase</span></code> 的 <code class="docutils literal"><span class="pre">InferShape</span></code> 中会读取 <code class="docutils literal"><span class="pre">do_mutate_lod_info</span></code> ，并且调用 <code class="docutils literal"><span class="pre">LODTensor</span></code> 相关的方法实现 <code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的复制。</li>
<li><code class="docutils literal"><span class="pre">OperatorBase</span></code> 中添加一个 member <code class="docutils literal"><span class="pre">is_lod_inited{false}</span></code> 来保证传递只进行一次</li>
</ul>
<p>一些逻辑如下</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">OperatorBase</span> <span class="p">{</span>
<span class="k">public</span><span class="o">:</span>
  <span class="c1">// ...</span>
  <span class="kt">void</span> <span class="n">InferShape</span><span class="p">()</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">is_load_inited</span><span class="p">)</span> <span class="p">{</span>
      <span class="kt">bool</span> <span class="n">do_mutate_lod_info</span> <span class="o">=</span> <span class="n">GetAttr</span><span class="o">&lt;</span><span class="kt">bool</span><span class="o">&gt;</span><span class="p">(</span><span class="s">"do_mutate_load_info"</span><span class="p">);</span>
      <span class="c1">// find a input having LOD to copy</span>
      <span class="k">auto</span> <span class="n">lod_input</span> <span class="o">=</span> <span class="n">ValidLODInput</span><span class="p">();</span>
      <span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;</span><span class="nl">output</span> <span class="p">:</span> <span class="n">outputs</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">do_mutate_load_info</span><span class="p">)</span> <span class="p">{</span>
          <span class="n">output</span><span class="p">.</span><span class="n">ShareMutableLODFrom</span><span class="p">(</span><span class="n">lod_input</span><span class="p">);</span>
        <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
          <span class="n">output</span><span class="p">.</span><span class="n">ShareConstLODFrom</span><span class="p">(</span><span class="n">load_input</span><span class="p">);</span>
        <span class="p">}</span>
      <span class="p">}</span>
      <span class="n">is_pod_inited</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="c1">// call op's InferShape</span>
    <span class="c1">// ...</span>
  <span class="p">}</span>

<span class="k">private</span><span class="o">:</span>
  <span class="c1">// ...</span>
  <span class="kt">bool</span> <span class="n">is_lod_inited</span><span class="p">{</span><span class="nb">false</span><span class="p">};</span>
<span class="p">};</span>
</pre></div>
</div>
<p>如此，<code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的信息的传递对非OLD的Op的实现是完全透明的。</p>
</div>
<div class="section" id="lod-start-pos">
<span id="lod-start-pos"></span><h4><code class="docutils literal"><span class="pre">lod_start_pos</span></code> 的更新<a class="headerlink" href="#lod-start-pos" title="永久链接至标题">¶</a></h4>
<p>上一小节介绍到，对于需要修改 <code class="docutils literal"><span class="pre">load_start_pos</span></code> 的Op，<code class="docutils literal"><span class="pre">OperatorBase</span></code> 会分配一块自己的内存以存储修改，
Op在 <code class="docutils literal"><span class="pre">Run</span></code> 的实现中，操作更新自己的 <code class="docutils literal"><span class="pre">load_start_pos</span></code> ，
而所有依赖其 outputs 的 op 会通过共享的指针自动获取到其更新。</p>
</div>
</div>
</div>
<div class="section" id="">
<span id="id4"></span><h2>根据长度排序<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p>按照长度排序后，从前往后的时间步的batch size会自然地递减，可以直接塞入 Net 做batch计算</p>
<p>比如原始的输入：</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">origin</span><span class="p">:</span>
<span class="n">xxxx</span>
<span class="n">xx</span>
<span class="n">xxx</span>

<span class="o">-&gt;</span> <span class="nb">sorted</span><span class="p">:</span>
<span class="n">xxxx</span>
<span class="n">xxx</span>
<span class="n">xx</span>
</pre></div>
</div>
<p>经过 <code class="docutils literal"><span class="pre">SegmentInputs</span></code> 之后，每个会有4个时间步，每个时间步的输入如下（纵向排列）</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="mi">0</span>    <span class="mi">1</span>    <span class="mi">2</span>    <span class="mi">3</span>
<span class="n">x</span>    <span class="n">x</span>    <span class="n">x</span>    <span class="n">x</span>
<span class="n">x</span>    <span class="n">x</span>    <span class="n">x</span>
<span class="n">x</span>    <span class="n">x</span>
</pre></div>
</div>
<p>为了追踪排序前后序列的变化，这里用</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="k">struct</span> <span class="n">SortedSeqItem</span> <span class="p">{</span>
   <span class="kt">void</span> <span class="o">*</span><span class="n">start</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
   <span class="kt">void</span> <span class="o">*</span><span class="n">end</span><span class="p">{</span><span class="k">nullptr</span><span class="p">};</span>
<span class="p">};</span>

<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">SortedSeqItem</span><span class="o">&gt;</span> <span class="n">sorted_seqs</span><span class="p">;</span>
</pre></div>
</div>
<p>来追踪序列排序后的位置，并添加一个新的接口</p>
<div class="highlight-c++"><div class="highlight"><pre><span></span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">SortedSeqItem</span><span class="o">&gt;</span> <span class="n">SortBySeqLen</span><span class="p">(</span><span class="k">const</span> <span class="n">LODTensor</span><span class="o">&amp;</span> <span class="n">tensor</span><span class="p">);</span>
</pre></div>
</div>
<p>由于输入序列的顺序变化，以下现有的接口需要针对性地修改：</p>
<ul class="simple">
<li>InitMemories, memory需要根据 <code class="docutils literal"><span class="pre">sorted_seqs</span></code> 重新排列</li>
<li>SetmentInputs</li>
<li>ConcatOutputs</li>
</ul>
<p>此外，由于 <code class="docutils literal"><span class="pre">sorted_seqs</span></code> 需要被 <code class="docutils literal"><span class="pre">RecurrentGradientOp</span></code> 复用，因此会变成 <code class="docutils literal"><span class="pre">RecurrentOp</span></code> 一个新的output输出，
之后作为 <code class="docutils literal"><span class="pre">RecurrentGradientOp</span></code> 的一个输入传入。</p>
</div>
<div class="section" id="initmemories">
<span id="initmemories"></span><h2>InitMemories<a class="headerlink" href="#initmemories" title="永久链接至标题">¶</a></h2>
<p>由于序列顺序的变化，<code class="docutils literal"><span class="pre">boot_memories</span></code> 的batch上的element的顺序也需要对应重新排列。</p>
</div>
<div class="section" id="segmentinputs">
<span id="segmentinputs"></span><h2>SegmentInputs<a class="headerlink" href="#segmentinputs" title="永久链接至标题">¶</a></h2>
<p><code class="docutils literal"><span class="pre">SegmentInputs</span></code> 会依赖 <code class="docutils literal"><span class="pre">sorted_seqs</span></code> 的信息，将原始的序列按照排序后的序列顺序，从横向切割，转为每个step中的inputs。</p>
<p>即下面的转变：</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>origin:
xxxx
xx
xxx

   |
   |
  \ /
   !
0    1    2    3
x    x    x    x
x    x    x
x    x
</pre></div>
</div>
</div>
<div class="section" id="concatoutputs">
<span id="concatoutputs"></span><h2>ConcatOutputs<a class="headerlink" href="#concatoutputs" title="永久链接至标题">¶</a></h2>
<p><code class="docutils literal"><span class="pre">ConcatOutputs</span></code> 需要</p>
<ul class="simple">
<li>将每个时间步的输出重新还原为原始输入的序列顺序（以防止Infer阶段顺序打乱）</li>
<li>将每个序列concat 为规则的mini-batch表示</li>
</ul>
</div>
<div class="section" id="">
<span id="id5"></span><h2>参考文献<a class="headerlink" href="#" title="永久链接至标题">¶</a></h2>
<p><a class="reference external" href="https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.training/bucketing">Tensorflow Bucketing</a></p>
<p><a class="reference external" href="http://mxnet.io/how_to/bucketing.html">mxnet Bucketing</a></p>
<p><a class="reference external" href="https://discuss.pytorch.org/t/about-the-variable-length-input-in-rnn-scenario/345/5">variable length input in RNN scenario</a></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Level_of_detail">Level of details</a></p>
</div>
</div>
</div>
<div class="articleComments">
</div>
</div>
{% verbatim %}
<h1>如何写新的Operator</h1>
<ul>
<li><a href="#概念简介">概念简介</a></li>
<li><a href="#实现c类">实现C++类</a></li>
<li><a href="#定义protomaker类">定义ProtoMaker类</a></li>
<li><a href="#定义operator类">定义Operator类</a></li>
<li><a href="#定义opkernel类">定义OpKernel类</a></li>
<li><a href="#注册operator">注册Operator</a></li>
<li><a href="#编译">编译</a></li>
<li><a href="#绑定python">绑定Python</a></li>
<li><a href="#实现单元测试">实现单元测试</a></li>
<li><a href="#前向operator单测">前向Operator单测</a></li>
<li><a href="#反向operator单测">反向Operator单测</a></li>
<li><a href="#编译和执行">编译和执行</a></li>
<li><a href="#注意事项">注意事项</a></li>
</ul>
<h2>概念简介</h2>
<p>简单介绍需要用到基类，详细介绍请参考设计文档。</p>
<ul>
<li><code>framework::OperatorBase</code>: Operator(简写，Op)基类。</li>
<li><code>framework::OpKernel</code>: Op计算函数的基类，称作Kernel。</li>
<li><code>framework::OperatorWithKernel</code>：继承自OperatorBase，Op有计算函数，称作有Kernel。</li>
<li><code>class OpProtoAndCheckerMaker</code>：描述该Op的输入、输出、属性、注释,主要用于Python API接口生成</li>
</ul>
<p>依据是否包含kernel，可以将Op分为两种：包含Kernel的Op和不包含kernel的Op，前者Op的定义继承自<code>OperatorWithKernel</code>，后者继承自<code>OperatorBase</code>。本教程主要介绍带Kernel的Op如何写，简单总结Op需要包含的内容如下：</p>
<table>
<thead>
<tr>
<th>内容</th>
<th>定义位置</th>
</tr>
</thead>
<tbody>
<tr>
<td>OpProtoMake定义 </td>
<td>`.cc`文件，Backward Op不需要定义OpProtoMake </td>
</tr>
<tr>
<td>Op定义 </td>
<td> `.cc`文件</td>
</tr>
<tr>
<td>Kernel实现 </td>
<td> CPU、CUDA共享Kernel实现在`.h`文件中，否则，CPU 实现在`.cc`文件中，CUDA 实现在`.cu`文件中。</td>
</tr>
<tr>
<td>注册Op </td>
<td> Op注册实现在`.cc`文件；Kernel注册CPU实现在`.cc`文件中，CUDA实现在`.cu`文件中</td>
</tr>
</tbody>
</table>

<p>实现新的op都添加至目录<a href="https://github.com/PaddlePaddle/Paddle/tree/develop/paddle/fluid/operators">paddle/fluid/operators</a>下，文件命名以<code>*_op.h</code>（如有） 、 <code>*_op.cc</code> 、<code>*_op.cu</code>（如有）结尾。<strong>系统会根据文件名自动构建op和其对应的Python扩展。</strong></p>
<p>下面以矩阵乘操作，即<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/mul_op.cc">MulOp</a>为例来介绍如何写带Kernel的Operator。</p>
<h2>实现C++类</h2>
<h3>定义ProtoMaker类</h3>
<p>矩阵乘法的公式：$Out = X * Y$, 可见该计算由两个输入，一个输出组成。</p>
<p>首先定义<code>ProtoMaker</code>来描述该Op的输入、输出，并添加注释：</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MulOpMaker</span> <span class="o">:</span> <span class="k">public</span> <span class="n">framework</span><span class="o">::</span><span class="n">OpProtoAndCheckerMaker</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">MulOpMaker</span><span class="p">(</span><span class="n">OpProto</span> <span class="o">*</span><span class="n">proto</span><span class="p">,</span> <span class="n">OpAttrChecker</span> <span class="o">*</span><span class="n">op_checker</span><span class="p">)</span>
      <span class="o">:</span> <span class="n">OpProtoAndCheckerMaker</span><span class="p">(</span><span class="n">proto</span><span class="p">,</span> <span class="n">op_checker</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">AddInput</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">,</span> <span class="s">&quot;(Tensor), 2D tensor of size (M x K)&quot;</span><span class="p">);</span>
    <span class="n">AddInput</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">,</span> <span class="s">&quot;(Tensor), 2D tensor of size (K x N)&quot;</span><span class="p">);</span>
    <span class="n">AddOutput</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">,</span> <span class="s">&quot;(Tensor), 2D tensor of size (M x N)&quot;</span><span class="p">);</span>
    <span class="n">AddComment</span><span class="p">(</span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">DOC(</span><span class="s"></span>
<span class="s">Two Element Mul Operator.</span>
<span class="s">The equation is: Out = X * Y</span>
<span class="dl">)DOC</span><span class="s">&quot;</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>

<p><a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/mul_op.cc#L76-L127"><code>MulOpMaker</code></a>继承自<code>framework::OpProtoAndCheckerMaker</code>，构造函数含有2个参数：</p>
<ul>
<li><code>framework::OpProto</code> ： 前者存储Op的输入输出和参数属性，将用于Python API接口的生成。</li>
<li><code>framework::OpAttrChecker</code> ：后者用于检查参数属性的合法性。</li>
</ul>
<p>构造函数里通过<code>AddInput</code>添加输入参数，通过<code>AddOutput</code>添加输出参数，通过<code>AddComment</code>添加Op的注释。这些函数会将对应内容添加到<code>OpProto</code>中。</p>
<p>上面的代码在<code>MulOp</code>中添加两个输入<code>X</code>和<code>Y</code>，添加了一个输出<code>Out</code>，并解释了各自含义，命名请遵守<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/doc/fluid/dev/name_convention.md">命名规范</a>。</p>
<p>再以<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/scale_op.cc#L38-L55"><code>ScaleOp</code></a>为例：</p>
<div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">AttrType</span><span class="o">&gt;</span>
<span class="k">class</span> <span class="nc">ScaleOpMaker</span> <span class="o">:</span> <span class="k">public</span> <span class="n">framework</span><span class="o">::</span><span class="n">OpProtoAndCheckerMaker</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="n">ScaleOpMaker</span><span class="p">(</span><span class="n">OpProto</span> <span class="o">*</span><span class="n">proto</span><span class="p">,</span> <span class="n">OpAttrChecker</span> <span class="o">*</span><span class="n">op_checker</span><span class="p">)</span>
      <span class="o">:</span> <span class="n">OpProtoAndCheckerMaker</span><span class="p">(</span><span class="n">proto</span><span class="p">,</span> <span class="n">op_checker</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">AddInput</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">,</span> <span class="s">&quot;(Tensor) Input tensor of scale operator.&quot;</span><span class="p">);</span>
    <span class="n">AddOutput</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">,</span> <span class="s">&quot;(Tensor) Output tensor of scale operator.&quot;</span><span class="p">);</span>
    <span class="n">AddComment</span><span class="p">(</span><span class="sa">R</span><span class="s">&quot;</span><span class="dl">DOC(</span><span class="s"></span>
<span class="s">Scale operator</span>
<span class="s">$$Out = scale*X$$</span>
<span class="dl">)DOC</span><span class="s">&quot;</span><span class="p">);</span>
    <span class="n">AddAttr</span><span class="o">&lt;</span><span class="n">AttrType</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;scale&quot;</span><span class="p">,</span>
                      <span class="s">&quot;(float, default 1.0)&quot;</span>
                      <span class="s">&quot;The scaling factor of the scale operator.&quot;</span><span class="p">)</span>
        <span class="p">.</span><span class="n">SetDefault</span><span class="p">(</span><span class="mf">1.0</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>

<p>这个例子有<code>AddAttr&lt;AttrType&gt;("scale", "...").SetDefault(1.0);</code> : 增加<code>scale</code>系数，作为参数属性，并且设置默认值为1.0。</p>
<h3>定义Operator类</h3>
<p>下面的点实现了MulOp的定义：</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MulOp</span> <span class="o">:</span> <span class="k">public</span> <span class="n">framework</span><span class="o">::</span><span class="n">OperatorWithKernel</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="k">using</span> <span class="n">framework</span><span class="o">::</span><span class="n">OperatorWithKernel</span><span class="o">::</span><span class="n">OperatorWithKernel</span><span class="p">;</span>

 <span class="k">protected</span><span class="o">:</span>
  <span class="kt">void</span> <span class="n">InferShape</span><span class="p">(</span><span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">InferShapeContext</span> <span class="o">&amp;</span><span class="n">ctx</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
    <span class="k">auto</span> <span class="n">dim0</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">dims</span><span class="p">();</span>
    <span class="k">auto</span> <span class="n">dim1</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">dims</span><span class="p">();</span>
    <span class="n">PADDLE_ENFORCE_EQ</span><span class="p">(</span><span class="n">dim0</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="s">&quot;input X(%s) should be a tensor with 2 dims, a matrix&quot;</span><span class="p">,</span>
                      <span class="n">ctx</span><span class="p">.</span><span class="n">op_</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">));</span>
    <span class="n">PADDLE_ENFORCE_EQ</span><span class="p">(</span><span class="n">dim1</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="mi">2</span><span class="p">,</span>
                      <span class="s">&quot;input Y(%s) should be a tensor with 2 dims, a matrix&quot;</span><span class="p">,</span>
                      <span class="n">ctx</span><span class="p">.</span><span class="n">op_</span><span class="p">.</span><span class="n">Input</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">));</span>
    <span class="n">PADDLE_ENFORCE_EQ</span><span class="p">(</span>
        <span class="n">dim0</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dim1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="s">&quot;First matrix&#39;s width must be equal with second matrix&#39;s height.&quot;</span><span class="p">);</span>
    <span class="n">ctx</span><span class="p">.</span><span class="n">Output</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Resize</span><span class="p">({</span><span class="n">dim0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dim1</span><span class="p">[</span><span class="mi">1</span><span class="p">]});</span>
  <span class="p">}</span>
<span class="p">};</span>
</pre></div>

<p><a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/mul_op.cc#L22"><code>MulOp</code></a>继承自<code>OperatorWithKernel</code>。<code>public</code>成员：</p>
<div class="highlight"><pre><span></span><span class="k">using</span> <span class="n">framework</span><span class="o">::</span><span class="n">OperatorWithKernel</span><span class="o">::</span><span class="n">OperatorWithKernel</span><span class="p">;</span>
</pre></div>

<p>这句表示使用基类<code>OperatorWithKernel</code>的构造函数，也可写成：</p>
<div class="highlight"><pre><span></span><span class="n">MulOp</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="o">&amp;</span><span class="n">type</span><span class="p">,</span> <span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">VariableNameMap</span> <span class="o">&amp;</span><span class="n">inputs</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">VariableNameMap</span> <span class="o">&amp;</span><span class="n">outputs</span><span class="p">,</span>
      <span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">AttributeMap</span> <span class="o">&amp;</span><span class="n">attrs</span><span class="p">)</span>
  <span class="o">:</span> <span class="n">OperatorWithKernel</span><span class="p">(</span><span class="n">type</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">attrs</span><span class="p">)</span> <span class="p">{}</span>
</pre></div>

<p>还需要重写<code>InferShape</code>接口。<code>InferShape</code>为const函数，不能修改Op的成员变量，参数为<code>const framework::InferShapeContext &amp;ctx</code>，通过该参数可获取到输入输出以及属性。它的功能是：</p>
<ul>
<li>1). 做检查， 尽早报错：检查输入数据维度、类型等是否合法。</li>
<li>2). 设置输出Tensor的形状。</li>
</ul>
<p>通常<code>OpProtoMaker</code>和<code>Op</code>类的定义写在<code>.cc</code>文件中，和下面将要介绍的注册函数一起放在<code>.cc</code>中</p>
<h3>定义OpKernel类</h3>
<p><code>MulKernel</code>继承自<code>framework::OpKernel</code>，带有下面两个模板参数:</p>
<ul>
<li>
<p><code>typename DeviceContext</code>: 表示设备类型，不同设备(CPU、CUDA)共享同一个Kernel时，需加该模板参数，不共享则不加，一个不共享的例子是<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/cross_entropy_op.h#L43"><code>OnehotCrossEntropyOpKernel</code></a>。</p>
</li>
<li>
<p><code>typename T</code> : 表示数据类型，如<code>float</code>, <code>double</code>等。</p>
</li>
</ul>
<p>需要为<code>MulKernel</code>类重写<code>Compute</code>接口。
- <code>Compute</code>接受一个输入参数：<code>const framework::ExecutionContext&amp; context</code>。
- 与<code>InferShapeContext</code>相比，<code>ExecutionContext</code>增加了设备类型，同样可获取到输入输出和属性参数。
- <code>Compute</code>函数里实现<code>OpKernel</code>的具体计算逻辑。</p>
<p>下面是 <code>MulKernel</code> <code>Compute</code>的实现：</p>
<div class="highlight"><pre><span></span><span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">DeviceContext</span><span class="p">,</span> <span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
<span class="k">class</span> <span class="nc">MulKernel</span> <span class="o">:</span> <span class="k">public</span> <span class="n">framework</span><span class="o">::</span><span class="n">OpKernel</span> <span class="p">{</span>
<span class="k">public</span><span class="o">:</span>
<span class="kt">void</span> <span class="n">Compute</span><span class="p">(</span><span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">ExecutionContext</span><span class="o">&amp;</span> <span class="n">context</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">X</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">);</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">);</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Output</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">);</span>
  <span class="n">Z</span><span class="o">-&gt;</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">context</span><span class="p">.</span><span class="n">GetPlace</span><span class="p">());</span>
  <span class="k">auto</span><span class="o">&amp;</span> <span class="n">device_context</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="k">template</span> <span class="n">device_context</span><span class="o">&lt;</span><span class="n">DeviceContext</span><span class="o">&gt;</span><span class="p">();</span>
  <span class="n">math</span><span class="o">::</span><span class="n">matmul</span><span class="o">&lt;</span><span class="n">DeviceContext</span><span class="p">,</span> <span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="o">*</span><span class="n">X</span><span class="p">,</span> <span class="nb">false</span><span class="p">,</span> <span class="o">*</span><span class="n">Y</span><span class="p">,</span> <span class="nb">false</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">device_context</span><span class="p">);</span>
<span class="p">}</span>
<span class="p">};</span>
</pre></div>

<p>需要注意：<strong>不同设备(CPU、CUDA)共享一个Op定义，是否则共享同一个<code>OpKernel</code>，取决于<code>Compute</code>调用的函数是否支持不同设备。</strong></p>
<p><code>MulOp</code>的CPU、CUDA实现共享同一个<code>Kernel</code>。<code>OpKernel</code>不共享的例子可以参考：<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/operators/cross_entropy_op.h#L43"><code>OnehotCrossEntropyOpKernel</code></a>。</p>
<p>为了使<code>OpKernel</code>的计算过程书写更加简单，并且CPU、CUDA的代码可以复用，我们通常借助 Eigen unsupported Tensor模块来实现<code>Compute</code>接口。关于在PaddlePaddle中如何使用Eigen库，请参考<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/doc/fluid/dev/use_eigen_cn.md">使用文档</a>。</p>
<p>到此，前向Op实现完成。接下来，需要在<code>.cc</code>文件中注册该op和kernel。
反向Op类的定义，反向OpKernel的定义与前向Op类似，这里不再赘述。<strong>但需注意反向Op没有<code>ProtoMaker</code></strong>。</p>
<h3>注册Operator</h3>
<ul>
<li>
<p>在<code>.cc</code>文件中注册前向、反向Op类，注册CPU Kernel。</p>
<div class="highlight"><pre><span></span><span class="k">namespace</span> <span class="n">ops</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">::</span><span class="n">operators</span><span class="p">;</span>
<span class="n">REGISTER_OPERATOR</span><span class="p">(</span><span class="n">mul</span><span class="p">,</span> <span class="n">ops</span><span class="o">::</span><span class="n">MulOp</span><span class="p">,</span> <span class="n">ops</span><span class="o">::</span><span class="n">MulOpMaker</span><span class="p">,</span>
              <span class="n">paddle</span><span class="o">::</span><span class="n">framework</span><span class="o">::</span><span class="n">DefaultGradOpDescMaker</span><span class="o">&lt;</span><span class="nb">true</span><span class="o">&gt;</span><span class="p">)</span>
<span class="n">REGISTER_OPERATOR</span><span class="p">(</span><span class="n">mul_grad</span><span class="p">,</span> <span class="n">ops</span><span class="o">::</span><span class="n">MulGradOp</span><span class="p">)</span>
<span class="n">REGISTER_OP_CPU_KERNEL</span><span class="p">(</span><span class="n">mul</span><span class="p">,</span> <span class="n">ops</span><span class="o">::</span><span class="n">MulKernel</span><span class="o">&lt;</span><span class="n">paddle</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">CPUDeviceContext</span><span class="p">,</span> <span class="kt">float</span><span class="o">&gt;</span><span class="p">);</span>
<span class="n">REGISTER_OP_CPU_KERNEL</span><span class="p">(</span><span class="n">mul_grad</span><span class="p">,</span>
              <span class="n">ops</span><span class="o">::</span><span class="n">MulGradKernel</span><span class="o">&lt;</span><span class="n">paddle</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">CPUDeviceContext</span><span class="p">,</span> <span class="kt">float</span><span class="o">&gt;</span><span class="p">);</span>
</pre></div>

</li>
</ul>
<p>在上面的代码中：</p>
<pre><code>- `REGISTER_OPERATOR` ： 注册`ops::MulOp`类，类型名为`mul`，该类的`ProtoMaker`为`ops::MulOpMaker`，注册`ops::MulOpGrad`，类型名为`mul_grad`。
- `REGISTER_OP_CPU_KERNEL` ：注册`ops::MulKernel`类，并特化模板参数为`paddle::platform::CPUPlace`和`float`类型，同理，注册`ops::MulGradKernel`类。
</code></pre>
<ul>
<li>
<p>在 <code>.cu</code>文件中注册CUDA Kernel。</p>
<ul>
<li>请注意，如果CUDA Kernel的实现基于Eigen unsupported模块，那么在 <code>.cu</code>的开始请加上宏定义 <code>#define EIGEN_USE_GPU</code>，代码示例如下：</li>
</ul>
<div class="highlight"><pre><span></span><span class="c1">// if use Eigen unsupported module before include head files</span>
<span class="cp">#define EIGEN_USE_GPU</span>

<span class="k">namespace</span> <span class="n">ops</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">::</span><span class="n">operators</span><span class="p">;</span>
<span class="n">REGISTER_OP_CUDA_KERNEL</span><span class="p">(</span><span class="n">mul</span><span class="p">,</span> <span class="n">ops</span><span class="o">::</span><span class="n">MulKernel</span><span class="o">&lt;</span><span class="n">paddle</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">CUDADeviceContext</span><span class="p">,</span> <span class="kt">float</span><span class="o">&gt;</span><span class="p">);</span>
<span class="n">REGISTER_OP_CUDA_KERNEL</span><span class="p">(</span><span class="n">mul_grad</span><span class="p">,</span>
                       <span class="n">ops</span><span class="o">::</span><span class="n">MulGradKernel</span><span class="o">&lt;</span><span class="n">paddle</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">CUDADeviceContext</span><span class="p">,</span> <span class="kt">float</span><span class="o">&gt;</span><span class="p">);</span>
</pre></div>

</li>
</ul>
<h3>编译</h3>
<p>运行下面命令可以进行编译：</p>
<div class="highlight"><pre><span></span>make mul_op
</pre></div>

<h2>绑定Python</h2>
<p>系统会对新增的op自动绑定Python，并链接到生成的lib库中。</p>
<h2>实现单元测试</h2>
<p>单测包括对比前向Op不同设备(CPU、CUDA)的实现、对比反向OP不同设备(CPU、CUDA)的实现、反向Op的梯度测试。下面介绍介绍<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/python/paddle/fluid/tests/unittests/test_mul_op.py"><code>MulOp</code>的单元测试</a>。</p>
<h3>前向Operator单测</h3>
<p>Op单元测试继承自<code>OpTest</code>。各项更加具体的单元测试在<code>TestMulOp</code>里完成。测试Operator，需要：</p>
<ol>
<li>在<code>setUp</code>函数定义输入、输出，以及相关的属性参数。</li>
<li>生成随机的输入数据。</li>
<li>在Python脚本中实现与前向operator相同的计算逻辑，得到输出值，与operator前向计算的输出进行对比。</li>
<li>反向计算已经自动集成进测试框架，直接调用相应接口即可。</li>
</ol>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">unittest</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">op_test</span> <span class="kn">import</span> <span class="n">OpTest</span>


<span class="k">class</span> <span class="nc">TestMulOp</span><span class="p">(</span><span class="n">OpTest</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op_type</span> <span class="o">=</span> <span class="s2">&quot;mul&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">84</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">),</span>
            <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">84</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Out&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])}</span>

    <span class="k">def</span> <span class="nf">test_check_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_output</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">test_check_grad_normal</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_grad</span><span class="p">([</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="s1">&#39;Out&#39;</span><span class="p">,</span> <span class="n">max_relative_error</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_check_grad_ingore_x</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_grad</span><span class="p">(</span>
            <span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="s1">&#39;Out&#39;</span><span class="p">,</span> <span class="n">max_relative_error</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">no_grad_set</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">test_check_grad_ingore_y</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_grad</span><span class="p">(</span>
            <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">],</span> <span class="s1">&#39;Out&#39;</span><span class="p">,</span> <span class="n">max_relative_error</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">no_grad_set</span><span class="o">=</span><span class="nb">set</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">))</span>
</pre></div>

<p>上面的代码首先导入依赖的包，下面是对<code>setUp</code>函数中操作的重要变量的详细解释：</p>
<ul>
<li><code>self.op_type = "mul"</code> : 定义类型，与operator注册时注册的类型一致。</li>
<li><code>self.inputs</code> : 定义输入，类型为<code>numpy.array</code>，并初始化。</li>
<li><code>self.outputs</code> : 定义输出，并在Python脚本中完成与operator同样的计算逻辑，返回Python端的计算结果。</li>
</ul>
<h3>反向operator单测</h3>
<p>而反向测试中：
- <code>test_check_grad_normal</code>中调用<code>check_grad</code>使用数值法检测梯度正确性和稳定性。
  - 第一个参数<code>["X", "Y"]</code> : 指定对输入变量<code>X</code>、<code>Y</code>做梯度检测。
  - 第二个参数<code>"Out"</code> : 指定前向网络最终的输出目标变量<code>Out</code>。
  - 第三个参数<code>max_relative_error</code>：指定检测梯度时能容忍的最大错误值。
- <code>test_check_grad_ingore_x</code>和<code>test_check_grad_ingore_y</code>分支用来测试只需要计算一个输入梯度的情况。</p>
<h3>编译和执行</h3>
<p><code>python/paddle/fluid/tests/unittests/</code> 目录下新增的 <code>test_*.py</code> 单元测试会被自动加入工程进行编译。</p>
<p>请注意，<strong>不同于Op的编译测试，运行单元测试测时需要编译整个工程</strong>，并且编译时需要打开<code>WITH_TESTING</code>, 即<code>cmake paddle_dir -DWITH_TESTING=ON</code>。编译成功后，执行下面的命令来运行单元测试：</p>
<div class="highlight"><pre><span></span>make <span class="nb">test</span> <span class="nv">ARGS</span><span class="o">=</span><span class="s2">&quot;-R test_mul_op -V&quot;</span>
</pre></div>

<p>或者:</p>
<div class="highlight"><pre><span></span>ctest -R test_mul_op
</pre></div>

<h2>注意事项</h2>
<ul>
<li>注册Op时的类型名，需要和该Op的名字一样。即不允许在<code>A_op.cc</code>里面，注册<code>REGISTER_OPERATOR(B, ...)</code>等，这将会导致单元测试出错。</li>
<li>如果Op没有实现CUDA Kernel，请不要创建空的<code>*_op.cu</code>，这将会导致单元测试出错。</li>
<li>如果多个Op依赖一些共用的函数，可以创建非<code>*_op.*</code>格式的文件来存放，如<code>gather.h</code>文件。</li>
</ul>
{% endverbatim %}
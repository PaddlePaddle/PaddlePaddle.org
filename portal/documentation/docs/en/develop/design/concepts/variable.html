{% verbatim %}
<h1>Design Doc: Variable</h1>
<p>Variable is also known as <em>blob</em> in MxNet and Caffe2.  It is the input and output type of operators, where a neural network is a graph of operators.</p>
<h2>Requirements: Lazy Memory Allocation</h2>
<p>For the flexibility of a DL system, a variable should be able to contain any typed value -- a tensor in most cases, but could also be some integer IDs or a scope of other variables in the case of RNN.</p>
<p>To use the minimum amount of memory, we would like that a variable allocates memory only when it has to, or, lazy memory allocation.  Let's take the following example:</p>
<div class="highlight"><pre><span></span><span class="n">Variable</span> <span class="n">vr</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">;</span>

<span class="n">Tensor</span><span class="o">*</span> <span class="n">t1</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">();</span>
<span class="n">Tensor</span><span class="o">*</span> <span class="n">t2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Tensor</span><span class="p">();</span>

<span class="n">Randomize</span><span class="p">(</span>
  <span class="cm">/* malloc */</span> <span class="n">v1</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">float16</span><span class="o">&gt;</span><span class="p">(</span><span class="n">DDim</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">200</span><span class="p">)),</span>
  <span class="cm">/* size */</span> <span class="n">t1</span><span class="p">.</span><span class="n">Size</span><span class="p">());</span>

<span class="n">Randomize</span><span class="p">(</span>
  <span class="cm">/* malloc */</span> <span class="n">v2</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">float16</span><span class="o">&gt;</span><span class="p">(</span><span class="n">DDim</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">300</span><span class="p">)),</span>
  <span class="cm">/* size */</span> <span class="n">t2</span><span class="p">.</span><span class="n">Size</span><span class="p">());</span>

<span class="n">Mult</span><span class="p">(</span>
  <span class="cm">/*result*/</span> <span class="n">vr</span><span class="p">.</span><span class="n">GetMutable</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">v1</span><span class="p">.</span><span class="n">Type</span><span class="p">()</span><span class="o">&gt;</span><span class="p">(</span><span class="n">SizeOfMult</span><span class="p">(</span><span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">)),</span>
  <span class="cm">/*input1*/</span> <span class="n">v1</span><span class="p">.</span><span class="n">Get</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">data</span><span class="p">(),</span>
  <span class="cm">/*input2*/</span> <span class="n">v2</span><span class="p">.</span><span class="n">Get</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">().</span><span class="n">data</span><span class="p">());</span>
</pre></div>

<p>We see that a variable holds nothing until <code>Variable::GetMutable&lt;Tensor&gt;()</code> allocates a tensor and puts it in the variable.  Similarly, a tensor gets its memory until <code>Tensor::mutable_data()</code>.</p>
<p>This syntax for lazy memory allocation when we call <code>Randomize</code> and <code>Mult</code>, those functions that mutate the variable, so it saves us some line of C++ code.</p>
<h2>Implementation: Type Hiding</h2>
<p>To make memory allocation lazy, we cannot assume that we know the type held by a variable at definition time.  In other words, <code>class Variable</code> cannot be a template <code>template &lt;T&gt; class Variable</code>.</p>
<p>Because we don't know the type <code>T</code>, we cannot save a <code>T*</code> as <code>Variable's</code> data member.  Instead, we save an interface object <code>Placeholder</code>, which can return the pointer to the saved object via <code>Placeholder::Ptr()</code> as <code>void*</code>.</p>
<p>But anyway, Variable needs to know <code>T</code> so could it <code>delete&lt;T&gt;(ptr)</code> and so could <code>Variable::Get</code> checks the expected type and the saved object's type.</p>
<p>We save <code>T</code> in <code>PlaceholderImpl</code>, the implementation of <code>Placeholder</code>.  Please be aware that <code>PlaceholderImpl</code> is a class template and <code>T</code> is passed in as a template parameter.</p>
<p>Because <code>PlaceholderImpl</code> knows <code>T</code>, it can save and return <code>typeid(T)</code> for the type comparison in <code>Variable::Get</code> and <code>Variable::GetMutable</code>.</p>
<h2>Conclusion</h2>
<p>The technique type hiding utilizes C++ class templates, interface and derivation, and C++ RTTI (typeid).  This combination saves us from defining something like <code>caffe2::TypeMeta</code>, which takes hundreds of lines of C++ code.</p>
{% endverbatim %}
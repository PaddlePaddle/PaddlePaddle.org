{% verbatim %}
<h1>Design Doc: Execute the Program with Multi CPU</h1>
<h2>Abstract</h2>
<p>This Design Doc propose an approach to make the user-defined Op graph
running with multi-CPU, we will use an auto transpiler to convert the user-defined
Op graph to a multi-CPU Op graph, and run <code>ParallelDo</code> Op to run the graph.</p>
<h2>Transpiler</h2>
<p><img src="https://raw.githubusercontent.com/PaddlePaddle/Paddle/develop/doc/fluid/images/single-thread@3x.png" width="300"></p>
<p>After converted:</p>
<p><img src="https://raw.githubusercontent.com/PaddlePaddle/Paddle/develop/doc/fluid/images/multi-threads@3x.png" width="1000"></p>
<h2>Implement</h2>
<ul>
<li><code>Multi-CPU Transpiler</code> will convert the graph to a multi-CPU graph
  which would be executed with multi-threads.</li>
<li><code>BlockingCounter</code> will <code>Init/Decrement</code> an atomic counter, and Blocking <code>Wait</code>
  for the atomic counter become <code>0</code>:
  <div class="highlight"><pre><span></span><span class="n">BlockingCounter</span> <span class="nf">bc</span><span class="p">(</span><span class="n">thread_count</span><span class="p">);</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">thread_count</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">thread_pool</span><span class="o">-&gt;</span><span class="n">Start</span><span class="p">([</span><span class="o">&amp;</span><span class="n">bc</span><span class="p">]</span> <span class="p">{</span><span class="n">bc</span><span class="p">.</span><span class="n">DecrementCount</span><span class="p">();</span> <span class="p">})</span>
<span class="p">}</span>
<span class="n">bc</span><span class="p">.</span><span class="n">Wait</span><span class="p">();</span>
</pre></div></li>
<li><code>ParallelDo</code> Operator</li>
<li>Initialize a thread pool which is a Singleton.</li>
<li>Use a block id as the input, and create run the specify Block on independent scope
    with multi-threads.</li>
<li>Initialize a <code>BlockingCounter</code> instance and wait until all threads are done.</li>
<li><code>Split</code> Operator will split the Input Tensor into a TensorArray.</li>
<li><code>Merge</code> merge all the gradients which calculated in different threads
  with <code>mean/sum/max/min...</code> method, and then run the Optimizer Op to optimize <code>W</code>.</li>
</ul>
<h2>TODO</h2>
<ul>
<li>Improve the optimizer stage with multi-threads, since we could
  assign the parameters to the different threads and execute
  optimizer with multi-threads.</li>
</ul>
{% endverbatim %}
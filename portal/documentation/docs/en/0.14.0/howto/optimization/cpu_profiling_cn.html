<html><body><p>{% verbatim %}
</p><p>此教程会介绍如何使用Python的cProfile包、Python库yep、Google perftools来进行性能分析 (profiling) 与调优（performance tuning）。</p>
<p>Profling 指发现性能瓶颈。系统中的瓶颈可能和程序员开发过程中想象的瓶颈相去甚远。Tuning 指消除瓶颈。性能优化的过程通常是不断重复地 profiling 和 tuning。</p>
<p>PaddlePaddle 用户一般通过调用 Python API 编写深度学习程序。大部分 Python API 调用用 C++ 写的 libpaddle.so。所以 PaddlePaddle 的性能分析与调优分为两个部分:</p>
<ul>
<li>Python 代码的性能分析</li>
<li>Python 与 C++ 混合代码的性能分析</li>
</ul>
<h1>Python代码的性能分析</h1>
<h3>生成性能分析文件</h3>
<p>Python标准库中提供了性能分析的工具包，<a href="https://docs.python.org/2/library/profile.html">cProfile</a>。生成Python性能分析的命令如下:</p>
<div class="highlight"><pre><span></span>python -m cProfile -o profile.out main.py
</pre></div>
<p>其中 <code>main.py</code> 是我们要分析的程序，<code>-o</code>标识了一个输出的文件名，用来存储本次性能分析的结果。如果不指定这个文件，<code>cProfile</code>会打印到标准输出。</p>
<h3>查看性能分析文件</h3>
<p><code>cProfile</code> 在main.py 运行完毕后输出<code>profile.out</code>。我们可以使用<a href="https://github.com/ymichael/cprofilev"><code>cprofilev</code></a>来查看性能分析结果。<code>cprofilev</code>是一个Python的第三方库。使用它会开启一个HTTP服务，将性能分析结果以网页的形式展示出来：</p>
<div class="highlight"><pre><span></span>cprofilev -a <span class="m">0</span>.0.0.0 -p <span class="m">3214</span> -f profile.out main.py
</pre></div>
<p>其中<code>-a</code>标识HTTP服务绑定的IP。使用<code>0.0.0.0</code>允许外网访问这个HTTP服务。<code>-p</code>标识HTTP服务的端口。<code>-f</code>标识性能分析的结果文件。<code>main.py</code>标识被性能分析的源文件。</p>
<p>用Web浏览器访问对应网址，即可显示性能分析的结果：</p>
<div class="highlight"><pre><span></span>   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.284    0.284   29.514   29.514 main.py:1(&lt;module&gt;)
     4696    0.128    0.000   15.748    0.003 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/executor.py:20(run)
     4696   12.040    0.003   12.040    0.003 {built-in method run}
        1    0.144    0.144    6.534    6.534 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/v2/__init__.py:14(&lt;module&gt;)
</pre></div>
<p>每一列的含义是:</p>
<table>
<thead>
<tr>
<th>列名</th>
<th>含义 </th>
</tr>
</thead>
<tbody>
<tr>
<td> ncalls</td>
<td> 函数的调用次数</td>
</tr>
<tr>
<td>tottime</td>
<td> 函数实际使用的总时间。该时间去除掉本函数调用其他函数的时间</td>
</tr>
<tr>
<td> percall </td>
<td> tottime的每次调用平均时间</td>
</tr>
<tr>
<td> cumtime</td>
<td> 函数总时间。包含这个函数调用其他函数的时间</td>
</tr>
<tr>
<td> percall</td>
<td> cumtime的每次调用平均时间</td>
</tr>
<tr>
<td> filename:lineno(function) </td>
<td> 文件名, 行号，函数名 </td>
</tr>
</tbody>
</table>
<h3>寻找性能瓶颈</h3>
<p>通常<code>tottime</code>和<code>cumtime</code>是寻找瓶颈的关键指标。这两个指标代表了某一个函数真实的运行时间。</p>
<p>将性能分析结果按照tottime排序，效果如下:</p>
<div class="highlight"><pre><span></span>     4696   12.040    0.003   12.040    0.003 {built-in method run}
   300005    0.874    0.000    1.681    0.000 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/v2/dataset/mnist.py:38(reader)
   107991    0.676    0.000    1.519    0.000 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:219(__init__)
     4697    0.626    0.000    2.291    0.000 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:428(sync_with_cpp)
        1    0.618    0.618    0.618    0.618 /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/__init__.py:1(&lt;module&gt;)
</pre></div>
<p>可以看到最耗时的函数是C++端的<code>run</code>函数。这需要联合我们第二节<code>Python</code>与<code>C++</code>混合代码的性能分析来进行调优。而<code>sync_with_cpp</code>函数的总共耗时很长，每次调用的耗时也很长。于是我们可以点击<code>sync_with_cpp</code>的详细信息，了解其调用关系。</p>
<div class="highlight"><pre><span></span>Called By:

   Ordered by: internal time
   List reduced from 4497 to 2 due to restriction &lt;'sync_with_cpp'&gt;

Function                                                                                                 was called by...
                                                                                                             ncalls  tottime  cumtime
/home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:428(sync_with_cpp)  &lt;-    4697    0.626    2.291  /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:562(sync_with_cpp)
/home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:562(sync_with_cpp)  &lt;-    4696    0.019    2.316  /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:487(clone)
                                                                                                                  1    0.000    0.001  /home/yuyang/perf_test/.env/lib/python2.7/site-packages/paddle/fluid/framework.py:534(append_backward)


Called:

   Ordered by: internal time
   List reduced from 4497 to 2 due to restriction &lt;'sync_with_cpp'&gt;
</pre></div>
<p>通常观察热点函数间的调用关系，和对应行的代码，就可以了解到问题代码在哪里。当我们做出性能修正后，再次进行性能分析(profiling)即可检查我们调优后的修正是否能够改善程序的性能。</p>
<h2>Python与C++混合代码的性能分析</h2>
<h3>生成性能分析文件</h3>
<p>C++的性能分析工具非常多。常见的包括<code>gprof</code>, <code>valgrind</code>, <code>google-perftools</code>。但是调试Python中使用的动态链接库与直接调试原始二进制相比增加了很多复杂度。幸而Python的一个第三方库<code>yep</code>提供了方便的和<code>google-perftools</code>交互的方法。于是这里使用<code>yep</code>进行Python与C++混合代码的性能分析</p>
<p>使用<code>yep</code>前需要安装<code>google-perftools</code>与<code>yep</code>包。ubuntu下安装命令为</p>
<div class="highlight"><pre><span></span>apt update
apt install libgoogle-perftools-dev
pip install yep
</pre></div>
<p>安装完毕后，我们可以通过</p>
<div class="highlight"><pre><span></span>python -m yep -v main.py
</pre></div>
<p>生成性能分析文件。生成的性能分析文件为<code>main.py.prof</code>。</p>
<p>命令行中的<code>-v</code>指定在生成性能分析文件之后，在命令行显示分析结果。我们可以在命令行中简单的看一下生成效果。因为C++与Python不同，编译时可能会去掉调试信息，运行时也可能因为多线程产生混乱不可读的性能分析结果。为了生成更可读的性能分析结果，可以采取下面几点措施:</p>
<ol>
<li>编译时指定<code>-g</code>生成调试信息。使用cmake的话，可以将CMAKE_BUILD_TYPE指定为<code>RelWithDebInfo</code>。</li>
<li>编译时一定要开启优化。单纯的<code>Debug</code>编译性能会和<code>-O2</code>或者<code>-O3</code>有非常大的差别。<code>Debug</code>模式下的性能测试是没有意义的。</li>
<li>运行性能分析的时候，先从单线程开始，再开启多线程，进而多机。毕竟单线程调试更容易。可以设置<code>OMP_NUM_THREADS=1</code>这个环境变量关闭openmp优化。</li>
</ol>
<h3>查看性能分析文件</h3>
<p>在运行完性能分析后，会生成性能分析结果文件。我们可以使用<a href="https://github.com/google/pprof"><code>pprof</code></a>来显示性能分析结果。注意，这里使用了用<code>Go</code>语言重构后的<code>pprof</code>，因为这个工具具有web服务界面，且展示效果更好。</p>
<p>安装<code>pprof</code>的命令和一般的<code>Go</code>程序是一样的，其命令如下:</p>
<div class="highlight"><pre><span></span>go get github.com/google/pprof
</pre></div>
<p>进而我们可以使用如下命令开启一个HTTP服务:</p>
<div class="highlight"><pre><span></span>pprof -http<span class="o">=</span><span class="m">0</span>.0.0.0:3213 <span class="sb">`</span>which python<span class="sb">`</span>  ./main.py.prof
</pre></div>
<p>这行命令中，<code>-http</code>指开启HTTP服务。<code>which python</code>会产生当前Python二进制的完整路径，进而指定了Python可执行文件的路径。<code>./main.py.prof</code>输入了性能分析结果。</p>
<p>访问对应的网址，我们可以查看性能分析的结果。结果如下图所示:</p>
<p><img alt="result" src="../../../../_images/pprof_1.png"/></p>
<h3>寻找性能瓶颈</h3>
<p>与寻找Python代码的性能瓶颈类似，寻找Python与C++混合代码的性能瓶颈也是要看<code>tottime</code>和<code>cumtime</code>。而<code>pprof</code>展示的调用图也可以帮助我们发现性能中的问题。</p>
<p>例如下图中，</p>
<p><img alt="kernel_perf" src="../../../../_images/pprof_2.png"/></p>
<p>在一次训练中，乘法和乘法梯度的计算占用2%-4%左右的计算时间。而<code>MomentumOp</code>占用了17%左右的计算时间。显然，<code>MomentumOp</code>的性能有问题。</p>
<p>在<code>pprof</code>中，对于性能的关键路径都做出了红色标记。先检查关键路径的性能问题，再检查其他部分的性能问题，可以更有次序的完成性能的优化。</p>
{% endverbatim %}</body></html>
{% verbatim %}
<h1>Cluster Training Benchmark</h1>
<h2>Setup</h2>
<ul>
<li>Platform</li>
<li>Kubernetes: v1.6.2</li>
<li>
<p>Linux Kernel: v3.10.0</p>
</li>
<li>
<p>Resource</p>
</li>
<li>CPU: 10 Cores per Pod</li>
<li>
<p>Memory: 5GB per Pod</p>
</li>
<li>
<p>Docker Image</p>
</li>
</ul>
<p>We use different base Docker Image to run the benchmark on Kubernetes:
  - PaddlePaddle v2: paddlepaddle/paddle:0.11.0
  - PaddlePaddle Fluid: paddlepaddle/paddle:[commit-id]
  - TensorFlow: tensorflow/tensorflow:1.5.0-rc0</p>
<ul>
<li>Model
  vgg16 is used in this benchmark.</li>
</ul>
<h2>Cases</h2>
<ul>
<li>Variable</li>
<li>Batch Size of training data.</li>
<li>PServer count of the training job.</li>
<li>
<p>The number of trainers.</p>
</li>
<li>
<p>Invariant</p>
</li>
<li>The resource of trainer/pserver Pod.</li>
</ul>
<h3>Measure the Performance for Different Batch Size</h3>
<ul>
<li>PServer Count: 40</li>
<li>Trainer Count: 100</li>
<li>Metrics: mini-batch / sec</li>
</ul>
<table>
<thead>
<tr>
<th>Batch Size </th>
<th> 32</th>
<th>64</th>
<th>128 </th>
<th>256</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td>-</td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
<tr>
<td>PaddlePaddle v2  </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
<tr>
<td>TensorFlow </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
</tbody>
</table>

<h3>Measure the Performance for Different PServer Count</h3>
<ul>
<li>Trainer Count: 100</li>
<li>Batch Size: 64</li>
<li>Metrics: mini-batch / sec</li>
</ul>
<table>
<thead>
<tr>
<th>PServer Count  </th>
<th>10</th>
<th>20</th>
<th>40 </th>
<th>60</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td>-</td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
<tr>
<td>PaddlePaddle v2  </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
<tr>
<td>TensorFlow </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
</tr>
</tbody>
</table>

<h3>Measure Parallel Efficiency By Increasing Trainer Count</h3>
<ul>
<li>PServer Count: 20</li>
<li>Batch Size: 64</li>
<li>Metrics:</li>
</ul>
<p>$S = div(T1, TN)$</p>
<p>which S is the ratio of T1 over TN, training time of 1 and N trainers.
The parallel efficiency is:</p>
<p>$E = div(S, N)$</p>
<table>
<thead>
<tr>
<th>Trainer Counter  </th>
<th>1</th>
<th>10</th>
<th>20 </th>
<th>30</th>
<th>40</th>
<th>50</th>
<th>60 </th>
<th>70</th>
<th>80</th>
<th>90</th>
<th>100 </th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td>-</td>
<td>- </td>
<td>- </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
</tr>
<tr>
<td>PaddlePaddle v2  </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
</tr>
<tr>
<td>TensorFlow </td>
<td>-  </td>
<td>- </td>
<td>-  </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
<td>- </td>
<td>-</td>
<td>- </td>
<td>- </td>
</tr>
</tbody>
</table>

<h2>Reproduce the benchmark</h2>
<p>TODO</p>
{% endverbatim %}
{% verbatim %}
<h1>Performance for Distributed vgg16</h1>
<h2>Test Result</h2>
<h3>Hardware Infomation</h3>
<ul>
<li>CPU: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz</li>
<li>cpu MHz       : 2101.000</li>
<li>cache size    : 20480 KB</li>
</ul>
<h3>Blas settings</h3>
<p>Setting environment variable: <code>MKL_NUM_THREADS=1</code>.</p>
<h3>Single Node Single Thread</h3>
<ul>
<li>Metrics: samples / sec</li>
</ul>
<table>
<thead>
<tr>
<th>Batch Size </th>
<th> 32</th>
<th>64</th>
<th>128 </th>
<th>256</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td> 15.44 </td>
<td> 16.32 </td>
<td> 16.74 </td>
<td> 16.79 </td>
</tr>
<tr>
<td>PaddlePaddle v2  </td>
<td> 15.97 </td>
<td> 17.04 </td>
<td> 17.60 </td>
<td> 17.83 </td>
</tr>
<tr>
<td>TensorFlow </td>
<td> 9.09 </td>
<td> 9.10 </td>
<td> 9.24 </td>
<td> 8.66 </td>
</tr>
</tbody>
</table>

<h3>Different Batch Size</h3>
<ul>
<li>PServer Count: 10</li>
<li>Trainer Count: 20</li>
<li>Metrics: samples / sec</li>
</ul>
<table>
<thead>
<tr>
<th>Batch Size </th>
<th> 32</th>
<th>64</th>
<th>128 </th>
<th>256</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td> 190.20 </td>
<td> 222.15 </td>
<td> 247.40 </td>
<td> 258.18 </td>
</tr>
<tr>
<td>PaddlePaddle v2  </td>
<td> 170.96 </td>
<td> 233.71 </td>
<td> 256.14 </td>
<td> 329.23 </td>
</tr>
<tr>
<td>TensorFlow </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
</tr>
</tbody>
</table>

<h3>Accelerate Rate</h3>
<ul>
<li>Pserver Count: 20</li>
<li>Batch Size: 128</li>
<li>Metrics: samples / sec</li>
</ul>
<table>
<thead>
<tr>
<th>Trainer Count </th>
<th>20</th>
<th>40</th>
<th>80</th>
<th>100</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid</td>
<td> 263.29 (78.64%) </td>
<td> 518.80 (77.47%) </td>
<td> 836.26 (62.44%) </td>
<td> 1019.29 (60.89%) </td>
</tr>
<tr>
<td>PaddlePaddle v2 (need more tests)   </td>
<td> 326.85 (92.85%) </td>
<td> 534.58 (75.93%) </td>
<td> 853.30 (60.60%) </td>
<td> 1041.99 (59.20%) </td>
</tr>
<tr>
<td>TensorFlow </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
</tr>
</tbody>
</table>

<h3>Different Pserver Count</h3>
<ul>
<li>Trainer Count: 60</li>
<li>Batch Size: 128</li>
<li>Metrics: samples/ sec</li>
</ul>
<table>
<thead>
<tr>
<th>PServer Count </th>
<th>3</th>
<th>6</th>
<th>10</th>
<th>20</th>
</tr>
</thead>
<tbody>
<tr>
<td> PaddlePaddle Fluid(should fix in next PR) </td>
<td> 589.1 </td>
<td> 592.6 </td>
<td> 656.4 </td>
<td> 655.8 </td>
</tr>
<tr>
<td>PaddlePaddle v2 (need more tests)   </td>
<td> 593.4 </td>
<td> 791.3 </td>
<td> 729.7 </td>
<td> 821.7 </td>
</tr>
<tr>
<td>TensorFlow </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
</tr>
</tbody>
</table>

<p><em>The performance gap between Fuild and v2 comes from the network interference.</em></p>
<h2>Steps to Run the Performance Test</h2>
<ol>
<li>You must re-compile PaddlePaddle and enable <code>-DWITH_DISTRIBUTE</code> to build PaddlePaddle with distributed support.</li>
<li>When the build finishes, copy the output <code>whl</code> package located under <code>build/python/dist</code> to current directory.</li>
<li>Run <code>docker build -t [image:tag] .</code> to build the docker image and run <code>docker push [image:tag]</code> to push the image to reponsitory so kubernetes can find it.</li>
<li>Run <code>kubectl create -f pserver.yaml &amp;&amp; kubectl create -f trainer.yaml</code> to start the job on your kubernetes cluster (you must configure the <code>kubectl</code> client before this step).</li>
<li>Run <code>kubectl get po</code> to get running pods, and run <code>kubectl logs [podID]</code> to fetch the pod log of pservers and trainers.</li>
</ol>
<p>Check the logs for the distributed training progress and analyze the performance.</p>
<h2>Enable Verbos Logs</h2>
<p>Edit <code>pserver.yaml</code> and <code>trainer.yaml</code> and add an environment variable <code>GLOG_v=3</code> and <code>GLOG_logtostderr=1</code> to see what happend in detail.</p>
{% endverbatim %}
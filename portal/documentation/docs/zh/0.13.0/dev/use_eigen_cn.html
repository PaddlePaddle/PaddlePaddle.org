{% verbatim %}
<h1>在Paddle中如何使用Eigen</h1>
<p>神经网络本质上是一个计算图，计算需要的数据存放在<code>Tensor</code>中，而计算过程是由<code>Operartor</code>来描述的。在执行时，<code>Operator</code>调用对应<code>OpKernel</code>中的<code>Compute</code>接口，实现对<code>Tensor</code>的操作。</p>
<h2>Eigen Tensor模块</h2>
<p>Eigen Tensor模块对element-wise计算提供了强大的支持，并且书写一份代码，可以同时在CPU、GPU执行。但Eigen Tensor是一个正在开发中的模块，因此可能测试不够完备，文档较少。</p>
<p>关于Eigen Tensor模块的详细介绍请参考<a href="https://github.com/RLovelett/eigen/blob/master/unsupported/Eigen/CXX11/src/Tensor/README.md">文档1</a> 和<a href="https://bitbucket.org/eigen/eigen/src/default/unsupported/Eigen/CXX11/src/Tensor/README.md">文档2</a></p>
<h2>paddle::framework::Tensor</h2>
<p>Paddle Tensor定义在framework目录下，其主要接口如下：</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Tensor</span> <span class="p">{</span>
 <span class="k">public</span><span class="o">:</span>
  <span class="cm">/*! Return a pointer to mutable memory block. */</span>
  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
  <span class="kr">inline</span> <span class="n">T</span><span class="o">*</span> <span class="n">data</span><span class="p">();</span>

  <span class="cm">/**</span>
<span class="cm">   * @brief   Return a pointer to mutable memory block.</span>
<span class="cm">   * @note    If not exist, then allocation.</span>
<span class="cm">   */</span>
  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
  <span class="kr">inline</span> <span class="n">T</span><span class="o">*</span> <span class="n">mutable_data</span><span class="p">(</span><span class="n">platform</span><span class="o">::</span><span class="n">Place</span> <span class="n">place</span><span class="p">);</span>

  <span class="cm">/**</span>
<span class="cm">   * @brief     Return a pointer to mutable memory block.</span>
<span class="cm">   *</span>
<span class="cm">   * @param[in] dims    The dimensions of the memory block.</span>
<span class="cm">   * @param[in] place   The place of the memory block.</span>
<span class="cm">   *</span>
<span class="cm">   * @note      If not exist, then allocation.</span>
<span class="cm">   */</span>
  <span class="k">template</span> <span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
  <span class="kr">inline</span> <span class="n">T</span><span class="o">*</span> <span class="n">mutable_data</span><span class="p">(</span><span class="n">DDim</span> <span class="n">dims</span><span class="p">,</span> <span class="n">platform</span><span class="o">::</span><span class="n">Place</span> <span class="n">place</span><span class="p">);</span>

  <span class="cm">/*! Resize the dimensions of the memory block. */</span>
  <span class="kr">inline</span> <span class="n">Tensor</span><span class="o">&amp;</span> <span class="n">Resize</span><span class="p">(</span><span class="k">const</span> <span class="n">DDim</span><span class="o">&amp;</span> <span class="n">dims</span><span class="p">);</span>

  <span class="cm">/*! Return the dimensions of the memory block. */</span>
  <span class="kr">inline</span> <span class="k">const</span> <span class="n">DDim</span><span class="o">&amp;</span> <span class="n">dims</span><span class="p">()</span> <span class="k">const</span><span class="p">;</span>

 <span class="k">private</span><span class="o">:</span>  
  <span class="cm">/*! holds the memory block if allocated. */</span>
  <span class="n">std</span><span class="o">::</span><span class="n">shared_ptr</span><span class="o">&lt;</span><span class="n">Placeholder</span><span class="o">&gt;</span> <span class="n">holder_</span><span class="p">;</span>

  <span class="cm">/*! points to dimensions of memory block. */</span>
  <span class="n">DDim</span> <span class="n">dim_</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>

<p><code>Placeholder</code>的作用是延迟分配内存，即我们可以先定义一个Tensor，然后使用Resize接口设置Tensor的大小，最后再调用mutable_data接口分配实际的内存。</p>
<div class="highlight"><pre><span></span><span class="n">paddle</span><span class="o">::</span><span class="n">framework</span><span class="o">::</span><span class="n">Tensor</span> <span class="n">t</span><span class="p">;</span>
<span class="n">paddle</span><span class="o">::</span><span class="n">platform</span><span class="o">::</span><span class="n">CPUPlace</span> <span class="n">place</span><span class="p">;</span>
<span class="c1">// set size first</span>
<span class="n">t</span><span class="p">.</span><span class="n">Resize</span><span class="p">({</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">});</span>
<span class="c1">// allocate memory on CPU later</span>
<span class="n">t</span><span class="p">.</span><span class="n">mutable_data</span><span class="p">(</span><span class="n">place</span><span class="p">);</span>
</pre></div>

<h3>paddle::framework::Tensor使用样例</h3>
<p>下面以AddOp为例说明Tensor的使用过程：</p>
<ul>
<li>InferShape</li>
</ul>
<p>在运行神经网络计算图时，我们先调用每个<code>Operator</code>的<code>InferShape</code>接口，根据输入Tensor的大小来设置输出Tensor的大小，<code>Resize</code>接口会被调用。</p>
<div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">InferShape</span><span class="p">(</span><span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">InferShapeContext</span> <span class="o">&amp;</span><span class="n">ctx</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
  <span class="n">PADDLE_ENFORCE_EQ</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">dims</span><span class="p">(),</span>
                    <span class="n">ctx</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">dims</span><span class="p">(),</span>
                    <span class="s">&quot;Two input of Add Op&#39;s dimension must be same.&quot;</span><span class="p">);</span>
  <span class="n">ctx</span><span class="p">.</span><span class="n">Output</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Resize</span><span class="p">(</span><span class="n">ctx</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">dims</span><span class="p">());</span>
<span class="p">}</span>
</pre></div>

<ul>
<li>Run</li>
</ul>
<p><code>Operator</code>的<code>Run</code>接口最终会调用对应<code>OpKernel</code>的<code>Compute</code>接口，在这时真正的分配内存，<code>mutable_data</code>接口会被调用。</p>
<div class="highlight"><pre><span></span><span class="kt">void</span> <span class="nf">Compute</span><span class="p">(</span><span class="k">const</span> <span class="n">framework</span><span class="o">::</span><span class="n">ExecutionContext</span><span class="o">&amp;</span> <span class="n">context</span><span class="p">)</span> <span class="k">const</span> <span class="k">override</span> <span class="p">{</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">input0</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;X&quot;</span><span class="p">);</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">input1</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Input</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Y&quot;</span><span class="p">);</span>
  <span class="k">auto</span><span class="o">*</span> <span class="n">output</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">Output</span><span class="o">&lt;</span><span class="n">Tensor</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&quot;Out&quot;</span><span class="p">);</span>

  <span class="n">output</span><span class="o">-&gt;</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">(</span><span class="n">context</span><span class="p">.</span><span class="n">GetPlace</span><span class="p">());</span>

  <span class="k">auto</span> <span class="n">x</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">input0</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">y</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">input1</span><span class="p">);</span>
  <span class="k">auto</span> <span class="n">z</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">output</span><span class="p">);</span>

  <span class="k">auto</span> <span class="n">place</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">GetEigenDevice</span><span class="o">&lt;</span><span class="n">Place</span><span class="o">&gt;</span><span class="p">();</span>

  <span class="n">z</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">place</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>

<h3>paddle::framework::Tensor到EigenTensor的转换</h3>
<p>如上一小节所示，在具体的计算中，我们需要先把输入Tensor和输出Tensor转换为Eigen支持的格式。我们在<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/framework/eigen.h">eigen.h</a>中提供了一些全局函数用来实现paddle::framework::Tensor到EigenTensor/EigenMatrix/EigenVector/EigenScalar的转换。</p>
<p>以EigenTensor为例，做一个介绍</p>
<div class="highlight"><pre><span></span><span class="n">Tensor</span> <span class="n">t</span><span class="p">;</span>
<span class="kt">float</span><span class="o">*</span> <span class="n">p</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="n">mutable_data</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">make_ddim</span><span class="p">({</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">}),</span> <span class="n">platform</span><span class="o">::</span><span class="n">CPUPlace</span><span class="p">());</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">3</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<span class="p">}</span>

<span class="n">EigenTensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">3</span><span class="o">&gt;::</span><span class="n">Type</span> <span class="n">et</span> <span class="o">=</span> <span class="n">EigenTensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span> <span class="mi">3</span><span class="o">&gt;::</span><span class="n">From</span><span class="p">(</span><span class="n">t</span><span class="p">);</span>
</pre></div>

<p>From是EigenTensor模板提供的一个接口，可以实现从paddle::framework::Tensor到对EigenTensor的转换。由于Tensor的rank是模板参数，因此在转换时需要显示的指定。</p>
<p>在Eigen中，不同rank的Tensor是不同类型，Vector是rank为1的Tensor。需要额外注意的是，EigenVector<T>::From方法是把paddle中的一维Tensor转为Eigen的一维Tensor，在这里用EigenVector来表示；而EigenVector<T>::Flatten方法是把paddle中的一个Tensor进行reshape操作，压扁成为Eigen的一维Tensor，类型仍然为EigenVector。</p>
<p>更多的转换方法请参考eigen_test.cc中的<a href="https://github.com/PaddlePaddle/Paddle/blob/develop/paddle/fluid/framework/eigen_test.cc">单元测试</a>。</p>
<h2>实现计算</h2>
<p>当需要完成计算时，我们需要等式左边的EigenTensor调用device接口。在这里需要注意的是，这里的EigenTensor之间的运算只是改变了原有Tensor中的数据，而不会改变原有Tensor的shape信息。</p>
<div class="highlight"><pre><span></span><span class="k">auto</span> <span class="n">x</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">input0</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">y</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">input1</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">z</span> <span class="o">=</span> <span class="n">EigenVector</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">Flatten</span><span class="p">(</span><span class="o">*</span><span class="n">output</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">place</span> <span class="o">=</span> <span class="n">context</span><span class="p">.</span><span class="n">GetEigenDevice</span><span class="o">&lt;</span><span class="n">Place</span><span class="o">&gt;</span><span class="p">();</span>
<span class="n">z</span><span class="p">.</span><span class="n">device</span><span class="p">(</span><span class="n">place</span><span class="p">)</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="p">;</span>
</pre></div>

<p>在这段代码中，input0/input1/output可以是任意维度的Tensor。我们调用了EigenVector的Flatten接口，把任意维度的Tensor转为了一维的EigenVector。而在计算结束之后，input0/input1/output的原有shape信息不变。如果想改变原有Tensor的shape信息，可以调用Resize接口进行改变。</p>
<p>由于Eigen Tensor模块的文档较少，我们可以参考TensorFlow的<a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/core/kernels">kernels</a>模块下的相关<code>OpKernel</code>的计算代码。</p>
{% endverbatim %}
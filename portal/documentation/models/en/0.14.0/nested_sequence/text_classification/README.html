{% verbatim %}
<p>运行本目录下的程序示例需要使用PaddlePaddle v0.11.0 版本。如果您的PaddlePaddle安装版本低于此要求，请按照<a href="http://www.paddlepaddle.org/docs/develop/documentation/zh/build_and_install/pip_install_cn.html">安装文档</a>中的说明更新PaddlePaddle安装版本。</p>
<hr/>
<h1>基于双层序列的文本分类</h1>
<h2>简介</h2>
<p>本例将演示如何在 PaddlePaddle 中将长文本输入（通常能达到段落或者篇章基本）组织为双层序列，完成对长文本的分类任务。</p>
<h2>模型介绍</h2>
<p>我们将一段文本看成句子的序列，而每个句子又是词语的序列。</p>
<p>我们首先用卷积神经网络编码段落中的每一句话；然后，将每句话的表示向量经过池化层得到段落的编码向量；最后将段落的编码向量作为分类器（以softmax层的全连接层）输入，得到最终的分类结果。</p>
<p><strong>模型结构如下图所示</strong>
</p><p align="center">
<img align="center" src="images/model.jpg" width="60%"/><br/>
图1. 基于双层序列的文本分类模型
</p>
<p>PaddlePaddle 实现该网络结构的代码见 <code>network_conf.py</code>。</p>
<p>对双层时间序列的处理，需要先将双层时间序列数据变换成单层时间序列数据，再对每一个单层时间序列进行处理。 在 PaddlePaddle 中 ，<code>recurrent_group</code> 是帮助我们构建处理双层序列的层次化模型的主要工具。这里，我们使用两个嵌套的 <code>recurrent_group</code> 。外层的 <code>recurrent_group</code> 将段落拆解为句子，<code>step</code> 函数中拿到的输入是句子序列；内层的 <code>recurrent_group</code> 将句子拆解为词语，<code>step</code> 函数中拿到的输入是非序列的词语。</p>
<p>在词语级别，我们通过 CNN 网络以词向量为输入输出学习到的句子表示；在段落级别，将每个句子的表示通过池化作用得到段落表示。</p>
<div class="highlight"><pre><span></span><span class="n">nest_group</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">recurrent_group</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">SubsequenceInput</span><span class="p">(</span><span class="n">emb</span><span class="p">),</span>
                                                 <span class="n">hidden_size</span><span class="p">],</span>
                                          <span class="n">step</span><span class="o">=</span><span class="n">cnn_cov_group</span><span class="p">)</span>
</pre></div>
<p>拆解后的单层序列数据经过一个CNN网络学习对应的向量表示，CNN的网络结构包含以下部分：</p>
<ul>
<li><strong>卷积层</strong>： 文本分类中的卷积在时间序列上进行，卷积核的宽度和词向量层产出的矩阵一致，卷积后得到的结果为“特征图”， 使用多个不同高度的卷积核，可以得到多个特征图。本例代码默认使用了大小为 3（图1红色框）和 4（图1蓝色框）的卷积核。</li>
<li><strong>最大池化层</strong>： 对卷积得到的各个特征图分别进行最大池化操作。由于特征图本身已经是向量，因此最大池化实际上就是选出各个向量中的最大元素。将所有最大元素又被拼接在一起，组成新的向量。</li>
<li><strong>线性投影层</strong>： 将不同卷积得到的结果经过最大池化层之后拼接为一个长向量， 然后经过一个线性投影得到对应单层序列的表示向量。</li>
</ul>
<p>CNN网络具体代码实现如下：
</p><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">cnn_cov_group</span><span class="p">(</span><span class="n">group_input</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Convolution group definition.</span>
<span class="sd">    :param group_input: The input of this layer.</span>
<span class="sd">    :type group_input: LayerOutput</span>
<span class="sd">    :params hidden_size: The size of the fully connected layer.</span>
<span class="sd">    :type hidden_size: int</span>
<span class="sd">    """</span>
    <span class="n">conv3</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">sequence_conv_pool</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">group_input</span><span class="p">,</span> <span class="n">context_len</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>
    <span class="n">conv4</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">sequence_conv_pool</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">group_input</span><span class="p">,</span> <span class="n">context_len</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">)</span>

    <span class="n">linear_proj</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">conv3</span><span class="p">,</span> <span class="n">conv4</span><span class="p">],</span>
                                  <span class="n">size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
                                  <span class="n">param_attr</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">attr</span><span class="o">.</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'_cov_value_weight'</span><span class="p">),</span>
                                  <span class="n">bias_attr</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">attr</span><span class="o">.</span><span class="n">ParamAttr</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'_cov_value_bias'</span><span class="p">),</span>
                                  <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">linear_proj</span>
</pre></div>
PaddlePaddle 中已经封装好的带有池化的文本序列卷积模块：<code>paddle.networks.sequence_conv_pool</code>，可直接调用。
<p>在得到每个句子的表示向量之后， 将所有句子表示向量经过一个平均池化层， 得到一个样本的向量表示， 向量经过一个全连接层输出最终的预测结果。 代码如下：
</p><div class="highlight"><pre><span></span><span class="n">avg_pool</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">pooling</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">nest_group</span><span class="p">,</span>
                                <span class="n">pooling_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">Avg</span><span class="p">(),</span>
                                <span class="n">agg_level</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">AggregateLevel</span><span class="o">.</span><span class="n">TO_NO_SEQUENCE</span><span class="p">)</span>

<span class="n">prob</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">mixed</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">class_num</span><span class="p">,</span>
                          <span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">full_matrix_projection</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">avg_pool</span><span class="p">)],</span>
                          <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
</pre></div>
<h2>安装依赖包</h2>
<div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
<h2>指定训练配置参数</h2>
<p>通过 <code>config.py</code> 脚本修改训练和模型配置参数，脚本中有对可配置参数的详细解释，示例如下：
</p><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">TrainerConfig</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="c1"># whether to use GPU for training</span>
    <span class="n">use_gpu</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="c1"># the number of threads used in one machine</span>
    <span class="n">trainer_count</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># train batch size</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>

    <span class="o">...</span>


<span class="k">class</span> <span class="nc">ModelConfig</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="c1"># embedding vector dimension</span>
    <span class="n">emb_size</span> <span class="o">=</span> <span class="mi">28</span>

    <span class="o">...</span>
</pre></div>
修改 <code>config.py</code> 对参数进行调整。例如，通过修改 <code>use_gpu</code> 参数来指定是否使用 GPU 进行训练。
<h2>使用 PaddlePaddle 内置数据运行</h2>
<h3>训练</h3>
<p>在终端执行：
</p><div class="highlight"><pre><span></span>python train.py
</pre></div>
将以 PaddlePaddle 内置的情感分类数据集: <code>imdb</code> 运行本例。
<h3>预测</h3>
<p>训练结束后模型将存储在指定目录当中（默认models目录），在终端执行：
</p><div class="highlight"><pre><span></span>python infer.py --model_path <span class="s1">'models/params_pass_00000.tar.gz'</span>
</pre></div>
默认情况下，预测脚本将加载训练一个pass的模型对 <code>imdb的测试集</code> 进行测试。
<h2>使用自定义数据训练和预测</h2>
<h3>训练</h3>
<p>1.数据组织</p>
<p>输入数据格式如下：每一行为一条样本，以 <code>\t</code> 分隔，第一列是类别标签，第二列是输入文本的内容。以下是两条示例数据：</p>
<div class="highlight"><pre><span></span>positive        This movie is very good. The actor is so handsome.
negative        What a terrible movie. I waste so much time.
</pre></div>
<p>2.编写数据读取接口</p>
<p>自定义数据读取接口只需编写一个 Python 生成器实现<strong>从原始输入文本中解析一条训练样本</strong>的逻辑。以下代码片段实现了读取原始数据返回类型为： <code>paddle.data_type.integer_value_sub_sequence</code> 和 <code>paddle.data_type.integer_value</code>
</p><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_reader</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">word_dict</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Reader interface for training data</span>

<span class="sd">    :param data_dir: data directory</span>
<span class="sd">    :type data_dir: str</span>
<span class="sd">    :param word_dict: path of word dictionary,</span>
<span class="sd">        the dictionary must has a "UNK" in it.</span>
<span class="sd">    :type word_dict: Python dict</span>
<span class="sd">    :param label_dict: path of label dictionary.</span>
<span class="sd">    :type label_dict: Python dict</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="nf">reader</span><span class="p">():</span>
        <span class="n">UNK_ID</span> <span class="o">=</span> <span class="n">word_dict</span><span class="p">[</span><span class="s1">'&lt;unk&gt;'</span><span class="p">]</span>
        <span class="n">word_col</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">lbl_col</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">data_dir</span><span class="p">):</span>
            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">file_path</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s2">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="n">line_split</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">)</span>
                    <span class="n">doc</span> <span class="o">=</span> <span class="n">line_split</span><span class="p">[</span><span class="n">word_col</span><span class="p">]</span>
                    <span class="n">doc_ids</span> <span class="o">=</span> <span class="p">[]</span>
                    <span class="k">for</span> <span class="n">sent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">"."</span><span class="p">):</span>
                        <span class="n">sent_ids</span> <span class="o">=</span> <span class="p">[</span>
                            <span class="n">word_dict</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">UNK_ID</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">sent</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
                        <span class="k">if</span> <span class="n">sent_ids</span><span class="p">:</span>
                            <span class="n">doc_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sent_ids</span><span class="p">)</span>

                    <span class="k">yield</span> <span class="n">doc_ids</span><span class="p">,</span> <span class="n">label_dict</span><span class="p">[</span><span class="n">line_split</span><span class="p">[</span><span class="n">lbl_col</span><span class="p">]]</span>

    <span class="k">return</span> <span class="n">reader</span>
</pre></div>
需要注意的是， 本例中以英文句号<code>'.'</code>作为分隔符， 将一段文本分隔为一定数量的句子， 且每个句子表示为对应词表的索引数组（<code>sent_ids</code>）。 由于当前样本的表示(<code>doc_ids</code>)中包含了该段文本的所有句子， 因此，它的类型为：<code>paddle.data_type.integer_value_sub_sequence</code>。
<p>3.指定命令行参数进行训练</p>
<p><code>train.py</code>训练脚本中包含以下参数：
</p><div class="highlight"><pre><span></span>Options:
  --train_data_dir TEXT   The path of training dataset (default: None). If
                          this parameter is not set, imdb dataset will be
                          used.
  --test_data_dir TEXT    The path of testing dataset (default: None). If this
                          parameter is not set, imdb dataset will be used.
  --word_dict_path TEXT   The path of word dictionary (default: None). If this
                          parameter is not set, imdb dataset will be used. If
                          this parameter is set, but the file does not exist,
                          word dictionay will be built from the training data
                          automatically.
  --label_dict_path TEXT  The path of label dictionary (default: None).If this
                          parameter is not set, imdb dataset will be used. If
                          this parameter is set, but the file does not exist,
                          label dictionay will be built from the training data
                          automatically.
  --model_save_dir TEXT   The path to save the trained models (default:
                          'models').
  --help                  Show this message and exit.
</pre></div>
<p>修改<code>train.py</code>脚本中的启动参数，可以直接运行本例。 以<code>data</code>目录下的示例数据为例，在终端执行：
</p><div class="highlight"><pre><span></span>python train.py <span class="se">\</span>
  --train_data_dir <span class="s1">'data/train_data'</span>  <span class="se">\</span>
  --test_data_dir <span class="s1">'data/test_data'</span> <span class="se">\</span>
  --word_dict_path <span class="s1">'word_dict.txt'</span> <span class="se">\</span>
  --label_dict_path <span class="s1">'label_dict.txt'</span>
</pre></div>
即可对样例数据进行训练。
<h3>预测</h3>
<p>1.指定命令行参数</p>
<p><code>infer.py</code>训练脚本中包含以下参数：</p>
<div class="highlight"><pre><span></span>Options:
  --data_path TEXT        The path of data for inference (default: None). If
                          this parameter is not set, imdb test dataset will be
                          used.
  --model_path TEXT       The path of saved model.  [required]
  --word_dict_path TEXT   The path of word dictionary (default: None). If this
                          parameter is not set, imdb dataset will be used.
  --label_dict_path TEXT  The path of label dictionary (default: None).If this
                          parameter is not set, imdb dataset will be used.
  --batch_size INTEGER    The number of examples in one batch (default: 32).
  --help                  Show this message and exit.
</pre></div>
<p>2.以<code>data</code>目录下的示例数据为例，在终端执行：
</p><div class="highlight"><pre><span></span>python infer.py <span class="se">\</span>
  --data_path <span class="s1">'data/infer.txt'</span> <span class="se">\</span>
  --word_dict_path <span class="s1">'word_dict.txt'</span> <span class="se">\</span>
  --label_dict_path <span class="s1">'label_dict.txt'</span> <span class="se">\</span>
  --model_path <span class="s1">'models/params_pass_00000.tar.gz'</span>
</pre></div>
<p>即可对样例数据进行预测。</p>
{% endverbatim %}
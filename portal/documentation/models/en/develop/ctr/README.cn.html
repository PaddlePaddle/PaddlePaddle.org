{% verbatim %}
<p>运行本目录下的程序示例需要使用PaddlePaddle v0.10.0 版本。如果您的PaddlePaddle安装版本低于此要求，请按照<a href="http://www.paddlepaddle.org/docs/develop/documentation/zh/build_and_install/pip_install_cn.html">安装文档</a>中的说明更新PaddlePaddle安装版本。</p>
<hr/>
<h1>点击率预估</h1>
<p>以下是本例目录包含的文件以及对应说明:</p>
<div class="highlight"><pre><span></span>├── README.md               # 本教程markdown 文档
├── dataset.md              # 数据集处理教程
├── images                  # 本教程图片目录
│   ├── lr_vs_dnn.jpg
│   └── wide_deep.png
├── infer.py                # 预测脚本
├── network_conf.py         # 模型网络配置
├── reader.py               # data reader
├── train.py                # 训练脚本
└── utils.py                # helper functions
└── avazu_data_processer.py # 示例数据预处理脚本
</pre></div>
<h2>背景介绍</h2>
<p>CTR(Click-Through Rate，点击率预估)[<a href="https://en.wikipedia.org/wiki/Click-through_rate">1</a>]
是对用户点击一个特定链接的概率做出预测，是广告投放过程中的一个重要环节。精准的点击率预估对在线广告系统收益最大化具有重要意义。</p>
<p>当有多个广告位时，CTR 预估一般会作为排序的基准，比如在搜索引擎的广告系统里，当用户输入一个带商业价值的搜索词（query）时，系统大体上会执行下列步骤来展示广告：</p>
<ol>
<li>获取与用户搜索词相关的广告集合</li>
<li>业务规则和相关性过滤</li>
<li>根据拍卖机制和 CTR 排序</li>
<li>展出广告</li>
</ol>
<p>可以看到，CTR 在最终排序中起到了很重要的作用。</p>
<h3>发展阶段</h3>
<p>在业内，CTR 模型经历了如下的发展阶段：</p>
<ul>
<li>Logistic Regression(LR) / GBDT + 特征工程</li>
<li>LR + DNN 特征</li>
<li>DNN + 特征工程</li>
</ul>
<p>在发展早期时 LR 一统天下，但最近 DNN 模型由于其强大的学习能力和逐渐成熟的性能优化，
逐渐地接过 CTR 预估任务的大旗。</p>
<h3>LR vs DNN</h3>
<p>下图展示了 LR 和一个 (3x2) 的 DNN 模型的结构：</p>
<p align="center">
<img hspace="10" src="images/lr_vs_dnn.jpg" width="620"/> <br/>
Figure 1. LR 和 DNN 模型结构对比
</p>
<p>LR 的蓝色箭头部分可以直接类比到 DNN 中对应的结构，可以看到 LR 和 DNN 有一些共通之处（比如权重累加），
但前者的模型复杂度在相同输入维度下比后者可能低很多（从某方面讲，模型越复杂，越有潜力学习到更复杂的信息）；
如果 LR 要达到匹敌 DNN 的学习能力，必须增加输入的维度，也就是增加特征的数量，
这也就是为何 LR 和大规模的特征工程必须绑定在一起的原因。</p>
<p>LR 对于 DNN 模型的优势是对大规模稀疏特征的容纳能力，包括内存和计算量等方面，工业界都有非常成熟的优化方法；
而 DNN 模型具有自己学习新特征的能力，一定程度上能够提升特征使用的效率，
这使得 DNN 模型在同样规模特征的情况下，更有可能达到更好的学习效果。</p>
<p>本文后面的章节会演示如何使用 PaddlePaddle 编写一个结合两者优点的模型。</p>
<h2>数据和任务抽象</h2>
<p>我们可以将 <code>click</code> 作为学习目标，任务可以有以下几种方案：</p>
<ol>
<li>直接学习 click，0,1 作二元分类</li>
<li>Learning to rank, 具体用 pairwise rank（标签 1&gt;0）或者 listwise rank</li>
<li>统计每个广告的点击率，将同一个 query 下的广告两两组合，点击率高的&gt;点击率低的，做 rank 或者分类</li>
</ol>
<p>我们直接使用第一种方法做分类任务。</p>
<p>我们使用 Kaggle 上 <code>Click-through rate prediction</code> 任务的数据集[<a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">2</a>] 来演示本例中的模型。</p>
<p>具体的特征处理方法参看 <a href="./dataset.html">data process</a>。</p>
<p>本教程中演示模型的输入格式如下：</p>
<div class="highlight"><pre><span></span># &lt;dnn input ids&gt; \t &lt;lr input sparse values&gt; \t click
1 23 190 \t 230:0.12 3421:0.9 23451:0.12 \t 0
23 231 \t 1230:0.12 13421:0.9 \t 1
</pre></div>
<p>详细的格式描述如下：</p>
<ul>
<li><code>dnn input ids</code> 采用 one-hot 表示，只需要填写值为1的ID（注意这里不是变长输入）</li>
<li><code>lr input sparse values</code> 使用了 <code>ID:VALUE</code> 的表示，值部分最好规约到值域 <code>[-1, 1]</code>。</li>
</ul>
<p>此外，模型训练时需要传入一个文件描述 dnn 和 lr两个子模型的输入维度，文件的格式如下：</p>
<div class="highlight"><pre><span></span>dnn_input_dim: &lt;int&gt;
lr_input_dim: &lt;int&gt;
</pre></div>
<p>其中， <code>&lt;int&gt;</code> 表示一个整型数值。</p>
<p>本目录下的 <code>avazu_data_processor.py</code> 可以对下载的演示数据集[<a href="#参考文档">2</a>] 进行处理，具体使用方法参考如下说明：</p>
<div class="highlight"><pre><span></span>usage: avazu_data_processer.py [-h] --data_path DATA_PATH --output_dir
                               OUTPUT_DIR
                               [--num_lines_to_detect NUM_LINES_TO_DETECT]
                               [--test_set_size TEST_SET_SIZE]
                               [--train_size TRAIN_SIZE]

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --data_path DATA_PATH
                        path of the Avazu dataset
  --output_dir OUTPUT_DIR
                        directory to output
  --num_lines_to_detect NUM_LINES_TO_DETECT
                        number of records to detect dataset's meta info
  --test_set_size TEST_SET_SIZE
                        size of the validation dataset(default: 10000)
  --train_size TRAIN_SIZE
                        size of the trainset (default: 100000)
</pre></div>
<ul>
<li><code>data_path</code> 是待处理的数据路径</li>
<li><code>output_dir</code> 生成数据的输出路径</li>
<li><code>num_lines_to_detect</code> 预先扫描数据生成ID的个数，这里是扫描的文件行数</li>
<li><code>test_set_size</code> 生成测试集的行数</li>
<li><code>train_size</code> 生成训练姐的行数</li>
</ul>
<h2>Wide &amp; Deep Learning Model</h2>
<p>谷歌在 16 年提出了 Wide &amp; Deep Learning 的模型框架，用于融合适合学习抽象特征的 DNN 和 适用于大规模稀疏特征的 LR 两种模型的优点。</p>
<h3>模型简介</h3>
<p>Wide &amp; Deep Learning Model[<a href="#参考文献">3</a>] 可以作为一种相对成熟的模型框架使用，
在 CTR 预估的任务中工业界也有一定的应用，因此本文将演示使用此模型来完成 CTR 预估的任务。</p>
<p>模型结构如下：</p>
<p align="center">
<img hspace="10" src="images/wide_deep.png" width="820"/> <br/>
Figure 2. Wide &amp; Deep Model
</p>
<p>模型上边的 Wide 部分，可以容纳大规模系数特征，并且对一些特定的信息（比如 ID）有一定的记忆能力；
而模型下边的 Deep 部分，能够学习特征间的隐含关系，在相同数量的特征下有更好的学习和推导能力。</p>
<h3>编写模型输入</h3>
<p>模型只接受 3 个输入，分别是</p>
<ul>
<li><code>dnn_input</code> ，也就是 Deep 部分的输入</li>
<li><code>lr_input</code> ，也就是 Wide 部分的输入</li>
<li><code>click</code> ， 点击与否，作为二分类模型学习的标签</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">dnn_merged_input</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'dnn_input'</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">sparse_binary_vector</span><span class="p">(</span><span class="n">data_meta_info</span><span class="p">[</span><span class="s1">'dnn_input'</span><span class="p">]))</span>

<span class="n">lr_merged_input</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'lr_input'</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">sparse_binary_vector</span><span class="p">(</span><span class="n">data_meta_info</span><span class="p">[</span><span class="s1">'lr_input'</span><span class="p">]))</span>

<span class="n">click</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'click'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">dense_vector</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
<h3>编写 Wide 部分</h3>
<p>Wide 部分直接使用了 LR 模型，但激活函数改成了 <code>RELU</code> 来加速</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_lr_submodel</span><span class="p">():</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">lr_merged_input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'lr'</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">fc</span>
</pre></div>
<h3>编写 Deep 部分</h3>
<p>Deep 部分使用了标准的多层前向传导的 DNN 模型</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_dnn_submodel</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">):</span>
    <span class="n">dnn_embedding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">dnn_merged_input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">dnn_layer_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">dnn_embedding</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
            <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">(),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">'dnn-fc-</span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">fc</span>
    <span class="k">return</span> <span class="n">_input_layer</span>
</pre></div>
<h3>两者融合</h3>
<p>两个 submodel 的最上层输出加权求和得到整个模型的输出，输出部分使用 <code>sigmoid</code> 作为激活函数，得到区间 (0,1) 的预测值，
来逼近训练数据中二元类别的分布，并最终作为 CTR 预估的值使用。</p>
<div class="highlight"><pre><span></span><span class="c1"># conbine DNN and LR submodels</span>
<span class="k">def</span> <span class="nf">combine_submodels</span><span class="p">(</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">merge_layer</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">])</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">merge_layer</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">'output'</span><span class="p">,</span>
        <span class="c1"># use sigmoid function to approximate ctr, wihch is a float value between 0 and 1.</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">fc</span>
</pre></div>
<h3>训练任务的定义</h3>
<div class="highlight"><pre><span></span><span class="n">dnn</span> <span class="o">=</span> <span class="n">build_dnn_submodel</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">build_lr_submodel</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">combine_submodels</span><span class="p">(</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

<span class="c1"># ==============================================================================</span>
<span class="c1">#                   cost and train period</span>
<span class="c1"># ==============================================================================</span>
<span class="n">classification_cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">multi_binary_label_cross_entropy_cost</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">click</span><span class="p">)</span>


<span class="n">paddle</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">trainer_count</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">classification_cost</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">cost</span><span class="o">=</span><span class="n">classification_cost</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">update_equation</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">AvazuDataset</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">n_records_as_test</span><span class="o">=</span><span class="n">test_set_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">event_handler</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndIteration</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Pass </span><span class="si">%d</span><span class="s2">, Samples </span><span class="si">%d</span><span class="s2">, Cost </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span>
                <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="n">feeding</span><span class="o">=</span><span class="n">field_index</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Test </span><span class="si">%d</span><span class="s2">-</span><span class="si">%d</span><span class="s2">, Cost </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span>
                                           <span class="n">result</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>


<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
        <span class="n">paddle</span><span class="o">.</span><span class="n">reader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">buf_size</span><span class="o">=</span><span class="mi">500</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">),</span>
    <span class="n">feeding</span><span class="o">=</span><span class="n">field_index</span><span class="p">,</span>
    <span class="n">event_handler</span><span class="o">=</span><span class="n">event_handler</span><span class="p">,</span>
    <span class="n">num_passes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
<h2>运行训练和测试</h2>
<p>训练模型需要如下步骤：</p>
<ol>
<li>准备训练数据<ol>
<li>从 <a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">Kaggle CTR</a> 下载 train.gz</li>
<li>解压 train.gz 得到 train.txt</li>
<li><code>mkdir -p output; python avazu_data_processer.py --data_path train.txt --output_dir output --num_lines_to_detect 1000 --test_set_size 100</code> 生成演示数据</li>
</ol>
</li>
<li>执行 <code>python train.py --train_data_path ./output/train.txt --test_data_path ./output/test.txt --data_meta_file ./output/data.meta.txt --model_type=0</code> 开始训练</li>
</ol>
<p>上面第2个步骤可以为 <code>train.py</code> 填充命令行参数来定制模型的训练过程，具体的命令行参数及用法如下</p>
<div class="highlight"><pre><span></span>usage: train.py [-h] --train_data_path TRAIN_DATA_PATH
                [--test_data_path TEST_DATA_PATH] [--batch_size BATCH_SIZE]
                [--num_passes NUM_PASSES]
                [--model_output_prefix MODEL_OUTPUT_PREFIX] --data_meta_file
                DATA_META_FILE --model_type MODEL_TYPE

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --train_data_path TRAIN_DATA_PATH
                        path of training dataset
  --test_data_path TEST_DATA_PATH
                        path of testing dataset
  --batch_size BATCH_SIZE
                        size of mini-batch (default:10000)
  --num_passes NUM_PASSES
                        number of passes to train
  --model_output_prefix MODEL_OUTPUT_PREFIX
                        prefix of path for model to store (default:
                        ./ctr_models)
  --data_meta_file DATA_META_FILE
                        path of data meta info file
  --model_type MODEL_TYPE
                        model type, classification: 0, regression 1 (default
                        classification)
</pre></div>
<ul>
<li><code>train_data_path</code> ： 训练集的路径</li>
<li><code>test_data_path</code> : 测试集的路径</li>
<li><code>num_passes</code>: 模型训练多少轮</li>
<li><code>data_meta_file</code>: 参考<a href="### 数据和任务抽象">数据和任务抽象</a>的描述。</li>
<li><code>model_type</code>: 模型分类或回归</li>
</ul>
<h2>用训好的模型做预测</h2>
<p>训好的模型可以用来预测新的数据， 预测数据的格式为</p>
<div class="highlight"><pre><span></span># &lt;dnn input ids&gt; \t &lt;lr input sparse values&gt;
1 23 190 \t 230:0.12 3421:0.9 23451:0.12
23 231 \t 1230:0.12 13421:0.9
</pre></div>
<p>这里与训练数据的格式唯一不同的地方，就是没有标签，也就是训练数据中第3列 <code>click</code> 对应的数值。</p>
<p><code>infer.py</code> 的使用方法如下</p>
<div class="highlight"><pre><span></span>usage: infer.py [-h] --model_gz_path MODEL_GZ_PATH --data_path DATA_PATH
                --prediction_output_path PREDICTION_OUTPUT_PATH
                [--data_meta_path DATA_META_PATH] --model_type MODEL_TYPE

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --model_gz_path MODEL_GZ_PATH
                        path of model parameters gz file
  --data_path DATA_PATH
                        path of the dataset to infer
  --prediction_output_path PREDICTION_OUTPUT_PATH
                        path to output the prediction
  --data_meta_path DATA_META_PATH
                        path of trainset's meta info, default is ./data.meta
  --model_type MODEL_TYPE
                        model type, classification: 0, regression 1 (default
                        classification)
</pre></div>
<ul>
<li><code>model_gz_path_model</code>：用 <code>gz</code> 压缩过的模型路径</li>
<li><code>data_path</code> ： 需要预测的数据路径</li>
<li><code>prediction_output_paht</code>：预测输出的路径</li>
<li><code>data_meta_file</code> ：参考<a href="### 数据和任务抽象">数据和任务抽象</a>的描述。</li>
<li><code>model_type</code> ：分类或回归</li>
</ul>
<p>示例数据可以用如下命令预测</p>
<div class="highlight"><pre><span></span>python infer.py --model_gz_path &lt;model_path&gt; --data_path output/infer.txt --prediction_output_path predictions.txt --data_meta_path data.meta.txt
</pre></div>
<p>最终的预测结果位于 <code>predictions.txt</code>。</p>
<h2>参考文献</h2>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Click-through_rate">https://en.wikipedia.org/wiki/Click-through_rate</a></li>
<li><a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">https://www.kaggle.com/c/avazu-ctr-prediction/data</a></li>
<li>Cheng H T, Koc L, Harmsen J, et al. <a href="https://arxiv.org/pdf/1606.07792.pdf">Wide &amp; deep learning for recommender systems</a>[C]//Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, 2016: 7-10.</li>
</ol>
{% endverbatim %}
{% verbatim %}
<p>The minimum PaddlePaddle version needed for the code sample in this directory is the lastest develop branch. If you are on a version of PaddlePaddle earlier than this, <a href="http://www.paddlepaddle.org/docs/develop/documentation/en/build_and_install/pip_install_en.html">please update your installation</a>.</p>
<hr/>
<h2>SSD Object Detection</h2>
<h3>Introduction</h3>
<p><a href="https://arxiv.org/abs/1512.02325">Single Shot MultiBox Detector (SSD)</a> framework for object detection is based on a feed-forward convolutional network. The early network is a standard convolutional architecture for image classification, such as VGG, ResNet, or MobileNet, which is also called base network. In this tutorial we used <a href="https://arxiv.org/abs/1704.04861">MobileNet</a>.</p>
<h3>Data Preparation</h3>
<p>You can use <a href="http://host.robots.ox.ac.uk/pascal/VOC/">PASCAL VOC dataset</a> or <a href="http://cocodataset.org/#download">MS-COCO dataset</a>.</p>
<h4>PASCAL VOC Dataset</h4>
<p>If you want to train model on PASCAL VOC dataset, please download datset at first, skip this step if you already have one.</p>
<div class="highlight"><pre><span></span><span class="nb">cd</span> data/pascalvoc
./download.sh
</pre></div>
<p>The command <code>download.sh</code> also will create training and testing file lists.</p>
<h4>MS-COCO Dataset</h4>
<p>If you want to train model on MS-COCO dataset, please download datset at first, skip this step if you already have one.</p>
<div class="highlight"><pre><span></span>cd data/coco
./download.sh
</pre></div>
<h3>Train</h3>
<h4>Download the Pre-trained Model.</h4>
<p>We provide two pre-trained models. The one is MobileNet-v1 SSD trained on COCO dataset, but removed the convolutional predictors for COCO dataset. This model can be used to initialize the models when training other dataset, like PASCAL VOC. Then other pre-trained model is MobileNet v1 trained on ImageNet 2012 dataset, but removed the last weights and bias in Fully-Connected layer.</p>
<p>Declaration: the MobileNet-v1 SSD model is converted by <a href="https://github.com/tensorflow/models/blob/f87a58cd96d45de73c9a8330a06b2ab56749a7fa/research/object_detection/g3doc/detection_model_zoo.md">TensorFlow model</a>. The MobileNet v1 model is converted <a href="https://github.com/shicai/MobileNet-Caffe">Caffe</a>.</p>
<ul>
<li>Download MobileNet-v1 SSD:
    <div class="highlight"><pre><span></span>./pretrained/download_coco.sh
</pre></div></li>
<li>Download MobileNet-v1:
    <div class="highlight"><pre><span></span>./pretrained/download_imagenet.sh
</pre></div></li>
</ul>
<h4>Train on PASCAL VOC</h4>
<ul>
<li>Train on one device (/GPU).
  <div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="o">-</span><span class="n">u</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">parallel</span><span class="o">=</span><span class="bp">False</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'pascalvoc'</span> <span class="o">--</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'pretrained/ssd_mobilenet_v1_coco/'</span>
</pre></div></li>
<li>Train on multi devices (/GPUs).</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="n">python</span> <span class="o">-</span><span class="n">u</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'pascalvoc'</span> <span class="o">--</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'pretrained/ssd_mobilenet_v1_coco/'</span>
</pre></div>
<h4>Train on MS-COCO</h4>
<ul>
<li>Train on one device (/GPU).
  <div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="o">-</span><span class="n">u</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">parallel</span><span class="o">=</span><span class="bp">False</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'coco2014'</span> <span class="o">--</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'pretrained/mobilenet_v1_imagenet/'</span>
</pre></div></li>
<li>Train on multi devices (/GPUs).
  <div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span> <span class="n">python</span> <span class="o">-</span><span class="n">u</span> <span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'coco2014'</span> <span class="o">--</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s1">'pretrained/mobilenet_v1_imagenet/'</span>
</pre></div></li>
</ul>
<p>TBD</p>
<h3>Evaluate</h3>
<p>You can evaluate your trained model in different metric like 11point, integral on both PASCAL VOC and COCO dataset. Moreover, we provide eval_coco_map.py which uses a COCO-specific mAP metric defined by <a href="http://cocodataset.org/#detections-eval">COCO committee</a>. To use this eval_coco_map.py, <a href="https://github.com/cocodataset/cocoapi">cocoapi</a> is needed.
Install the cocoapi:
</p><div class="highlight"><pre><span></span># COCOAPI=/path/to/clone/cocoapi
git clone https://github.com/cocodataset/cocoapi.git &lt;span class="markdown-equation" id="equation-0"&gt;&lt;/span&gt;COCOAPI/PythonAPI
# Install into global site-packages
make install
# Alternatively, if you do not have permissions or prefer
# not to install the COCO API into global site-packages
python2 setup.py install --user
</pre></div>
Note we set the defualt test list to the dataset's test/val list, you can use your own test list by setting test_list args.
<h4>Evaluate on PASCAL VOC</h4>
<div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="nb">eval</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'pascalvoc'</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="s1">'train_pascal_model/90'</span> <span class="o">--</span><span class="n">data_dir</span><span class="o">=</span><span class="s1">'data/pascalvoc'</span> <span class="o">--</span><span class="n">test_list</span><span class="o">=</span><span class="s1">'test.txt'</span> <span class="o">--</span><span class="n">ap_version</span><span class="o">=</span><span class="s1">'11point'</span>
</pre></div>
<h4>Evaluate on MS-COCO</h4>
<div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="nb">eval</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'coco2014'</span> <span class="o">--</span><span class="n">nms_threshold</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="s1">'train_coco_model/40'</span> <span class="o">--</span><span class="n">test_list</span><span class="o">=</span><span class="s1">'annotations/instances_minival2014.json'</span> <span class="o">--</span><span class="n">ap_version</span><span class="o">=</span><span class="s1">'integral'</span>
<span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="n">eval_coco_map</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'coco2017'</span> <span class="o">--</span><span class="n">nms_threshold</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="s1">'train_coco_model/40'</span> <span class="o">--</span><span class="n">test_list</span><span class="o">=</span><span class="s1">'annotations/instances_minival2017.json'</span>
</pre></div>
<p>TBD</p>
<h3>Infer and Visualize</h3>
<p></p><div class="highlight"><pre><span></span><span class="n">env</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="mi">0</span> <span class="n">python</span> <span class="n">infer</span><span class="o">.</span><span class="n">py</span> <span class="o">--</span><span class="n">dataset</span><span class="o">=</span><span class="s1">'coco'</span> <span class="o">--</span><span class="n">nms_threshold</span><span class="o">=</span><span class="mf">0.5</span> <span class="o">--</span><span class="n">model_dir</span><span class="o">=</span><span class="s1">'train_coco_model/20'</span> <span class="o">--</span><span class="n">image_path</span><span class="o">=</span><span class="s1">'./data/coco/val2014/COCO_val2014_000000000139.jpg'</span>
</pre></div>
Below is the examples after running python infer.py to inference and visualize the model result.
<p align="center">
<img height="300" hspace="10" src="images/COCO_val2014_000000000139.jpg" width="400"/>
<img height="300" hspace="10" src="images/COCO_val2014_000000000785.jpg" width="400"/>
<img height="300" hspace="10" src="images/COCO_val2014_000000142324.jpg" width="400"/>
<img height="300" hspace="10" src="images/COCO_val2014_000000144003.jpg" width="400"/> <br/>
MobileNet-SSD300x300 Visualization Examples
</p>
<p>TBD</p>
<h3>Released Model</h3>
<table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Pre-trained Model</th>
<th align="center">Training data</th>
<th align="center">Test data</th>
<th align="center">mAP</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">MobileNet-v1-SSD 300x300</td>
<td align="center">COCO MobileNet SSD</td>
<td align="center">VOC07+12 trainval</td>
<td align="center">VOC07 test</td>
<td align="center">xx%</td>
</tr>
<tr>
<td align="center">MobileNet-v1-SSD 300x300</td>
<td align="center">ImageNet MobileNet</td>
<td align="center">VOC07+12 trainval</td>
<td align="center">VOC07 test</td>
<td align="center">xx%</td>
</tr>
<tr>
<td align="center">MobileNet-v1-SSD 300x300</td>
<td align="center">ImageNet MobileNet</td>
<td align="center">MS-COCO trainval</td>
<td align="center">MS-COCO test</td>
<td align="center">xx%</td>
</tr>
</tbody>
</table>
<p>TBD</p>
{% endverbatim %}
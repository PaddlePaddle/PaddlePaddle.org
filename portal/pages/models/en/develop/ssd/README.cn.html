{% verbatim %}
<p>运行本目录下的程序示例需要使用PaddlePaddle v0.10.0 版本。如果您的PaddlePaddle安装版本低于此要求，请按照<a href="http://www.paddlepaddle.org/docs/develop/documentation/zh/build_and_install/pip_install_cn.html">安装文档</a>中的说明更新PaddlePaddle安装版本。</p>
<hr/>
<h1>SSD目标检测</h1>
<h2>概述</h2>
<p>SSD全称：Single Shot MultiBox Detector，是目标检测领域较新且效果较好的检测算法之一[<a href="#引用">1</a>]，有着检测速度快且检测精度高的有的。PaddlePaddle已集成SSD算法，本示例旨在介绍如何使用PaddlePaddle中的SSD模型进行目标检测。下文首先简要介绍SSD原理，然后介绍示例包含文件及如何使用，接着介绍如何在PASCAL VOC数据集上训练、评估及检测，最后简要介绍如何在自有数据集上使用SSD。</p>
<h2>SSD原理</h2>
<p>SSD使用一个卷积神经网络实现“端到端”的检测：输入为原始图像，输出为检测结果，无需借助外部工具或流程进行特征提取、候选框生成等。论文中SSD使用VGG16[<a href="#引用">2</a>]作为基础网络进行图像特征提取。但SSD对原始VGG16网络做了一些改变：</p>
<ol>
<li>将最后的fc6、fc7全连接层变为卷积层，卷积层参数通过对原始fc6、fc7参数采样得到。</li>
<li>将pool5层的参数由2x2-s2（kernel大小为2x2，stride size为2）更改为3x3-s1-p1（kernel大小为3x3，stride size为1，padding size为1）。</li>
<li>在conv4_3、conv7、conv8_2、conv9_2、conv10_2及pool11层后面接了priorbox层，priorbox层的主要目的是根据输入的特征图（feature map）生成一系列的矩形候选框。更详细的介绍可参考[<a href="#引用">1</a>]。</li>
</ol>
<p>下图为模型（输入图像尺寸：300x300）的总体结构：</p>
<p align="center">
<img height="250" hspace="10" src="images/ssd_network.png" width="900"/> <br/>
图1. SSD 网络结构
</p>
<p>图中每个矩形盒子代表一个卷积层，最后两个矩形框分别表示汇总各卷积层输出结果和后处理阶段。在预测阶段，网络会输出一组候选矩形框，每个矩形包含：位置和类别得分。图中倒数第二个矩形框即表示网络的检测结果的汇总处理。由于候选矩形框数量较多且很多矩形框重叠严重，这时需要经过后处理来筛选出质量较高的少数矩形框，主要方法有非极大值抑制（Non-maximum Suppression）。</p>
<p>从SSD的网络结构可以看出，候选矩形框在多个特征图（feature map）上生成，不同的feature map具有的感受野不同，这样可以在不同尺度扫描图像，相对于其他检测方法可以生成更丰富的候选框，从而提高检测精度；另一方面SSD对VGG16的扩展部分以较小的代价实现对候选框的位置和类别得分的计算，整个过程只需要一个卷积神经网络完成，所以速度较快。</p>
<h2>示例总览</h2>
<p>本示例共包含如下文件：</p>
<table>
<caption>表1. 示例文件</caption>
<tr><th>文件</th><th>用途</th></tr>
<tr><td>train.py</td><td>训练脚本</td></tr>
<tr><td>eval.py</td><td>评估脚本，用于评估训好模型</td></tr>
<tr><td>infer.py</td><td>检测脚本，给定图片及模型，实施检测</td></tr>
<tr><td>visual.py</td><td>检测结果可视化</td></tr>
<tr><td>image_util.py</td><td>图像预处理所需公共函数</td></tr>
<tr><td>data_provider.py</td><td>数据处理脚本，生成训练、评估或检测所需数据</td></tr>
<tr><td>config/pascal_voc_conf.py</td><td>神经网络超参数配置文件</td></tr>
<tr><td>data/label_list</td><td>类别列表</td></tr>
<tr><td>data/prepare_voc_data.py</td><td>准备训练PASCAL VOC数据列表</td></tr>
</table>
<p>训练阶段需要对数据做预处理，包括裁剪、采样等，这部分操作在<code>image_util.py</code>和<code>data_provider.py</code>中完成。</p>
<p>需要注意：<strong><code>config/vgg_config.py</code>是参数配置文件，含有训练参数、神经网络参数等。配置文件中的参数针对PASCAL VOC数据集而配置，当训练自有数据时，需要进行针对性的修改。</strong></p>
<p><code>data/prepare_voc_data.py</code>脚本用来生成文件列表，包括切分训练集和测试集，使用时需要事先下载并解压数据，默认采用VOC2007和VOC2012。</p>
<h2>PASCAL VOC数据集</h2>
<h3>数据准备</h3>
<ol>
<li>请首先下载数据集：VOC2007[<a href="#引用">3</a>]和VOC2012[<a href="#引用">4</a>]。VOC2007包含训练集和测试集，VOC2012只包含训练集，将下载好的数据解压，目录结构为<code>data/VOCdevkit/VOC2007</code>和<code>data/VOCdevkit/VOC2012</code>。</li>
<li>
<p>进入<code>data</code>目录，运行<code>python prepare_voc_data.py</code>即可生成<code>trainval.txt</code>和<code>test.txt</code>。核心函数为：</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_filelist</span><span class="p">(</span><span class="n">devkit_dir</span><span class="p">,</span> <span class="n">years</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">):</span>
    <span class="n">trainval_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="n">years</span><span class="p">:</span>
        <span class="n">trainval</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">walk_dir</span><span class="p">(</span><span class="n">devkit_dir</span><span class="p">,</span> <span class="n">year</span><span class="p">)</span>
        <span class="n">trainval_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">trainval</span><span class="p">)</span>
        <span class="n">test_list</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">trainval_list</span><span class="p">)</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">osp</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'trainval.txt'</span><span class="p">),</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">ftrainval</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">trainval_list</span><span class="p">:</span>
            <span class="n">ftrainval</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">osp</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">'test.txt'</span><span class="p">),</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">ftest</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">test_list</span><span class="p">:</span>
            <span class="n">ftest</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">item</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">' '</span> <span class="o">+</span> <span class="n">item</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</li>
</ol>
<p>该函数首先对每一年（year）数据进行处理，然后将训练图像的文件路径列表进行随机乱序，最后保存训练文件列表和测试文件列表。默认<code>prepare_voc_data.py</code>和<code>VOCdevkit</code>在相同目录下，且生成的文件列表也在该目录次数。</p>
<p>需注意<code>trainval.txt</code>既包含VOC2007的训练数据，也包含VOC2012的训练数据，<code>test.txt</code>只包含VOC2007的测试数据。</p>
<p>下面是<code>trainval.txt</code>前几行输入示例：</p>
<pre><code>```text
VOCdevkit/VOC2007/JPEGImages/000005.jpg VOCdevkit/VOC2007/Annotations/000005.xml
VOCdevkit/VOC2007/JPEGImages/000007.jpg VOCdevkit/VOC2007/Annotations/000007.xml
VOCdevkit/VOC2007/JPEGImages/000009.jpg VOCdevkit/VOC2007/Annotations/000009.xml
```

文件共两个字段，第一个字段为图像文件的相对路径，第二个字段为对应标注文件的相对路径。
</code></pre>
<h3>预训练模型准备</h3>
<p>下载预训练的VGG-16模型，我们提供了一个转换好的模型，下载模型<a href="http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz">http://paddlepaddle.bj.bcebos.com/model_zoo/detection/ssd_model/vgg_model.tar.gz</a>，并将其放置路径为<code>vgg/vgg_model.tar.gz</code>。</p>
<h3>模型训练</h3>
<p>直接执行<code>python train.py</code>即可进行训练。需要注意本示例仅支持CUDA GPU环境，无法在CPU上训练，主要因为使用CPU训练速度很慢，实践中一般使用GPU来处理图像任务，这里实现采用硬编码方式使用cuDNN，不提供CPU版本。<code>train.py</code>的一些关键执行逻辑：</p>
<div class="highlight"><pre><span></span><span class="n">paddle</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">trainer_count</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">data_args</span> <span class="o">=</span> <span class="n">data_provider</span><span class="o">.</span><span class="n">Settings</span><span class="p">(</span>
                <span class="n">data_dir</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span>
                <span class="n">label_file</span><span class="o">=</span><span class="s1">'label_list'</span><span class="p">,</span>
                <span class="n">resize_h</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">IMG_HEIGHT</span><span class="p">,</span>
                <span class="n">resize_w</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">IMG_WIDTH</span><span class="p">,</span>
                <span class="n">mean_value</span><span class="o">=</span><span class="p">[</span><span class="mi">104</span><span class="p">,</span><span class="mi">117</span><span class="p">,</span><span class="mi">124</span><span class="p">])</span>
<span class="n">train</span><span class="p">(</span><span class="n">train_file_list</span><span class="o">=</span><span class="s1">'./data/trainval.txt'</span><span class="p">,</span>
      <span class="n">dev_file_list</span><span class="o">=</span><span class="s1">'./data/test.txt'</span><span class="p">,</span>
      <span class="n">data_args</span><span class="o">=</span><span class="n">data_args</span><span class="p">,</span>
      <span class="n">init_model_path</span><span class="o">=</span><span class="s1">'./vgg/vgg_model.tar.gz'</span><span class="p">)</span>
</pre></div>
<p>主要包括：</p>
<ol>
<li>调用<code>paddle.init</code>指定使用4卡GPU训练。</li>
<li>调用<code>data_provider.Settings</code>配置数据预处理所需参数，其中<code>cfg.IMG_HEIGHT</code>和<code>cfg.IMG_WIDTH</code>在配置文件<code>config/vgg_config.py</code>中设置，这里均为300，300x300是一个典型配置，兼顾效率和检测精度，也可以通过修改配置文件扩展到512x512。</li>
<li>调用<code>train</code>执行训练，其中<code>train_file_list</code>指定训练数据列表，<code>dev_file_list</code>指定评估数据列表，<code>init_model_path</code>指定预训练模型位置。</li>
<li>训练过程中会打印一些日志信息，每训练1个batch会输出当前的轮数、当前batch的cost及mAP（mean Average Precision，平均精度均值），每训练一个pass，会保存一次模型，默认保存在<code>checkpoints</code>目录下（注：需事先创建）。</li>
</ol>
<p>下面给出SDD300x300在VOC数据集（train包括07+12，test为07）上的mAP曲线，迭代140轮mAP可达到71.52%。</p>
<p align="center">
<img hspace="10" src="images/SSD300x300_map.png"/> <br/>
图2. SSD300x300 mAP收敛曲线
</p>
<h3>模型评估</h3>
<p>执行<code>python eval.py</code>即可对模型进行评估，<code>eval.py</code>的关键执行逻辑如下：</p>
<div class="highlight"><pre><span></span><span class="n">paddle</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">trainer_count</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>  <span class="c1"># use 4 gpus</span>

<span class="n">data_args</span> <span class="o">=</span> <span class="n">data_provider</span><span class="o">.</span><span class="n">Settings</span><span class="p">(</span>
    <span class="n">data_dir</span><span class="o">=</span><span class="s1">'./data'</span><span class="p">,</span>
    <span class="n">label_file</span><span class="o">=</span><span class="s1">'label_list'</span><span class="p">,</span>
    <span class="n">resize_h</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">IMG_HEIGHT</span><span class="p">,</span>
    <span class="n">resize_w</span><span class="o">=</span><span class="n">cfg</span><span class="o">.</span><span class="n">IMG_WIDTH</span><span class="p">,</span>
    <span class="n">mean_value</span><span class="o">=</span><span class="p">[</span><span class="mi">104</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">124</span><span class="p">])</span>

<span class="nb">eval</span><span class="p">(</span>
    <span class="n">eval_file_list</span><span class="o">=</span><span class="s1">'./data/test.txt'</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">data_args</span><span class="o">=</span><span class="n">data_args</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span><span class="s1">'models/pass-00000.tar.gz'</span><span class="p">)</span>
</pre></div>
<p>调用<code>paddle.init</code>指定使用4卡GPU评估；<code>data_provider.Settings</code>参见训练阶段的配置；调用<code>eval</code>执行评估，其中<code>eval_file_list</code>指定评估数据列表，<code>batch_size</code>指定评估时batch size的大小，<code>model_path</code>指定模型:位置。评估结束会输出<code>loss</code>信息和<code>mAP</code>信息。</p>
<h3>图像检测</h3>
<p>执行<code>python infer.py</code>即可使用训练好的模型对图片实施检测，<code>infer.py</code>关键逻辑如下：</p>
<div class="highlight"><pre><span></span><span class="n">infer</span><span class="p">(</span>
    <span class="n">eval_file_list</span><span class="o">=</span><span class="s1">'./data/infer.txt'</span><span class="p">,</span>
    <span class="n">save_path</span><span class="o">=</span><span class="s1">'infer.res'</span><span class="p">,</span>
    <span class="n">data_args</span><span class="o">=</span><span class="n">data_args</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">model_path</span><span class="o">=</span><span class="s1">'models/pass-00000.tar.gz'</span><span class="p">,</span>
    <span class="n">threshold</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
<p>其中<code>eval_file_list</code>指定图像路径列表；<code>save_path</code>指定预测结果保存路径；<code>data_args</code>如上；<code>batch_size</code>为每多少样本预测一次；<code>model_path</code>指模型的位置；<code>threshold</code>为置信度阈值，只有得分大于或等于该值的才会输出。下面给出<code>infer.res</code>的一些输出样例：</p>
<div class="highlight"><pre><span></span>VOCdevkit/VOC2007/JPEGImages/006936.jpg 12 0.997844 131.255611777 162.271582842 396.475315094 334.0
VOCdevkit/VOC2007/JPEGImages/006936.jpg 14 0.998557 229.160234332 49.5991278887 314.098775387 312.913876176
VOCdevkit/VOC2007/JPEGImages/006936.jpg 14 0.372522 187.543615699 133.727034628 345.647156239 327.448492289
...
</pre></div>
<p>共包含4个字段，以tab分割，第一个字段是检测图像路径，第二字段为检测矩形框内类别，第三个字段是置信度，第四个字段是4个坐标值（以空格分割）。</p>
<p>示例还提供了一个可视化脚本，直接运行<code>python visual.py</code>即可，须指定输出检测结果路径及输出目录，默认可视化后图像保存在<code>./visual_res</code>，下面是用训练好的模型infer部分图像并可视化的效果：</p>
<p align="center">
<img height="150" hspace="10" src="images/vis_1.jpg" width="200"/>
<img height="150" hspace="10" src="images/vis_2.jpg" width="200"/>
<img height="150" hspace="10" src="images/vis_3.jpg" width="100"/>
<img height="150" hspace="10" src="images/vis_4.jpg" width="200"/> <br/>
图3. SSD300x300 检测可视化示例
</p>
<h2>自有数据集</h2>
<p>在自有数据上训练PaddlePaddle SSD需要完成两个关键准备，首先需要适配网络可以接受的输入格式，这里提供一个推荐的结构，以<code>train.txt</code>为例</p>
<div class="highlight"><pre><span></span>image00000_file_path    image00000_annotation_file_path
image00001_file_path    image00001_annotation_file_path
image00002_file_path    image00002_annotation_file_path
...
</pre></div>
<p>文件共两列，以空白符分割，第一列为图像文件的路径，第二列为对应标注数据的文件路径。对图像文件的读取比较直接，略微复杂的是对标注数据的解析，本示例中标注数据使用xml文件存储，所以需要在<code>data_provider.py</code>中对xml解析，核心逻辑如下：</p>
<div class="highlight"><pre><span></span><span class="n">bbox_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">root</span> <span class="o">=</span> <span class="n">xml</span><span class="o">.</span><span class="n">etree</span><span class="o">.</span><span class="n">ElementTree</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">label_path</span><span class="p">)</span><span class="o">.</span><span class="n">getroot</span><span class="p">()</span>
<span class="k">for</span> <span class="nb">object</span> <span class="ow">in</span> <span class="n">root</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">'object'</span><span class="p">):</span>
    <span class="n">bbox_sample</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># start from 1</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">label_list</span><span class="o">.</span><span class="n">index</span><span class="p">(</span>
         <span class="nb">object</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'name'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)))</span>
    <span class="n">bbox</span> <span class="o">=</span> <span class="nb">object</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'bndbox'</span><span class="p">)</span>
    <span class="n">difficult</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">object</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'difficult'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">bbox</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'xmin'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">/</span><span class="n">img_width</span><span class="p">)</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">bbox</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'ymin'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">/</span><span class="n">img_height</span><span class="p">)</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">bbox</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'xmax'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">/</span><span class="n">img_width</span><span class="p">)</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">bbox</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s1">'ymax'</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">/</span><span class="n">img_height</span><span class="p">)</span>
    <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">difficult</span><span class="p">)</span>
    <span class="n">bbox_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox_sample</span><span class="p">)</span>
</pre></div>
<p>这里一条标注数据包括：label、xmin、ymin、xmax、ymax和is_difficult，is_difficult表示该object是否为难例，实际中如果不需要，只需把该字段置零即可。自有数据也需要提供对应的解析逻辑，假设标注数据（比如image00000_annotation_file_path）存储格式如下：</p>
<div class="highlight"><pre><span></span>label1 xmin1 ymin1 xmax1 ymax1
label2 xmin2 ymin2 xmax2 ymax2
...
</pre></div>
<p>每行对应一个物体，共5个字段，第一个为label（注背景为0，需从1编号），剩余4个为坐标，对应的解析逻辑可更改为如下：</p>
<div class="highlight"><pre><span></span><span class="n">bbox_labels</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">label_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">flabel</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">flabel</span><span class="p">:</span>
        <span class="n">bbox_sample</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">bbox</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">bbox</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">img_width</span><span class="p">))</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">img_height</span><span class="p">))</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">img_width</span><span class="p">))</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">/</span><span class="nb">float</span><span class="p">(</span><span class="n">img_height</span><span class="p">))</span>
        <span class="n">bbox_sample</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
        <span class="n">bbox_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bbox_sample</span><span class="p">)</span>
</pre></div>
<p><strong>同时需要注意根据图像大小及检测物体的大小等更改网络结构相关的超参数，请仿照<code>config/vgg_config.py</code>创建自己的配置文件，参数设置经验请参考论文[<a href="#引用">1</a>]。</strong></p>
<h2>引用</h2>
<ol>
<li>Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C. Berg. <a href="https://arxiv.org/abs/1512.02325">SSD: Single shot multibox detector</a>. European conference on computer vision. Springer, Cham, 2016.</li>
<li>Simonyan, Karen, and Andrew Zisserman. <a href="https://arxiv.org/abs/1409.1556">Very deep convolutional networks for large-scale image recognition</a>. arXiv preprint arXiv:1409.1556 (2014).</li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2007/index.html">The PASCAL Visual Object Classes Challenge 2007</a></li>
<li><a href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html">Visual Object Classes Challenge 2012 (VOC2012)</a></li>
</ol>
{% endverbatim %}
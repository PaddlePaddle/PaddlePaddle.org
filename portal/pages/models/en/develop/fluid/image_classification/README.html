{% verbatim %}
<p>The minimum PaddlePaddle version needed for the code sample in this directory is the lastest develop branch. If you are on a version of PaddlePaddle earlier than this, <a href="http://www.paddlepaddle.org/docs/develop/documentation/en/build_and_install/pip_install_en.html">please update your installation</a>.</p>
<hr/>
<h1>SE-ResNeXt for image classification</h1>
<p>This model built with paddle fluid is still under active development and is not
the final version. We welcome feedbacks.</p>
<h2>Introduction</h2>
<p>The current code support the training of <a href="https://arxiv.org/abs/1709.01507">SE-ResNeXt</a> (50/152 layers).</p>
<h2>Data Preparation</h2>
<ol>
<li>
<p>Download ImageNet-2012 dataset
</p><div class="highlight"><pre><span></span>cd data/
mkdir -p ILSVRC2012/
cd ILSVRC2012/
# get training set
wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_train.tar
# get validation set
wget http://www.image-net.org/challenges/LSVRC/2012/nnoupb/ILSVRC2012_img_val.tar
# prepare directory
tar xf ILSVRC2012_img_train.tar
tar xf ILSVRC2012_img_val.tar

# unzip all classes data using unzip.sh
sh unzip.sh
</pre></div>
</li>
<li>
<p>Download training and validation label files from <a href="https://pan.baidu.com/s/1Y6BCo0nmxsm_FsEqmx2hKQ">ImageNet2012 url</a>(password:<code>wx99</code>). Untar it into workspace <code>ILSVRC2012/</code>. The files include</p>
</li>
</ol>
<p><strong>train_list.txt</strong>: training list of imagenet 2012 classification task, with each line seperated by SPACE.
</p><div class="highlight"><pre><span></span>train/n02483708/n02483708_2436.jpeg 369
train/n03998194/n03998194_7015.jpeg 741
train/n04523525/n04523525_38118.jpeg 884
train/n04596742/n04596742_3032.jpeg 909
train/n03208938/n03208938_7065.jpeg 535
...
</pre></div>
<strong>val_list.txt</strong>: validation list of imagenet 2012 classification task, with each line seperated by SPACE.
<div class="highlight"><pre><span></span>val/ILSVRC2012_val_00000001.jpeg 65
val/ILSVRC2012_val_00000002.jpeg 970
val/ILSVRC2012_val_00000003.jpeg 230
val/ILSVRC2012_val_00000004.jpeg 809
val/ILSVRC2012_val_00000005.jpeg 516
...
</pre></div>
<strong>synset_words.txt</strong>: the semantic label of each class.
<h2>Training a model</h2>
<p>To start a training task, one can use command line as:</p>
<div class="highlight"><pre><span></span>python train.py --num_layers=50 --batch_size=8 --with_mem_opt=True --parallel_exe=False
</pre></div>
<h2>Finetune a model</h2>
<p></p><div class="highlight"><pre><span></span>python train.py --num_layers=50 --batch_size=8 --with_mem_opt=True --parallel_exe=False --pretrained_model="pretrain/96/"
</pre></div>
TBD
<h2>Inference</h2>
<p></p><div class="highlight"><pre><span></span>python infer.py --num_layers=50 --batch_size=8 --model='model/90' --test_list=''
</pre></div>
TBD
<h2>Results</h2>
<p>The SE-ResNeXt-50 model is trained by starting with learning rate <code>0.1</code> and decaying it by <code>0.1</code> after each <code>10</code> epoches. Top-1/Top-5 Validation Accuracy on ImageNet 2012 is listed in table.</p>
<table>
<thead>
<tr>
<th>model</th>
<th align="center"><a href="https://arxiv.org/abs/1709.01507">original paper(Fig.5)</a></th>
<th align="center">Pytorch</th>
<th align="right">Paddle fluid</th>
</tr>
</thead>
<tbody>
<tr>
<td>SE-ResNeXt-50</td>
<td align="center">77.6%/-</td>
<td align="center">77.71%/93.63%</td>
<td align="right">77.42%/93.50%</td>
</tr>
</tbody>
</table>
<h2>Released models</h2>
<table>
<thead>
<tr>
<th>model</th>
<th align="right">Baidu Cloud</th>
</tr>
</thead>
<tbody>
<tr>
<td>SE-ResNeXt-50</td>
<td align="right"><a href="">url</a></td>
</tr>
<tr>
<td>TBD</td>
<td align="right"></td>
</tr>
</tbody>
</table>
{% endverbatim %}
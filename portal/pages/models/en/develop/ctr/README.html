{% verbatim %}
<p>The minimum PaddlePaddle version needed for the code sample in this directory is v0.10.0. If you are on a version of PaddlePaddle earlier than v0.10.0, <a href="http://www.paddlepaddle.org/docs/develop/documentation/en/build_and_install/pip_install_en.html">please update your installation</a>.</p>
<hr/>
<h1>Click-Through Rate Prediction</h1>
<h2>Introduction</h2>
<p>CTR(Click-Through Rate)[<a href="https://en.wikipedia.org/wiki/Click-through_rate">1</a>]
is a prediction of the probability that a user clicks on an advertisement. This model is widely used in the advertisement industry. Accurate click rate estimates are important for maximizing online advertising revenue.</p>
<p>When there are multiple ad slots, CTR estimates are generally used as a baseline for ranking. For example, in a search engine's ad system, when the user enters a query, the system typically performs the following steps to show relevant ads.</p>
<ol>
<li>Get the ad collection associated with the user's search term.</li>
<li>Business rules and relevance filtering.</li>
<li>Rank by auction mechanism and CTR.</li>
<li>Show ads.</li>
</ol>
<p>Here，CTR plays a crucial role.</p>
<h3>Brief history</h3>
<p>Historically, the CTR prediction model has been evolving as follows.</p>
<ul>
<li>Logistic Regression(LR) / Gradient Boosting Decision Trees (GBDT) + feature engineering</li>
<li>LR + Deep Neural Network (DNN)</li>
<li>DNN + feature engineering</li>
</ul>
<p>In the early stages of development LR dominated, but the recent years DNN based models are mainly used.</p>
<h3>LR vs DNN</h3>
<p>The following figure shows the structure of LR and DNN model:</p>
<p align="center">
<img hspace="10" src="images/lr_vs_dnn.jpg" width="620"/> <br/>
Figure 1.  LR and DNN model structure comparison
</p>
<p>We can see, LR and CNN have some common structures. However, DNN can have non-linear relation between input and output values by adding activation unit and further layers. This enables DNN to achieve better learning results in CTR estimates.</p>
<p>In the following, we demonstrate how to use PaddlePaddle to learn to predict CTR.</p>
<h2>Data and Model formation</h2>
<p>Here <code>click</code> is the learning objective. There are several ways to learn the objectives.</p>
<ol>
<li>Direct learning click, 0,1 for binary classification</li>
<li>Learning to rank, pairwise rank or listwise rank</li>
<li>Measure the ad click rate of each ad, then rank by the click rate.</li>
</ol>
<p>In this example, we use the first method.</p>
<p>We use the Kaggle <code>Click-through rate prediction</code> task [<a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">2</a>].</p>
<p>Please see the <a href="./dataset.html">data process</a> for pre-processing data.</p>
<p>The input data format for the demo model in this tutorial is as follows:</p>
<div class="highlight"><pre><span></span># &lt;dnn input ids&gt; \t &lt;lr input sparse values&gt; \t click
1 23 190 \t 230:0.12 3421:0.9 23451:0.12 \t 0
23 231 \t 1230:0.12 13421:0.9 \t 1
</pre></div>
<p>Description：</p>
<ul>
<li><code>dnn input ids</code> one-hot coding.</li>
<li><code>lr input sparse values</code> Use <code>ID:VALUE</code> , values are preferaly scaled to the range <code>[-1, 1]</code>。</li>
</ul>
<p>此外，模型训练时需要传入一个文件描述 dnn 和 lr两个子模型的输入维度，文件的格式如下：</p>
<div class="highlight"><pre><span></span>dnn_input_dim: &lt;int&gt;
lr_input_dim: &lt;int&gt;
</pre></div>
<p><int> represents an integer value.</int></p>
<p><code>avazu_data_processor.py</code> can be used to download the data set [<a href="#参考文档">2</a>]and pre-process the data.</p>
<div class="highlight"><pre><span></span>usage: avazu_data_processer.py [-h] --data_path DATA_PATH --output_dir
                               OUTPUT_DIR
                               [--num_lines_to_detect NUM_LINES_TO_DETECT]
                               [--test_set_size TEST_SET_SIZE]
                               [--train_size TRAIN_SIZE]

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --data_path DATA_PATH
                        path of the Avazu dataset
  --output_dir OUTPUT_DIR
                        directory to output
  --num_lines_to_detect NUM_LINES_TO_DETECT
                        number of records to detect dataset's meta info
  --test_set_size TEST_SET_SIZE
                        size of the validation dataset(default: 10000)
  --train_size TRAIN_SIZE
                        size of the trainset (default: 100000)
</pre></div>
<ul>
<li><code>data_path</code> The data path to be processed</li>
<li><code>output_dir</code> The output path of the data</li>
<li><code>num_lines_to_detect</code> The number of generated IDs</li>
<li><code>test_set_size</code> The number of rows for the test set</li>
<li><code>train_size</code> The number of rows of training set</li>
</ul>
<h2>Wide &amp; Deep Learning Model</h2>
<p>Google proposed a model framework for Wide &amp; Deep Learning to integrate the advantages of both DNNs suitable for learning abstract features and LR models for large sparse features.</p>
<h3>Introduction to the model</h3>
<p>Wide &amp; Deep Learning Model[<a href="#References">3</a>] is a relatively mature model, but this model is still being used in the CTR predicting task. Here we demonstrate the use of this model to complete the CTR predicting task.</p>
<p>The model structure is as follows:</p>
<p align="center">
<img hspace="10" src="images/wide_deep.png" width="820"/> <br/>
Figure 2. Wide &amp; Deep Model
</p>
<p>The wide part of the top side of the model can accommodate large-scale coefficient features and has some memory for some specific information (such as ID); and the Deep part of the bottom side of the model can learn the implicit relationship between features.</p>
<h3>Model Input</h3>
<p>The model has three inputs as follows.</p>
<ul>
<li><code>dnn_input</code> ，the Deep part of the input</li>
<li><code>lr_input</code> ，the wide part of the input</li>
<li><code>click</code> ， click on or not</li>
</ul>
<div class="highlight"><pre><span></span><span class="n">dnn_merged_input</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'dnn_input'</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">sparse_binary_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dnn_input_dim</span><span class="p">))</span>

<span class="n">lr_merged_input</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s1">'lr_input'</span><span class="p">,</span>
    <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">sparse_vector</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr_input_dim</span><span class="p">))</span>

<span class="n">click</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'click'</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">dtype</span><span class="o">.</span><span class="n">dense_vector</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
<h3>Wide part</h3>
<p>Wide part uses of the LR model, but the activation function changed to <code>RELU</code> for speed.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_lr_submodel</span><span class="p">():</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">lr_merged_input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'lr'</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">fc</span>
</pre></div>
<h3>Deep part</h3>
<p>The Deep part uses a standard multi-layer DNN.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">build_dnn_submodel</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">):</span>
    <span class="n">dnn_embedding</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">dnn_merged_input</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">dnn_layer_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">dnn_embedding</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
        <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">_input_layer</span><span class="p">,</span>
            <span class="n">size</span><span class="o">=</span><span class="n">dim</span><span class="p">,</span>
            <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">(),</span>
            <span class="n">name</span><span class="o">=</span><span class="s1">'dnn-fc-</span><span class="si">%d</span><span class="s1">'</span> <span class="o">%</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">_input_layer</span> <span class="o">=</span> <span class="n">fc</span>
    <span class="k">return</span> <span class="n">_input_layer</span>
</pre></div>
<h3>Combine</h3>
<p>The output section uses <code>sigmoid</code> function to output (0,1) as the prediction value.</p>
<div class="highlight"><pre><span></span><span class="c1"># conbine DNN and LR submodels</span>
<span class="k">def</span> <span class="nf">combine_submodels</span><span class="p">(</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
    <span class="n">merge_layer</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">])</span>
    <span class="n">fc</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">merge_layer</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s1">'output'</span><span class="p">,</span>
        <span class="c1"># use sigmoid function to approximate ctr, wihch is a float value between 0 and 1.</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">fc</span>
</pre></div>
<h3>Training</h3>
<div class="highlight"><pre><span></span><span class="n">dnn</span> <span class="o">=</span> <span class="n">build_dnn_submodel</span><span class="p">(</span><span class="n">dnn_layer_dims</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">build_lr_submodel</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">combine_submodels</span><span class="p">(</span><span class="n">dnn</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>

<span class="c1"># ==============================================================================</span>
<span class="c1">#                   cost and train period</span>
<span class="c1"># ==============================================================================</span>
<span class="n">classification_cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">multi_binary_label_cross_entropy_cost</span><span class="p">(</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">output</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">click</span><span class="p">)</span>


<span class="n">paddle</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">trainer_count</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">classification_cost</span><span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span>
    <span class="n">cost</span><span class="o">=</span><span class="n">classification_cost</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">params</span><span class="p">,</span> <span class="n">update_equation</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">AvazuDataset</span><span class="p">(</span><span class="n">train_data_path</span><span class="p">,</span> <span class="n">n_records_as_test</span><span class="o">=</span><span class="n">test_set_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">event_handler</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndIteration</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Pass </span><span class="si">%d</span><span class="s2">, Samples </span><span class="si">%d</span><span class="s2">, Cost </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">1000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span>
                <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
                <span class="n">feeding</span><span class="o">=</span><span class="n">field_index</span><span class="p">)</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"Test </span><span class="si">%d</span><span class="s2">-</span><span class="si">%d</span><span class="s2">, Cost </span><span class="si">%f</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span>
                                           <span class="n">result</span><span class="o">.</span><span class="n">cost</span><span class="p">))</span>


<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
        <span class="n">paddle</span><span class="o">.</span><span class="n">reader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="n">buf_size</span><span class="o">=</span><span class="mi">500</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">),</span>
    <span class="n">feeding</span><span class="o">=</span><span class="n">field_index</span><span class="p">,</span>
    <span class="n">event_handler</span><span class="o">=</span><span class="n">event_handler</span><span class="p">,</span>
    <span class="n">num_passes</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
<h2>Run training and testing</h2>
<p>The model go through the following steps:</p>
<ol>
<li>Prepare training data<ol>
<li>Download train.gz from <a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">Kaggle CTR</a> .</li>
<li>Unzip train.gz to get train.txt</li>
<li><code>mkdir -p output; python avazu_data_processer.py --data_path train.txt --output_dir output --num_lines_to_detect 1000 --test_set_size 100</code> 生成演示数据</li>
</ol>
</li>
<li>Execute <code>python train.py --train_data_path ./output/train.txt --test_data_path ./output/test.txt --data_meta_file ./output/data.meta.txt --model_type=0</code>. Start training.</li>
</ol>
<p>The argument options for <code>train.py</code> are as follows.</p>
<div class="highlight"><pre><span></span>usage: train.py [-h] --train_data_path TRAIN_DATA_PATH
                [--test_data_path TEST_DATA_PATH] [--batch_size BATCH_SIZE]
                [--num_passes NUM_PASSES]
                [--model_output_prefix MODEL_OUTPUT_PREFIX] --data_meta_file
                DATA_META_FILE --model_type MODEL_TYPE

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --train_data_path TRAIN_DATA_PATH
                        path of training dataset
  --test_data_path TEST_DATA_PATH
                        path of testing dataset
  --batch_size BATCH_SIZE
                        size of mini-batch (default:10000)
  --num_passes NUM_PASSES
                        number of passes to train
  --model_output_prefix MODEL_OUTPUT_PREFIX
                        prefix of path for model to store (default:
                        ./ctr_models)
  --data_meta_file DATA_META_FILE
                        path of data meta info file
  --model_type MODEL_TYPE
                        model type, classification: 0, regression 1 (default
                        classification)
</pre></div>
<ul>
<li><code>train_data_path</code> ：  The path of the training set</li>
<li><code>test_data_path</code> : The path of the testing set</li>
<li><code>num_passes</code>: number of rounds of model training</li>
<li><code>data_meta_file</code>: Please refer to <a href="### 数据和任务抽象">数据和任务抽象</a>的描述。</li>
<li><code>model_type</code>:  Model classification or regressio</li>
</ul>
<h2>Use the training model for prediction</h2>
<p>The training model can be used to predict new data, and the format of the forecast data is as follows.</p>
<div class="highlight"><pre><span></span># &lt;dnn input ids&gt; \t &lt;lr input sparse values&gt;
1 23 190 \t 230:0.12 3421:0.9 23451:0.12
23 231 \t 1230:0.12 13421:0.9
</pre></div>
<p>Here the only difference to the training data is that there is no label (i.e. <code>click</code> values).</p>
<p>We now can use <code>infer.py</code> to perform inference.</p>
<div class="highlight"><pre><span></span>usage: infer.py [-h] --model_gz_path MODEL_GZ_PATH --data_path DATA_PATH
                --prediction_output_path PREDICTION_OUTPUT_PATH
                [--data_meta_path DATA_META_PATH] --model_type MODEL_TYPE

PaddlePaddle CTR example

optional arguments:
  -h, --help            show this help message and exit
  --model_gz_path MODEL_GZ_PATH
                        path of model parameters gz file
  --data_path DATA_PATH
                        path of the dataset to infer
  --prediction_output_path PREDICTION_OUTPUT_PATH
                        path to output the prediction
  --data_meta_path DATA_META_PATH
                        path of trainset's meta info, default is ./data.meta
  --model_type MODEL_TYPE
                        model type, classification: 0, regression 1 (default
                        classification)
</pre></div>
<ul>
<li><code>model_gz_path_model</code>：path for <code>gz</code> compressed data.</li>
<li><code>data_path</code> ：</li>
<li><code>prediction_output_patj</code>：path for the predicted values s</li>
<li><code>data_meta_file</code> ：Please refer to <a href="### 数据和任务抽象">数据和任务抽象</a>。</li>
<li><code>model_type</code> ：Classification or regression</li>
</ul>
<p>The sample data can be predicted with the following command</p>
<div class="highlight"><pre><span></span>python infer.py --model_gz_path &lt;model_path&gt; --data_path output/infer.txt --prediction_output_path predictions.txt --data_meta_path data.meta.txt
</pre></div>
<p>The final prediction is written in  <code>predictions.txt</code>。</p>
<h2>References</h2>
<ol>
<li><a href="https://en.wikipedia.org/wiki/Click-through_rate">https://en.wikipedia.org/wiki/Click-through_rate</a></li>
<li><a href="https://www.kaggle.com/c/avazu-ctr-prediction/data">https://www.kaggle.com/c/avazu-ctr-prediction/data</a></li>
<li>Cheng H T, Koc L, Harmsen J, et al. <a href="https://arxiv.org/pdf/1606.07792.pdf">Wide &amp; deep learning for recommender systems</a>[C]//Proceedings of the 1st Workshop on Deep Learning for Recommender Systems. ACM, 2016: 7-10.</li>
</ol>
{% endverbatim %}
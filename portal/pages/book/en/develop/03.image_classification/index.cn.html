{% verbatim %}
<h1>图像分类</h1>
<p>本教程源代码目录在<a href="https://github.com/PaddlePaddle/book/tree/develop/03.image_classification">book/image_classification</a>， 初次使用请参考PaddlePaddle<a href="https://github.com/PaddlePaddle/book/blob/develop/README.cn.md#运行这本书">安装教程</a>，更多内容请参考本教程的<a href="http://bit.baidu.com/course/detail/id/168.html">视频课堂</a>。</p>
<h2>背景介绍</h2>
<p>图像相比文字能够提供更加生动、容易理解及更具艺术感的信息，是人们转递与交换信息的重要来源。在本教程中，我们专注于图像识别领域的一个重要问题，即图像分类。</p>
<p>图像分类是根据图像的语义信息将不同类别图像区分开来，是计算机视觉中重要的基本问题，也是图像检测、图像分割、物体跟踪、行为分析等其他高层视觉任务的基础。图像分类在很多领域有广泛应用，包括安防领域的人脸识别和智能视频分析等，交通领域的交通场景识别，互联网领域基于内容的图像检索和相册自动归类，医学领域的图像识别等。</p>
<p>一般来说，图像分类通过手工特征或特征学习方法对整个图像进行全部描述，然后使用分类器判别物体类别，因此如何提取图像的特征至关重要。在深度学习算法之前使用较多的是基于词袋(Bag of Words)模型的物体分类方法。词袋方法从自然语言处理中引入，即一句话可以用一个装了词的袋子表示其特征，袋子中的词为句子中的单词、短语或字。对于图像而言，词袋方法需要构建字典。最简单的词袋模型框架可以设计为<strong>底层特征抽取</strong>、<strong>特征编码</strong>、<strong>分类器设计</strong>三个过程。</p>
<p>而基于深度学习的图像分类方法，可以通过有监督或无监督的方式<strong>学习</strong>层次化的特征描述，从而取代了手工设计或选择图像特征的工作。深度学习模型中的卷积神经网络(Convolution Neural Network, CNN)近年来在图像领域取得了惊人的成绩，CNN直接利用图像像素信息作为输入，最大程度上保留了输入图像的所有信息，通过卷积操作进行特征的提取和高层抽象，模型输出直接是图像识别的结果。这种基于"输入-输出"直接端到端的学习方法取得了非常好的效果，得到了广泛的应用。</p>
<p>本教程主要介绍图像分类的深度学习模型，以及如何使用PaddlePaddle训练CNN模型。</p>
<h2>效果展示</h2>
<p>图像分类包括通用图像分类、细粒度图像分类等。图1展示了通用图像分类效果，即模型可以正确识别图像上的主要物体。</p>
<p align="center">
<img src="image/dog_cat.png " width="350"/><br/>
图1. 通用图像分类展示
</p>
<p>图2展示了细粒度图像分类-花卉识别的效果，要求模型可以正确识别花的类别。</p>
<p align="center">
<img src="image/flowers.png" width="400"/><br/>
图2. 细粒度图像分类展示
</p>
<p>一个好的模型既要对不同类别识别正确，同时也应该能够对不同视角、光照、背景、变形或部分遮挡的图像正确识别(这里我们统一称作图像扰动)。图3展示了一些图像的扰动，较好的模型会像聪明的人类一样能够正确识别。</p>
<p align="center">
<img src="image/variations.png" width="550"/><br/>
图3. 扰动图片展示[22]
</p>
<h2>模型概览</h2>
<p>图像识别领域大量的研究成果都是建立在<a href="http://host.robots.ox.ac.uk/pascal/VOC/">PASCAL VOC</a>、<a href="http://image-net.org/">ImageNet</a>等公开的数据集上，很多图像识别算法通常在这些数据集上进行测试和比较。PASCAL VOC是2005年发起的一个视觉挑战赛，ImageNet是2010年发起的大规模视觉识别竞赛(ILSVRC)的数据集，在本章中我们基于这些竞赛的一些论文介绍图像分类模型。</p>
<p>在2012年之前的传统图像分类方法可以用背景描述中提到的三步完成，但通常完整建立图像识别模型一般包括底层特征学习、特征编码、空间约束、分类器设计、模型融合等几个阶段。
  1). <strong>底层特征提取</strong>: 通常从图像中按照固定步长、尺度提取大量局部特征描述。常用的局部特征包括SIFT(Scale-Invariant Feature Transform, 尺度不变特征转换) [<a href="#参考文献">1</a>]、HOG(Histogram of Oriented Gradient, 方向梯度直方图) [<a href="#参考文献">2</a>]、LBP(Local Bianray Pattern, 局部二值模式) [<a href="#参考文献">3</a>] 等，一般也采用多种特征描述子，防止丢失过多的有用信息。
  2). <strong>特征编码</strong>: 底层特征中包含了大量冗余与噪声，为了提高特征表达的鲁棒性，需要使用一种特征变换算法对底层特征进行编码，称作特征编码。常用的特征编码包括向量量化编码 [<a href="#参考文献">4</a>]、稀疏编码 [<a href="#参考文献">5</a>]、局部线性约束编码 [<a href="#参考文献">6</a>]、Fisher向量编码 [<a href="#参考文献">7</a>] 等。
  3). <strong>空间特征约束</strong>: 特征编码之后一般会经过空间特征约束，也称作<strong>特征汇聚</strong>。特征汇聚是指在一个空间范围内，对每一维特征取最大值或者平均值，可以获得一定特征不变形的特征表达。金字塔特征匹配是一种常用的特征聚会方法，这种方法提出将图像均匀分块，在分块内做特征汇聚。
  4). <strong>通过分类器分类</strong>: 经过前面步骤之后一张图像可以用一个固定维度的向量进行描述，接下来就是经过分类器对图像进行分类。通常使用的分类器包括SVM(Support Vector Machine, 支持向量机)、随机森林等。而使用核方法的SVM是最为广泛的分类器，在传统图像分类任务上性能很好。</p>
<p>这种方法在PASCAL VOC竞赛中的图像分类算法中被广泛使用 [<a href="#参考文献">18</a>]。<a href="http://www.nec-labs.com/">NEC实验室</a>在ILSVRC2010中采用SIFT和LBP特征，两个非线性编码器以及SVM分类器获得图像分类的冠军 [<a href="#参考文献">8</a>]。</p>
<p>Alex Krizhevsky在2012年ILSVRC提出的CNN模型 [<a href="#参考文献">9</a>] 取得了历史性的突破，效果大幅度超越传统方法，获得了ILSVRC2012冠军，该模型被称作AlexNet。这也是首次将深度学习用于大规模图像分类中。从AlexNet之后，涌现了一系列CNN模型，不断地在ImageNet上刷新成绩，如图4展示。随着模型变得越来越深以及精妙的结构设计，Top-5的错误率也越来越低，降到了3.5%附近。而在同样的ImageNet数据集上，人眼的辨识错误率大概在5.1%，也就是目前的深度学习模型的识别能力已经超过了人眼。</p>
<p align="center">
<img src="image/ilsvrc.png" width="500"/><br/>
图4. ILSVRC图像分类Top-5错误率
</p>
<h3>CNN</h3>
<p>传统CNN包含卷积层、全连接层等组件，并采用softmax多类别分类器和多类交叉熵损失函数，一个典型的卷积神经网络如图5所示，我们先介绍用来构造CNN的常见组件。</p>
<p align="center">
<img src="image/lenet.png"/><br/>
图5. CNN网络示例[20]
</p>
<ul>
<li>卷积层(convolution layer): 执行卷积操作提取底层到高层的特征，发掘出图片局部关联性质和空间不变性质。</li>
<li>池化层(pooling layer): 执行降采样操作。通过取卷积输出特征图中局部区块的最大值(max-pooling)或者均值(avg-pooling)。降采样也是图像处理中常见的一种操作，可以过滤掉一些不重要的高频信息。</li>
<li>全连接层(fully-connected layer，或者fc layer): 输入层到隐藏层的神经元是全部连接的。</li>
<li>非线性变化: 卷积层、全连接层后面一般都会接非线性变化层，例如Sigmoid、Tanh、ReLu等来增强网络的表达能力，在CNN里最常使用的为ReLu激活函数。</li>
<li>Dropout [<a href="#参考文献">10</a>] : 在模型训练阶段随机让一些隐层节点权重不工作，提高网络的泛化能力，一定程度上防止过拟合。</li>
</ul>
<p>另外，在训练过程中由于每层参数不断更新，会导致下一次输入分布发生变化，这样导致训练过程需要精心设计超参数。如2015年Sergey Ioffe和Christian Szegedy提出了Batch Normalization (BN)算法 [<a href="#参考文献">14</a>] 中，每个batch对网络中的每一层特征都做归一化，使得每层分布相对稳定。BN算法不仅起到一定的正则作用，而且弱化了一些超参数的设计。经过实验证明，BN算法加速了模型收敛过程，在后来较深的模型中被广泛使用。</p>
<p>接下来我们主要介绍VGG，GoogleNet和ResNet网络结构。</p>
<h3>VGG</h3>
<p>牛津大学VGG(Visual Geometry Group)组在2014年ILSVRC提出的模型被称作VGG模型 [<a href="#参考文献">11</a>] 。该模型相比以往模型进一步加宽和加深了网络结构，它的核心是五组卷积操作，每两组之间做Max-Pooling空间降维。同一组内采用多次连续的3X3卷积，卷积核的数目由较浅组的64增多到最深组的512，同一组内的卷积核数目是一样的。卷积之后接两层全连接层，之后是分类层。由于每组内卷积层的不同，有11、13、16、19层这几种模型，下图展示一个16层的网络结构。VGG模型结构相对简洁，提出之后也有很多文章基于此模型进行研究，如在ImageNet上首次公开超过人眼识别的模型[<a href="#参考文献">19</a>]就是借鉴VGG模型的结构。</p>
<p align="center">
<img src="image/vgg16.png" width="750"/><br/>
图6. 基于ImageNet的VGG16模型
</p>
<h3>GoogleNet</h3>
<p>GoogleNet [<a href="#参考文献">12</a>] 在2014年ILSVRC的获得了冠军，在介绍该模型之前我们先来了解NIN(Network in Network)模型 [<a href="#参考文献">13</a>] 和Inception模块，因为GoogleNet模型由多组Inception模块组成，模型设计借鉴了NIN的一些思想。</p>
<p>NIN模型主要有两个特点：1) 引入了多层感知卷积网络(Multi-Layer Perceptron Convolution, MLPconv)代替一层线性卷积网络。MLPconv是一个微小的多层卷积网络，即在线性卷积后面增加若干层1x1的卷积，这样可以提取出高度非线性特征。2) 传统的CNN最后几层一般都是全连接层，参数较多。而NIN模型设计最后一层卷积层包含类别维度大小的特征图，然后采用全局均值池化(Avg-Pooling)替代全连接层，得到类别维度大小的向量，再进行分类。这种替代全连接层的方式有利于减少参数。</p>
<p>Inception模块如下图7所示，图(a)是最简单的设计，输出是3个卷积层和一个池化层的特征拼接。这种设计的缺点是池化层不会改变特征通道数，拼接后会导致特征的通道数较大，经过几层这样的模块堆积后，通道数会越来越大，导致参数和计算量也随之增大。为了改善这个缺点，图(b)引入3个1x1卷积层进行降维，所谓的降维就是减少通道数，同时如NIN模型中提到的1x1卷积也可以修正线性特征。</p>
<p align="center">
<img src="image/inception.png" width="800"/><br/>
图7. Inception模块
</p>
<p>GoogleNet由多组Inception模块堆积而成。另外，在网络最后也没有采用传统的多层全连接层，而是像NIN网络一样采用了均值池化层；但与NIN不同的是，池化层后面接了一层到类别数映射的全连接层。除了这两个特点之外，由于网络中间层特征也很有判别性，GoogleNet在中间层添加了两个辅助分类器，在后向传播中增强梯度并且增强正则化，而整个网络的损失函数是这个三个分类器的损失加权求和。</p>
<p>GoogleNet整体网络结构如图8所示，总共22层网络：开始由3层普通的卷积组成；接下来由三组子网络组成，第一组子网络包含2个Inception模块，第二组包含5个Inception模块，第三组包含2个Inception模块；然后接均值池化层、全连接层。</p>
<p align="center">
<img src="image/googlenet.jpeg"/><br/>
图8. GoogleNet[12]
</p>
<p>上面介绍的是GoogleNet第一版模型(称作GoogleNet-v1)。GoogleNet-v2 [<a href="#参考文献">14</a>] 引入BN层；GoogleNet-v3 [<a href="#参考文献">16</a>] 对一些卷积层做了分解，进一步提高网络非线性能力和加深网络；GoogleNet-v4 [<a href="#参考文献">17</a>] 引入下面要讲的ResNet设计思路。从v1到v4每一版的改进都会带来准确度的提升，介于篇幅，这里不再详细介绍v2到v4的结构。</p>
<h3>ResNet</h3>
<p>ResNet(Residual Network) [<a href="#参考文献">15</a>] 是2015年ImageNet图像分类、图像物体定位和图像物体检测比赛的冠军。针对训练卷积神经网络时加深网络导致准确度下降的问题，ResNet提出了采用残差学习。在已有设计思路(BN, 小卷积核，全卷积网络)的基础上，引入了残差模块。每个残差模块包含两条路径，其中一条路径是输入特征的直连通路，另一条路径对该特征做两到三次卷积操作得到该特征的残差，最后再将两条路径上的特征相加。</p>
<p>残差模块如图9所示，左边是基本模块连接方式，由两个输出通道数相同的3x3卷积组成。右边是瓶颈模块(Bottleneck)连接方式，之所以称为瓶颈，是因为上面的1x1卷积用来降维(图示例即256-&gt;64)，下面的1x1卷积用来升维(图示例即64-&gt;256)，这样中间3x3卷积的输入和输出通道数都较小(图示例即64-&gt;64)。</p>
<p align="center">
<img src="image/resnet_block.jpg" width="400"/><br/>
图9. 残差模块
</p>
<p>图10展示了50、101、152层网络连接示意图，使用的是瓶颈模块。这三个模型的区别在于每组中残差模块的重复次数不同(见图右上角)。ResNet训练收敛较快，成功的训练了上百乃至近千层的卷积神经网络。</p>
<p align="center">
<img src="image/resnet.png"/><br/>
图10. 基于ImageNet的ResNet模型
</p>
<h2>数据准备</h2>
<p>通用图像分类公开的标准数据集常用的有<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a>、<a href="http://image-net.org/">ImageNet</a>、<a href="http://mscoco.org/">COCO</a>等，常用的细粒度图像分类数据集包括<a href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html">CUB-200-2011</a>、<a href="http://vision.stanford.edu/aditya86/ImageNetDogs/">Stanford Dog</a>、<a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/">Oxford-flowers</a>等。其中ImageNet数据集规模相对较大，如<a href="#模型概览">模型概览</a>一章所讲，大量研究成果基于ImageNet。ImageNet数据从2010年来稍有变化，常用的是ImageNet-2012数据集，该数据集包含1000个类别：训练集包含1,281,167张图片，每个类别数据732至1300张不等，验证集包含50,000张图片，平均每个类别50张图片。</p>
<p>由于ImageNet数据集较大，下载和训练较慢，为了方便大家学习，我们使用<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a>数据集。CIFAR10数据集包含60,000张32x32的彩色图片，10个类别，每个类包含6,000张。其中50,000张图片作为训练集，10000张作为测试集。图11从每个类别中随机抽取了10张图片，展示了所有的类别。</p>
<p align="center">
<img src="image/cifar.png" width="350"/><br/>
图11. CIFAR10数据集[21]
</p>
<p>Paddle API提供了自动加载cifar数据集模块 <code>paddle.dataset.cifar</code>。</p>
<p>通过输入<code>python train.py</code>，就可以开始训练模型了，以下小节将详细介绍<code>train.py</code>的相关内容。</p>
<h3>模型结构</h3>
<h4>Paddle 初始化</h4>
<p>通过 <code>paddle.init</code>，初始化Paddle是否使用GPU，trainer的数目等等。</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">paddle.v2</span> <span class="kn">as</span> <span class="nn">paddle</span>
<span class="kn">from</span> <span class="nn">vgg</span> <span class="kn">import</span> <span class="n">vgg_bn_drop</span>
<span class="kn">from</span> <span class="nn">resnet</span> <span class="kn">import</span> <span class="n">resnet_cifar10</span>

<span class="c1"># PaddlePaddle init</span>
<span class="n">paddle</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">use_gpu</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">trainer_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
<p>本教程中我们提供了VGG和ResNet两个模型的配置。</p>
<h4>VGG</h4>
<p>首先介绍VGG模型结构，由于CIFAR10图片大小和数量相比ImageNet数据小很多，因此这里的模型针对CIFAR10数据做了一定的适配。卷积部分引入了BN和Dropout操作。</p>
<ol>
<li>
<p>定义数据输入及其维度</p>
<p>网络输入定义为 <code>data_layer</code> (数据层)，在图像分类中即为图像像素信息。CIFRAR10是RGB 3通道32x32大小的彩色图，因此输入数据大小为3072(3x32x32)，类别大小为10，即10分类。</p>
<div class="highlight"><pre><span></span><span class="n">datadim</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span>
<span class="n">classdim</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"image"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">dense_vector</span><span class="p">(</span><span class="n">datadim</span><span class="p">))</span>
</pre></div>
</li>
<li>
<p>定义VGG网络核心模块</p>
<p></p><div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">vgg_bn_drop</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
VGG核心模块的输入是数据层，<code>vgg_bn_drop</code> 定义了16层VGG结构，每层卷积后面引入BN层和Dropout层，详细的定义如下：
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">vgg_bn_drop</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">conv_block</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">num_filter</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">dropouts</span><span class="p">,</span> <span class="n">num_channels</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">paddle</span><span class="o">.</span><span class="n">networks</span><span class="o">.</span><span class="n">img_conv_group</span><span class="p">(</span>
            <span class="nb">input</span><span class="o">=</span><span class="n">ipt</span><span class="p">,</span>
            <span class="n">num_channels</span><span class="o">=</span><span class="n">num_channels</span><span class="p">,</span>
            <span class="n">pool_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">pool_stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">conv_num_filter</span><span class="o">=</span><span class="p">[</span><span class="n">num_filter</span><span class="p">]</span> <span class="o">*</span> <span class="n">groups</span><span class="p">,</span>
            <span class="n">conv_filter_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
            <span class="n">conv_act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">(),</span>
            <span class="n">conv_with_batchnorm</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">conv_batchnorm_drop_rate</span><span class="o">=</span><span class="n">dropouts</span><span class="p">,</span>
            <span class="n">pool_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">Max</span><span class="p">())</span>

    <span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">conv2</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">conv3</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">conv4</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="n">conv3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">conv5</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="n">conv4</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="n">drop</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">conv5</span><span class="p">,</span> <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">fc1</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">drop</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>
    <span class="n">bn</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">fc1</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">(),</span>
        <span class="n">layer_attr</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">attr</span><span class="o">.</span><span class="n">Extra</span><span class="p">(</span><span class="n">drop_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
    <span class="n">fc2</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">bn</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">fc2</span>
</pre></div>
<p>2.1. 首先定义了一组卷积网络，即conv_block。卷积核大小为3x3，池化窗口大小为2x2，窗口滑动大小为2，groups决定每组VGG模块是几次连续的卷积操作，dropouts指定Dropout操作的概率。所使用的<code>img_conv_group</code>是在<code>paddle.networks</code>中预定义的模块，由若干组 Conv-&gt;BN-&gt;ReLu-&gt;Dropout 和 一组 Pooling 组成。</p>
<p>2.2. 五组卷积操作，即 5个conv_block。 第一、二组采用两次连续的卷积操作。第三、四、五组采用三次连续的卷积操作。每组最后一个卷积后面Dropout概率为0，即不使用Dropout操作。</p>
<p>2.3. 最后接两层512维的全连接。</p>
</li>
<li>
<p>定义分类器</p>
<p>通过上面VGG网络提取高层特征，然后经过全连接层映射到类别维度大小的向量，再通过Softmax归一化得到每个类别的概率，也可称作分类器。</p>
<div class="highlight"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">net</span><span class="p">,</span>
                      <span class="n">size</span><span class="o">=</span><span class="n">classdim</span><span class="p">,</span>
                      <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Softmax</span><span class="p">())</span>
</pre></div>
</li>
<li>
<p>定义损失函数和网络输出</p>
<p>在有监督训练中需要输入图像对应的类别信息，同样通过<code>paddle.layer.data</code>来定义。训练中采用多类交叉熵作为损失函数，并作为网络的输出，预测阶段定义网络的输出为分类器得到的概率信息。</p>
<div class="highlight"><pre><span></span><span class="n">lbl</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">data</span><span class="p">(</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">"label"</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">data_type</span><span class="o">.</span><span class="n">integer_value</span><span class="p">(</span><span class="n">classdim</span><span class="p">))</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">classification_cost</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lbl</span><span class="p">)</span>
</pre></div>
</li>
</ol>
<h3>ResNet</h3>
<p>ResNet模型的第1、3、4步和VGG模型相同，这里不再介绍。主要介绍第2步即CIFAR10数据集上ResNet核心模块。</p>
<div class="highlight"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">resnet_cifar10</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">56</span><span class="p">)</span>
</pre></div>
<p>先介绍<code>resnet_cifar10</code>中的一些基本函数，再介绍网络连接过程。</p>
<ul>
<li><code>conv_bn_layer</code> : 带BN的卷积层。</li>
<li><code>shortcut</code> : 残差模块的"直连"路径，"直连"实际分两种形式：残差模块输入和输出特征通道数不等时，采用1x1卷积的升维操作；残差模块输入和输出通道相等时，采用直连操作。</li>
<li><code>basicblock</code> : 一个基础残差模块，即图9左边所示，由两组3x3卷积组成的路径和一条"直连"路径组成。</li>
<li><code>bottleneck</code> : 一个瓶颈残差模块，即图9右边所示，由上下1x1卷积和中间3x3卷积组成的路径和一条"直连"路径组成。</li>
<li><code>layer_warp</code> : 一组残差模块，由若干个残差模块堆积而成。每组中第一个残差模块滑动窗口大小与其他可以不同，以用来减少特征图在垂直和水平方向的大小。</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conv_bn_layer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span>
                  <span class="n">ch_out</span><span class="p">,</span>
                  <span class="n">filter_size</span><span class="p">,</span>
                  <span class="n">stride</span><span class="p">,</span>
                  <span class="n">padding</span><span class="p">,</span>
                  <span class="n">active_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">(),</span>
                  <span class="n">ch_in</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">img_conv</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="nb">input</span><span class="p">,</span>
        <span class="n">filter_size</span><span class="o">=</span><span class="n">filter_size</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="o">=</span><span class="n">ch_in</span><span class="p">,</span>
        <span class="n">num_filters</span><span class="o">=</span><span class="n">ch_out</span><span class="p">,</span>
        <span class="n">stride</span><span class="o">=</span><span class="n">stride</span><span class="p">,</span>
        <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">(),</span>
        <span class="n">bias_attr</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">batch_norm</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">tmp</span><span class="p">,</span> <span class="n">act</span><span class="o">=</span><span class="n">active_type</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">shortcut</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">n_in</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">n_in</span> <span class="o">!=</span> <span class="n">n_out</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">conv_bn_layer</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">n_out</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
                             <span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ipt</span>

<span class="k">def</span> <span class="nf">basicblock</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">ch_out</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="n">ch_in</span> <span class="o">=</span> <span class="n">ch_out</span> <span class="o">*</span> <span class="mi">2</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">conv_bn_layer</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">ch_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">conv_bn_layer</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">ch_out</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>
    <span class="n">short</span> <span class="o">=</span> <span class="n">shortcut</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">ch_in</span><span class="p">,</span> <span class="n">ch_out</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">addto</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="p">[</span><span class="n">tmp</span><span class="p">,</span> <span class="n">short</span><span class="p">],</span> <span class="n">act</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">activation</span><span class="o">.</span><span class="n">Relu</span><span class="p">())</span>

<span class="k">def</span> <span class="nf">layer_warp</span><span class="p">(</span><span class="n">block_func</span><span class="p">,</span> <span class="n">ipt</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="n">stride</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">block_func</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">stride</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">count</span><span class="p">):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">block_func</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tmp</span>
</pre></div>
<p><code>resnet_cifar10</code> 的连接结构主要有以下几个过程。</p>
<ol>
<li>底层输入连接一层 <code>conv_bn_layer</code>，即带BN的卷积层。</li>
<li>然后连接3组残差模块即下面配置3组 <code>layer_warp</code> ，每组采用图 10 左边残差模块组成。</li>
<li>最后对网络做均值池化并返回该层。</li>
</ol>
<p>注意：除过第一层卷积层和最后一层全连接层之外，要求三组 <code>layer_warp</code> 总的含参层数能够被6整除，即 <code>resnet_cifar10</code> 的 depth 要满足 <span class="markdown-equation" id="equation-0">$(depth - 2) % 6 == 0$</span> 。</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">resnet_cifar10</span><span class="p">(</span><span class="n">ipt</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">32</span><span class="p">):</span>
    <span class="c1"># depth should be one of 20, 32, 44, 56, 110, 1202</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">depth</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">%</span> <span class="mi">6</span> <span class="o">==</span> <span class="mi">0</span>
    <span class="n">n</span> <span class="o">=</span> <span class="p">(</span><span class="n">depth</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">6</span>
    <span class="n">nStages</span> <span class="o">=</span> <span class="p">{</span><span class="mi">16</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">}</span>
    <span class="n">conv1</span> <span class="o">=</span> <span class="n">conv_bn_layer</span><span class="p">(</span>
        <span class="n">ipt</span><span class="p">,</span> <span class="n">ch_in</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ch_out</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">res1</span> <span class="o">=</span> <span class="n">layer_warp</span><span class="p">(</span><span class="n">basicblock</span><span class="p">,</span> <span class="n">conv1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">res2</span> <span class="o">=</span> <span class="n">layer_warp</span><span class="p">(</span><span class="n">basicblock</span><span class="p">,</span> <span class="n">res1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">res3</span> <span class="o">=</span> <span class="n">layer_warp</span><span class="p">(</span><span class="n">basicblock</span><span class="p">,</span> <span class="n">res2</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">pool</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">layer</span><span class="o">.</span><span class="n">img_pool</span><span class="p">(</span>
        <span class="nb">input</span><span class="o">=</span><span class="n">res3</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pool_type</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">pooling</span><span class="o">.</span><span class="n">Avg</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">pool</span>
</pre></div>
<h2>训练模型</h2>
<h3>定义参数</h3>
<p>首先依据模型配置的<code>cost</code>定义模型参数。</p>
<div class="highlight"><pre><span></span><span class="c1"># Create parameters</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</pre></div>
<p>可以打印参数名字，如果在网络配置中没有指定名字，则默认生成。</p>
<div class="highlight"><pre><span></span><span class="k">print</span> <span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
<h3>构造训练(Trainer)</h3>
<p>根据网络拓扑结构和模型参数来构造出trainer用来训练，在构造时还需指定优化方法，这里使用最基本的Momentum方法，同时设定了学习率、正则等。</p>
<div class="highlight"><pre><span></span><span class="c1"># Create optimizer</span>
<span class="n">momentum_optimizer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span>
    <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">regularization</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">L2Regularization</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.0002</span> <span class="o">*</span> <span class="mi">128</span><span class="p">),</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span> <span class="o">/</span> <span class="mf">128.0</span><span class="p">,</span>
    <span class="n">learning_rate_decay_a</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">learning_rate_decay_b</span><span class="o">=</span><span class="mi">50000</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">learning_rate_schedule</span><span class="o">=</span><span class="s1">'discexp'</span><span class="p">)</span>

<span class="c1"># Create trainer</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">cost</span><span class="o">=</span><span class="n">cost</span><span class="p">,</span>
                             <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span>
                             <span class="n">update_equation</span><span class="o">=</span><span class="n">momentum_optimizer</span><span class="p">)</span>
</pre></div>
<p>通过 <code>learning_rate_decay_a</code> (简写<span class="markdown-equation" id="equation-1">$a$</span>） 、<code>learning_rate_decay_b</code> (简写<span class="markdown-equation" id="equation-2">$b$</span>) 和 <code>learning_rate_schedule</code> 指定学习率调整策略，这里采用离散指数的方式调节学习率，计算公式如下， <span class="markdown-equation" id="equation-3">$n$</span> 代表已经处理过的累计总样本数，<span class="markdown-equation" id="equation-4">$lr_{0}$</span> 即为 <code>settings</code> 里设置的 <code>learning_rate</code>。</p>
<p><span class="markdown-equation" id="equation-5">$$  lr = lr_{0} * a^ {\lfloor \frac{n}{ b}\rfloor} $$</span></p>
<h3>训练</h3>
<p>cifar.train10()每次产生一条样本，在完成shuffle和batch之后，作为训练的输入。</p>
<div class="highlight"><pre><span></span><span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
    <span class="n">paddle</span><span class="o">.</span><span class="n">reader</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span>
        <span class="n">paddle</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">cifar</span><span class="o">.</span><span class="n">train10</span><span class="p">(),</span> <span class="n">buf_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">),</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">)</span>
</pre></div>
<p>通过<code>feeding</code>来指定每一个数据和<code>paddle.layer.data</code>的对应关系。例如: <code>cifar.train10()</code>产生数据的第0列对应image层的特征。</p>
<div class="highlight"><pre><span></span><span class="n">feeding</span><span class="o">=</span><span class="p">{</span><span class="s1">'image'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
         <span class="s1">'label'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
</pre></div>
<p>可以使用<code>event_handler</code>回调函数来观察训练过程，或进行测试等, 该回调函数是<code>trainer.train</code>函数里设定。</p>
<p><code>event_handler_plot</code>可以用来利用回调数据来打点画图:</p>
<p><img alt="png" src="./image/train_and_test.png"/></p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">paddle.v2.plot</span> <span class="kn">import</span> <span class="n">Ploter</span>

<span class="n">train_title</span> <span class="o">=</span> <span class="s2">"Train cost"</span>
<span class="n">test_title</span> <span class="o">=</span> <span class="s2">"Test cost"</span>
<span class="n">cost_ploter</span> <span class="o">=</span> <span class="n">Ploter</span><span class="p">(</span><span class="n">train_title</span><span class="p">,</span> <span class="n">test_title</span><span class="p">)</span>

<span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">def</span> <span class="nf">event_handler_plot</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">step</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndIteration</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">cost_ploter</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_title</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>
            <span class="n">cost_ploter</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
        <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndPass</span><span class="p">):</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span>
            <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                <span class="n">paddle</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">cifar</span><span class="o">.</span><span class="n">test10</span><span class="p">(),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">feeding</span><span class="o">=</span><span class="n">feeding</span><span class="p">)</span>
        <span class="n">cost_ploter</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_title</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">cost</span><span class="p">)</span>
</pre></div>
<p><code>event_handler</code> 用来在训练过程中输出文本日志</p>
<div class="highlight"><pre><span></span><span class="c1"># End batch and end pass event handler</span>
<span class="k">def</span> <span class="nf">event_handler</span><span class="p">(</span><span class="n">event</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndIteration</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">Pass </span><span class="si">%d</span><span class="s2">, Batch </span><span class="si">%d</span><span class="s2">, Cost </span><span class="si">%f</span><span class="s2">, </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span>
                <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">batch_id</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">cost</span><span class="p">,</span> <span class="n">event</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">event</span><span class="p">,</span> <span class="n">paddle</span><span class="o">.</span><span class="n">event</span><span class="o">.</span><span class="n">EndPass</span><span class="p">):</span>
        <span class="c1"># save parameters</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'params_pass_</span><span class="si">%d</span><span class="s1">.tar'</span> <span class="o">%</span> <span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="s1">'w'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">save_parameter_to_tar</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

        <span class="n">result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">test</span><span class="p">(</span>
            <span class="n">reader</span><span class="o">=</span><span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
                <span class="n">paddle</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">cifar</span><span class="o">.</span><span class="n">test10</span><span class="p">(),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">),</span>
            <span class="n">feeding</span><span class="o">=</span><span class="n">feeding</span><span class="p">)</span>
        <span class="k">print</span> <span class="s2">"</span><span class="se">\n</span><span class="s2">Test with Pass </span><span class="si">%d</span><span class="s2">, </span><span class="si">%s</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">event</span><span class="o">.</span><span class="n">pass_id</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">metrics</span><span class="p">)</span>
</pre></div>
<p>通过<code>trainer.train</code>函数训练:</p>
<div class="highlight"><pre><span></span><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">reader</span><span class="o">=</span><span class="n">reader</span><span class="p">,</span>
    <span class="n">num_passes</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
    <span class="n">event_handler</span><span class="o">=</span><span class="n">event_handler_plot</span><span class="p">,</span>
    <span class="n">feeding</span><span class="o">=</span><span class="n">feeding</span><span class="p">)</span>
</pre></div>
<p>一轮训练log示例如下所示，经过1个pass， 训练集上平均error为0.6875 ，测试集上平均error为0.8852 。</p>
<div class="highlight"><pre><span></span>Pass 0, Batch 0, Cost 2.473182, {'classification_error_evaluator': 0.9140625}
...................................................................................................
Pass 0, Batch 100, Cost 1.913076, {'classification_error_evaluator': 0.78125}
...................................................................................................
Pass 0, Batch 200, Cost 1.783041, {'classification_error_evaluator': 0.7421875}
...................................................................................................
Pass 0, Batch 300, Cost 1.668833, {'classification_error_evaluator': 0.6875}
..........................................................................................
Test with Pass 0, {'classification_error_evaluator': 0.885200023651123}
</pre></div>
<p>图12是训练的分类错误率曲线图，运行到第200个pass后基本收敛，最终得到测试集上分类错误率为8.54%。</p>
<p align="center">
<img src="image/plot.png" width="400"/><br/>
图12. CIFAR10数据集上VGG模型的分类错误率
</p>
<h2>应用模型</h2>
<p>可以使用训练好的模型对图片进行分类，下面程序展示了如何使用<code>paddle.infer</code>接口进行推断，可以打开注释，更改加载的模型。</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="k">def</span> <span class="nf">load_image</span><span class="p">(</span><span class="nb">file</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">),</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">im</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="c1"># PIL打开图片存储顺序为H(高度)，W(宽度)，C(通道)。</span>
    <span class="c1"># PaddlePaddle要求数据顺序为CHW，所以需要转换顺序。</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># CHW</span>
    <span class="c1"># CIFAR训练图片通道顺序为B(蓝),G(绿),R(红),</span>
    <span class="c1"># 而PIL打开图片默认通道顺序为RGB,因为需要交换通道。</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">),:,:]</span> <span class="c1"># BGR</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="k">return</span> <span class="n">im</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">cur_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
<span class="n">test_data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">load_image</span><span class="p">(</span><span class="n">cur_dir</span> <span class="o">+</span> <span class="s1">'/image/dog.png'</span><span class="p">),))</span>

<span class="c1"># with open('params_pass_50.tar', 'r') as f:</span>
<span class="c1">#    parameters = paddle.parameters.Parameters.from_tar(f)</span>

<span class="n">probs</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span>
    <span class="n">output_layer</span><span class="o">=</span><span class="n">out</span><span class="p">,</span> <span class="n">parameters</span><span class="o">=</span><span class="n">parameters</span><span class="p">,</span> <span class="nb">input</span><span class="o">=</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">lab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="o">-</span><span class="n">probs</span><span class="p">)</span> <span class="c1"># probs and lab are the results of one batch data</span>
<span class="k">print</span> <span class="s2">"Label of image/dog.png is: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="n">lab</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
<h2>总结</h2>
<p>传统图像分类方法由多个阶段构成，框架较为复杂，而端到端的CNN模型结构可一步到位，而且大幅度提升了分类准确率。本文我们首先介绍VGG、GoogleNet、ResNet三个经典的模型；然后基于CIFAR10数据集，介绍如何使用PaddlePaddle配置和训练CNN模型，尤其是VGG和ResNet模型；最后介绍如何使用PaddlePaddle的API接口对图片进行预测和特征提取。对于其他数据集比如ImageNet，配置和训练流程是同样的，大家可以自行进行实验。</p>
<h2>参考文献</h2>
<p>[1] D. G. Lowe, <a href="http://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf">Distinctive image features from scale-invariant keypoints</a>. IJCV, 60(2):91-110, 2004.</p>
<p>[2] N. Dalal, B. Triggs, <a href="http://vision.stanford.edu/teaching/cs231b_spring1213/papers/CVPR05_DalalTriggs.pdf">Histograms of Oriented Gradients for Human Detection</a>, Proc. IEEE Conf. Computer Vision and Pattern Recognition, 2005.</p>
<p>[3] Ahonen, T., Hadid, A., and Pietikinen, M. (2006). <a href="http://ieeexplore.ieee.org/document/1717463/">Face description with local binary patterns: Application to face recognition</a>. PAMI, 28.</p>
<p>[4] J. Sivic, A. Zisserman, <a href="http://www.robots.ox.ac.uk/~vgg/publications/papers/sivic03.pdf">Video Google: A Text Retrieval Approach to Object Matching in Videos</a>, Proc. Ninth Int'l Conf. Computer Vision, pp. 1470-1478, 2003.</p>
<p>[5] B. Olshausen, D. Field, <a href="http://redwood.psych.cornell.edu/papers/olshausen_field_1997.pdf">Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by V1?</a>, Vision Research, vol. 37, pp. 3311-3325, 1997.</p>
<p>[6] Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., and Gong, Y. (2010). <a href="http://ieeexplore.ieee.org/abstract/document/5540018/">Locality-constrained Linear Coding for image classification</a>. In CVPR.</p>
<p>[7] Perronnin, F., Sánchez, J., &amp; Mensink, T. (2010). <a href="http://dl.acm.org/citation.cfm?id=1888101">Improving the fisher kernel for large-scale image classification</a>. In ECCV (4).</p>
<p>[8] Lin, Y., Lv, F., Cao, L., Zhu, S., Yang, M., Cour, T., Yu, K., and Huang, T. (2011). <a href="http://ieeexplore.ieee.org/document/5995477/">Large-scale image clas- sification: Fast feature extraction and SVM training</a>. In CVPR.</p>
<p>[9] Krizhevsky, A., Sutskever, I., and Hinton, G. (2012). <a href="http://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf">ImageNet classification with deep convolutional neu- ral networks</a>. In NIPS.</p>
<p>[10] G.E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R.R. Salakhutdinov. <a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors</a>. arXiv preprint arXiv:1207.0580, 2012.</p>
<p>[11] K. Chatfield, K. Simonyan, A. Vedaldi, A. Zisserman. <a href="https://arxiv.org/abs/1405.3531">Return of the Devil in the Details: Delving Deep into Convolutional Nets</a>. BMVC, 2014。</p>
<p>[12] Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., <a href="https://arxiv.org/abs/1409.4842">Going deeper with convolutions</a>. In: CVPR. (2015)</p>
<p>[13] Lin, M., Chen, Q., and Yan, S. <a href="https://arxiv.org/abs/1312.4400">Network in network</a>. In Proc. ICLR, 2014.</p>
<p>[14] S. Ioffe and C. Szegedy. <a href="https://arxiv.org/abs/1502.03167">Batch normalization: Accelerating deep network training by reducing internal covariate shift</a>. In ICML, 2015.</p>
<p>[15] K. He, X. Zhang, S. Ren, J. Sun. <a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a>. CVPR 2016.</p>
<p>[16] Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z. <a href="https://arxiv.org/abs/1512.00567">Rethinking the incep-tion architecture for computer vision</a>. In: CVPR. (2016).</p>
<p>[17] Szegedy, C., Ioffe, S., Vanhoucke, V. <a href="https://arxiv.org/abs/1602.07261">Inception-v4, inception-resnet and the impact of residual connections on learning</a>. arXiv:1602.07261 (2016).</p>
<p>[18] Everingham, M., Eslami, S. M. A., Van Gool, L., Williams, C. K. I., Winn, J. and Zisserman, A. <a href="(http://link.springer.com/article/10.1007/s11263-014-0733-5)">The Pascal Visual Object Classes Challenge: A Retrospective</a>. International Journal of Computer Vision, 111(1), 98-136, 2015.</p>
<p>[19] He, K., Zhang, X., Ren, S., and Sun, J. <a href="https://arxiv.org/abs/1502.01852">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</a>. ArXiv e-prints, February 2015.</p>
<p>[20] http://deeplearning.net/tutorial/lenet.html</p>
<p>[21] https://www.cs.toronto.edu/~kriz/cifar.html</p>
<p>[22] http://cs231n.github.io/classification/</p>
<p><br/>
<a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license"><img alt="知识共享许可协议" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" style="border-width:0"/></a><br/><span href="http://purl.org/dc/dcmitype/Text" property="dct:title" rel="dct:type" xmlns:dct="http://purl.org/dc/terms/">本教程</span> 由 <a href="http://book.paddlepaddle.org" property="cc:attributionName" rel="cc:attributionURL" xmlns:cc="http://creativecommons.org/ns#">PaddlePaddle</a> 创作，采用 <a href="http://creativecommons.org/licenses/by-sa/4.0/" rel="license">知识共享 署名-相同方式共享 4.0 国际 许可协议</a>进行许可。</p>
{% endverbatim %}